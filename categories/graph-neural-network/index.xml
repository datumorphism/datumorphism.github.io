<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Graph Neural Network on Datumorphism</title><link>https://datumorphism.leima.is/categories/graph-neural-network/</link><description>Recent content in Graph Neural Network on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Mon, 28 Nov 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://datumorphism.leima.is/categories/graph-neural-network/index.xml" rel="self" type="application/rss+xml"/><item><title>Mix-hop Propagation in GNN</title><link>https://datumorphism.leima.is/cards/forecasting/gnn-mix-hop-propagation/</link><pubDate>Mon, 28 Nov 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/forecasting/gnn-mix-hop-propagation/</guid><description>The mix-hop propagation layer has two steps1:
information propagation step: $$ \mathbf H^{(k)} = \beta \mathbf H_{in} + (1-\beta)\mathbf L \mathbf H^{(k-1)}, $$
where $\mathbf L= (1+ \operatorname{A}) (\mathbf A + \mathbf I)$. This convolution step tries to disentangle the correlation between the nodes. information selection step: $$ \mathbf H_{out} = \sum_k \mathbf H^{(k)} \mathbf W^{(k)}. $$
See Fig 4 in the paper1.
Wu2020 Wu Z, Pan S, Long G, Jiang J, Chang X, Zhang C. Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2005.11650 &amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>Graph Structure Learning in GNN</title><link>https://datumorphism.leima.is/cards/forecasting/gnn-graph-structure-learning/</link><pubDate>Mon, 28 Nov 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/forecasting/gnn-graph-structure-learning/</guid><description>We extract the definitions in Wu et al., 20201. Given node embeddings $\mathbf E_i$1,
$$ \begin{align} \mathbf M_i &amp;= \tanh(\alpha \mathbf E_i \Theta_i) \\ \mathbf A &amp;= \operatorname{ReLU}(\tanh(\alpha (\mathbf M_1 \mathbf M_2^T - \mathbf M_2\mathbf M_1^T))), \end{align} $$
The author also proposed sparse requirement and only take the top-$k$ largest elements in $A$.
Wu2020 Wu Z, Pan S, Long G, Jiang J, Chang X, Zhang C. Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2005.11650 &amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>MTGNN</title><link>https://datumorphism.leima.is/reading/mtgnn/</link><pubDate>Mon, 28 Nov 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/reading/mtgnn/</guid><description>Key Components Time Convolution (TC) Module Time Convolution The temporal convolution is responsible for capturing temporal patterns in a sequence. Graph Convolution Module Mix-hop Propagation in GNN Mix-hop is a strategy to avoid oversmoothing in GNN Graph Structure Learning Layer Graph Structure Learning in GNN We can learn a graph structure without prior knowledge Architecture Wu et al., 2020</description></item><item><title>StemGNN</title><link>https://datumorphism.leima.is/reading/stemgnn/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/reading/stemgnn/</guid><description>What problem is StemGNN solving: intra-series temporal pattern: DFT Each series inter-series correlations At each step, the interactions between nodes reversible operator Example problem Covid cases: DE, AT, NL, &amp;hellip; Predicting each country without considering the interactions between them Or introduce the people flow between them GFT: Completes DFT as it takes care of the inter-series correlations one extra slide for this topic Convolutions on Graphs one extra slide for this topic Graph Basics How to build the graph &amp;ldquo;self-attention&amp;rdquo;: outer product of key, query, as the adjacency matrix key, query are of length # of ndoes Weights and Biases LC 1DConv GLU FC Experiments Traffic adjacency matrix neighbouring sensors have higher correlations Covid Neighbouring countries have higher correlation Spetral analysis: Some eigenvectors have clear meanings Week spots Paper and code are not consistent https://github.</description></item></channel></rss>