<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Time Series on Datumorphism</title><link>https://datumorphism.leima.is/categories/time-series/</link><description>Recent content in Time Series on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Fri, 08 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://datumorphism.leima.is/categories/time-series/index.xml" rel="self" type="application/rss+xml"/><item><title>Prediction Space in Forecasting</title><link>https://datumorphism.leima.is/cards/forecasting/prediction-space/</link><pubDate>Fri, 08 Apr 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/forecasting/prediction-space/</guid><description>In a forecasting problem, we have
$\mathcal P$, the priors, e.g., price and demand is negatively correlated, $\mathcal D$, available dataset, $Y$, the observations, and $F$, the forecasts. Information Set $\mathcal A$
The priors $\mathcal D$ and the available data $\mathcal P$ can be summarized together as the information set $\mathcal A$. Under a probabilistic view, a forecaster will find out or approximate a CDF $\mathcal F$ such that1
$$ \mathcal F(Y\vert \mathcal D, \mathcal P) \to F. $$
Naively speaking, once the density $\rho(F, Y)$ is determined or estimated, a probabilistic forecaster can be formed.</description></item><item><title>Short-Time-Fourier-Transform</title><link>https://datumorphism.leima.is/wiki/time-series/short-time-fourier-transform/</link><pubDate>Wed, 20 Jun 2018 15:58:49 -0400</pubDate><guid>https://datumorphism.leima.is/wiki/time-series/short-time-fourier-transform/</guid><description>Short-Time-Fourier-Transform We Fourier transform the time series data using a Fourier transform, with some window function
\begin{equation} \tilde Y[n,k] = \sum_m Y[n+m] W[m] e^{-i \lambda_k m}, \end{equation}
where $\lambda_k=2\pi k/N$ and $W[m]$ is the window function at $m$.
References and Notes Cousera</description></item><item><title>Autoregressive Model</title><link>https://datumorphism.leima.is/wiki/time-series/autoregressive-model/</link><pubDate>Wed, 20 Jun 2018 15:58:49 -0400</pubDate><guid>https://datumorphism.leima.is/wiki/time-series/autoregressive-model/</guid><description>Autoregressive Given a time series ${T^i}$, a simple predictive model can be constructed using an autoregressive model.
$$ \begin{equation} T^t = \sum_{i=1}^p \beta_i T^{t - i} + \beta^t + \beta^0. \end{equation} $$
Such a model is usually called an AR(p) model due to the fact that we are using data back in $p$ steps.
Differential Equation For simplicity we will look at a AR(1) model. Assume the time series has a step size of $dt$, our model can be rewritten as
$$ T^t = \beta_1 T^{t - 1} + \beta^t + \beta^0 $$
which can be rewritten in the following way</description></item><item><title>Predictions Using Time Series Data</title><link>https://datumorphism.leima.is/wiki/time-series/predictions-time-series-data/</link><pubDate>Fri, 21 Jun 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/time-series/predictions-time-series-data/</guid><description>General Phenological Model for Seasonality In business, time series data $f(t)$ usually carries information about trend $g(t)$ ($g$ is used since trend is usually growth), seasonalities (periodical effects) $p(t)$, holiday effects (structural effects) $s(t)$, etc. We will decompose a time series $f(t)$ into four components
$$ \begin{equation} f(t) = g(t) + p(t) + s(t) + \epsilon(t). \end{equation} $$
To train a model for the predictions, we need to write down the exact models of these three predictable components.</description></item><item><title>State Space Models</title><link>https://datumorphism.leima.is/wiki/time-series/state-space-models/</link><pubDate>Sun, 27 Feb 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/time-series/state-space-models/</guid><description>State space model is an important category of model for sequential data. Through simple assumptions, state space models can achieve quite complicated distributions.
To model a sequence, we can use the joint probability of all the nodes,
$$ p(x_1, x_2, \cdots, x_N), $$
where $x_i$ are the nodes in the sequence.
Orders We can introduce different order of dependencies on the past.
The simplest model for the sequence is assuming i.i.d..
Zeroth OrderEach node is independent of each other
To model the dependencies in the sequence, we can assume a node depends on the previous nodes. The first-order model assume that node $x_{i+1}$ only depends on node $x_i$.</description></item><item><title>Hidden Markov Model</title><link>https://datumorphism.leima.is/wiki/time-series/hidden-markov-model/</link><pubDate>Sun, 27 Feb 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/time-series/hidden-markov-model/</guid><description>The hidden Markov model, HMM, is a type of [[State Space Models]] State Space Models The state space model is an important category of models for sequential data such as time series 1.
HMM Bishop2006 Christpher M. Bishop. Pattern Recognition and Machine Learning. Springer-Verlag New York; 2006. &amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>Continuous Ranked Probability Score - CRPS</title><link>https://datumorphism.leima.is/cards/time-series/crps/</link><pubDate>Fri, 18 Mar 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/time-series/crps/</guid><description>The Continuous Ranked Probability Score, known as CRPS, is a score to measure how a proposed distribution approximates the data, without knowledge about the true distributions of the data.
Definition CRPS is defined as1
$$ CRPS(P, x_a) = \int_{-\infty}^\infty \lVert P(x) - H(x - x_a) \rVert_2 dx, $$
where
$x_a$ is the true value of $x$, P(x) is our proposed cumulative distribution for $x$, $H(x)$ is the Heaviside step function $$ H(x) = \begin{cases} 1, &amp;\qquad x=0\\ 0, &amp;\qquad x\leq 0\\ \end{cases} $$
$\lVert \cdot \rVert_2$ is the L2 norm. Explain it The formula looks abstract on first sight, but it becomes crystal clear once we understand it.</description></item></channel></rss>