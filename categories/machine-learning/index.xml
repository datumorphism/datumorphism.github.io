<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Learning on Datumorphism</title><link>https://datumorphism.leima.is/categories/machine-learning/</link><description>Recent content in Machine Learning on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Mon, 08 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://datumorphism.leima.is/categories/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>An Introduction to Generative Models</title><link>https://datumorphism.leima.is/wiki/machine-learning/generative-models/generative/</link><pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/generative-models/generative/</guid><description>Discriminative model:
The conditional probability of class label on data (posterior) $p(C_k\mid x)$ Generative models:
Likelihood $p(x\mid C_k)$ Sample from the likelihood to generate data With latent variables $z$ and some neural network parameters $\theta$: $P(x,z\mid \theta) = p(x\mid z, \theta)p(z)$</description></item><item><title>Contrastive Model</title><link>https://datumorphism.leima.is/wiki/machine-learning/contrastive-models/contrastive/</link><pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/contrastive-models/contrastive/</guid><description>Contrastive models learn to compare1. Contrastive use special objective functions such as NCE Noise Contrastive Estimation: NCE Noise contrastive estimation (NCE) objective function is1 $$ \mathcal L = \mathbb E_{x, x^{+}, x^{-}} \left[ - \ln \frac{ C(x, x^{+})}{ C(x,x^{+}) + C(x,x^{-}) } \right], $$ where $x^{+}$ represents data similar to $x$, $x^{-}$ represents data dissimilar to $x$, $C(\cdot, \cdot)$ is a function to compute the similarities. For example, we can use $$ C(x, x^{+}) = e^{ f(x)^T f(x^{+}) }, $$ so that the objective function becomes $$ \mathcal L = \mathbb E_{x, x^{+}, x^{-}} \left[ - \ln \frac{ e^{ â€¦ and Mutual Information Mutual Information Mutual information is defined as $$ I(X;Y) = \mathbb E_{p_{XY}} \ln \frac{P_{XY}}{P_X P_Y}.</description></item><item><title>GAN</title><link>https://datumorphism.leima.is/wiki/machine-learning/adversarial-models/gan/</link><pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/adversarial-models/gan/</guid><description>The task of GAN is to generate features $X$ from some noise $\xi$ and class labels $Y$,
$$\xi, Y \to X.$$
Many different GANs are proposed. Vanilla GAN has a simple structure with a single discriminator and a single generator. It uses the minmax game setup. However, it is not stable to use minmax game to train a GAN model. WassersteinGAN was proposed to solve the stability problem during training1. More advanced GANs like BiGAN and ALI have more complex structures.
Vanilla GAN Minmax Game Suppose we have two players $G$ and $D$, and a utility $v(D, G)$, a minmax game is maximizing the utility $v(D, G)$ for the worst case of $G=\hat G$ that minimizes $v$ then we have to find $D=\hat D$ that maximizes $v$, i.</description></item><item><title>Receiver Operating Characteristics: ROC</title><link>https://datumorphism.leima.is/wiki/machine-learning/performance/roc/</link><pubDate>Wed, 13 May 2020 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/performance/roc/</guid><description>ROC space is the two-dimensional space spanned by True Positive Rate and False Positive Rate.
ROC Space. The color boxes are indicating the confusion matrices. Green is the fraction of true positive. Orange is the fraction of false positive. Refer to Confusion Matrix for more details.
AUC: Area under Curve TPR = TP Rate FPR = FP Rate The ROC curve is defined by the relation $f(TPR, FPR)$. Area under the ROC curve is
$$ \int TPR(FPR) d(FPR) \sim \sum_i TPR_i *\Delta FPR. $$
If AUC = 1, we have TP Rate = 1 for all FP Rate.</description></item><item><title>Tree-based Learning</title><link>https://datumorphism.leima.is/wiki/machine-learning/tree-based/overview/</link><pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/tree-based/overview/</guid><description>Decision tree is an easy-to-interpret method in supervised learning. Though simple, it is being used in some widely used algorithms such as random forest method.</description></item><item><title>Embedding</title><link>https://datumorphism.leima.is/wiki/machine-learning/embedding/overview/</link><pubDate>Sun, 13 Oct 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/embedding/overview/</guid><description/></item><item><title>Factorization</title><link>https://datumorphism.leima.is/wiki/machine-learning/factorization/overview/</link><pubDate>Mon, 17 Jun 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/factorization/overview/</guid><description/></item><item><title>Feature Engineering</title><link>https://datumorphism.leima.is/wiki/machine-learning/feature-engineering/overview/</link><pubDate>Mon, 17 Jun 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/feature-engineering/overview/</guid><description/></item><item><title>Naive Bayes</title><link>https://datumorphism.leima.is/wiki/machine-learning/bayesian/naive-bayes/</link><pubDate>Mon, 17 Jun 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/bayesian/naive-bayes/</guid><description>Naive Bayesian is a classifier using Bayes&amp;#39; Theorem Bayes&amp;#39; Theorem Bayes' Theorem is stated as $$ P(A\mid B) = \frac{P(B \mid A) P(A)}{P(B)} $$ $P(A\mid B)$: likelihood of A given B $P(A)$: marginal probability of A There is a nice tree diagram for the Bayes' theorem on Wikipedia. Tree diagram of Bayes' theorem with &amp;lsquo;naive&amp;rsquo; assumptions.
Problems with Conditional Probability Calculation By definition, the conditional probability of event $\mathbf Y$ given features $\mathbf X$ is $$ \begin{equation} P(\mathbf Y\mid \mathbf X) = \frac{P(\mathbf Y, \mathbf X)}{ P(\mathbf X) }, \label{def-cp-y-given-x} \end{equation} $$
where
$P(\mathbf X)$ is probability of an event having the features $\mathbf X$, $P(\mathbf Y, \mathbf X)$ is the probability of the event $Y$ with features $\mathbf X$.</description></item><item><title>Confusion Matrix (Contingency Table)</title><link>https://datumorphism.leima.is/wiki/machine-learning/basics/confusion-matrix/</link><pubDate>Fri, 31 May 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/basics/confusion-matrix/</guid><description>Confusion Matrix It is much easier to understand the confusion matrix if we use a binary classification problem as an example. For example, we have a bunch of cat photos and the user labeled &amp;ldquo;cute or not&amp;rdquo; data. Now we are using the labeled data to train a cute-or-not binary classifier.
Then we apply the classifier on the test dataset and we would only find four different kinds of results.
Labeled as Cute Labeled as Not Cute Classifier Predicted to be Cute True Positive (TP) False Positive (FP) Classifier Predicted to be Not Cute False Negative (FN) True Negative (TN) This table is easy enough to comprehend.</description></item><item><title>Linear Methods</title><link>https://datumorphism.leima.is/wiki/machine-learning/linear/linear-methods/</link><pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/linear/linear-methods/</guid><description>Solving Classification Problems with Linear Models One simple idea behind classification is to calculate the posterior probability of each class given the variables.
Suppose a dataset have features $F_\alpha$ where $\alpha = 1, 2, \cdots, K$, with corresponding class labels $G_\alpha$. The dataset that provides $N$ datapoints with each deoted as $X_i$. The posterior of the classification is $P(G = G_\alpha \vert X = X_i)$.
A naive idea is to classify the data into two classes $m$ and $n$ using the boundary of a linear model
$$ P(G = G_\alpha \vert X = X_i) = P(G = G_\beta \vert X = X_i).</description></item><item><title>Machine Learning Overview</title><link>https://datumorphism.leima.is/wiki/machine-learning/overview/</link><pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/overview/</guid><description>What is Machine Learning Abu-Mostafa, Magdon-Ismail, and Lin summarized machine learning problem using the following chart 1 2. Utilimately, we need to find an approximation $g$ of the true map $f$ from features $\mathcal X$ to targets $\mathcal Y$ on a specific probability distribution of features $P$. This process is done by using an algorithm to select some hypothesis that works.
From the book Learning From Data by Abu-Mostafa, Magdon-Ismail, and Lin. I am using a version by Deckert.
In the core of machine learning models, we have three components3:
Representation: encode data and problem representation, i.</description></item><item><title>Contrastive Model: Context-Instance</title><link>https://datumorphism.leima.is/wiki/machine-learning/contrastive-models/context-instance/</link><pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/contrastive-models/context-instance/</guid><description>In contrastive methods, we can manipulate the data to create data entries and infer the changes using a model. These methods are models that &amp;ldquo;predict relative position&amp;rdquo;1. Common tricks are
shuffling image sections like jigsaw, and rotate the image. We can also adjust the model to discriminate the similarities and differences. For example, to generate contrast, we can also use Mutual Information Mutual Information Mutual information is defined as $$ I(X;Y) = \mathbb E_{p_{XY}} \ln \frac{P_{XY}}{P_X P_Y}. $$ In the case that $X$ and $Y$ are independent variables, we have $P_{XY} = P_X P_Y$, thus $I(X;Y) = 0$.</description></item><item><title>f-GAN</title><link>https://datumorphism.leima.is/wiki/machine-learning/adversarial-models/f-gan/</link><pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/adversarial-models/f-gan/</guid><description>The essence of GAN GAN The task of GAN is to generate features $X$ from some noise $\xi$ and class labels $Y$, $$\xi, Y \to X.$$ Many different GANs are proposed. Vanilla GAN has a simple structure with a single discriminator and a single generator. It uses the minmax game setup. However, it is not stable to use minmax game to train a GAN model. WassersteinGAN was proposed to solve the stability problem during training1. More advanced GANs like BiGAN and ALI have more complex structures. Vanilla GAN Minmax Game â€¦ is comparing the generated distribution $p_G$ and the data distribution $p_\text{data}$.</description></item><item><title>Generative Model: Autoregressive Model</title><link>https://datumorphism.leima.is/wiki/machine-learning/generative-models/autoregressive-model/</link><pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/generative-models/autoregressive-model/</guid><description>The likelihood is modeled as
$$ \begin{align} p_\theta (x) &amp;= \Pi_{t=1}^T p_\theta (x_t \mid x_{1:t-1}) \\ &amp;= p_\theta(x_2 \mid x_{1:1}) p_\theta(x_3 \mid x_{1:2}) \cdots p_\theta(x_T \mid x_{1:T-1}) \end{align} $$
Taking the log of it
$$ \ln p_\theta (x) = \sum_{t=1}^T \ln p_\theta (x_t \mid x_{1:t-1}) $$</description></item><item><title>Poisson Regression</title><link>https://datumorphism.leima.is/wiki/machine-learning/linear/poisson-regression/</link><pubDate>Fri, 07 May 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/linear/poisson-regression/</guid><description>Poisson regression is a generalized linear model for count data.
To model a dataset that is generated from a Poisson distribution, we only need to model the mean $\mu$ as it is the only parameters. The simplest model we can have for some given features $X$ is a linear model. However, for count data, the effects of the predictors are often multiplicative. The next simplest model we can have is
$$ \mu = \exp\left(\beta X\right). $$
The $\exp$ makes sure that the mean is positive as this is required for count data.</description></item><item><title>Data Types and Level of Measurement in Machine Learning</title><link>https://datumorphism.leima.is/wiki/machine-learning/feature-engineering/data-types/</link><pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/feature-engineering/data-types/</guid><description>Types of Data There are several debatable categorization methods of data.
The first widely spread theory, or level of measurement, is by S. Stevens. The theory categorizes data into four types, nominal, ordinal, interval, and ratio.
Other methods are proposed for other fields of research. For example, N. R. Chrisman proposed a different method for cartography. However, these are not generic enough for data science. They are more general than a specific field of research.
For machine learning, many statistical data types have been proposed. Some examples of data types and their relations with the level of measurement are shown in the following chart.</description></item><item><title>Decision Tree</title><link>https://datumorphism.leima.is/wiki/machine-learning/tree-based/decision-tree/</link><pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/tree-based/decision-tree/</guid><description>In this article, we will explain how decision trees work and build a tree by hand.
The code used in this article can be found in this repo. Definition of the problem We will decide whether one should go to work today. In this demo project, we consider the following features.
feature possible values health 0: feeling bad, 1: feeling good weather 0: bad weather, 1: good weather holiday 1: holiday, 0: not holiday For more compact notations, we use the abstract notation $\{0,1\}^3$ to describe a set of three features each with 0 and 1 as possible values.</description></item><item><title>Bayesian Linear Regression</title><link>https://datumorphism.leima.is/wiki/machine-learning/bayesian/bayesian-linear-regression/</link><pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/bayesian/bayesian-linear-regression/</guid><description>Linear Regression and Likelihood The linear estimator $y$ is
$$ \begin{equation} y^n = \beta^m X_m^{\phantom{m}n}. \label{eq-linear-model} \end{equation} $$
As usual, we have redefined our data to get rid of the intercept $\beta^0$.
In ordinary linear models, we find the error being the difference between the target $\hat y$ and the estimator $y$
$$ \epsilon = \hat y - y, $$
which is required to have a minimum absolute value.
In linear regressions, we use least squares to solve the problem. In Bayesian linear regression, instead of using a deterministic estimator $\beta^m X_m^{\phantom{m}n}$, we assume a Gaussian random estimator
$$ \begin{equation} \mathcal{N}(\mu, \sigma^2) = \mathcal{N}(\beta^m X_m^{\phantom{m}n}, \sigma^2), \end{equation} $$</description></item><item><title>NMF: Nonnegative Matrix Factorizatioin</title><link>https://datumorphism.leima.is/wiki/machine-learning/factorization/nmf/</link><pubDate>Thu, 13 Jun 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/factorization/nmf/</guid><description>Decomposition To make it easier to understand, we start with a data point $\mathbf P$ in a $k$-dimensional space spanned by $k$ basis vectors $\mathbf V^k$. Naturally, we could write down the component decomposition of the point using the basis vectors $\mathbf V^k$,
$$ \mathbf P = P_k \mathbf V^k. $$
This is immediately obvious to us since we have been dealing with rank 2 $(k, 1)$ basis vectors and we are talking about the $k$ coordinates for a point.
This point is represented by a matrix of rank 2 $(k, 1)$ given this basis.
$$ \mathbf P \to \begin{pmatrix} P_1, P_2, \cdots, P_k \end{pmatrix} $$</description></item><item><title>Word2vec</title><link>https://datumorphism.leima.is/wiki/machine-learning/embedding/word2vec/</link><pubDate>Thu, 13 Jun 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/embedding/word2vec/</guid><description>Word2vec is a word embedding model that learns the probability of some words being neighbours in a sentence $p_{neighbours}(w_i, w_o)$.
Build a dataset of adjacent words. CBOW; skipgram; negative sampling; Encode the words using vectors. Build a model $f(\{\theta_i\})$ to calculate the probability of the words being neighours and improve the parameters $\{\theta_i\}$ using the dataset.</description></item><item><title>Bias-Variance</title><link>https://datumorphism.leima.is/wiki/machine-learning/basics/bias-variance/</link><pubDate>Fri, 07 Jun 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/basics/bias-variance/</guid><description>Bias and Variance Suppose $f(X)$ is a perfect model that represents a &amp;ldquo;tight&amp;rdquo; model of the dataset $(X,Y)$ but some irredicible error $\epsilon$,
$$ \begin{equation} Y = f(X) + \epsilon. \label{dataset-using-true-model} \end{equation} $$
On the other hand, we build another model using a specific method such as k-nearest neighbors, which is denoted as $k(X)$.
Why the two models?
Why are we talking about the perfect model and a model using a specific method?
The perfect model $f(X)$ is our ultimate goal, while the model using a specific method $k(X)$ is our effort of approaching the ultimate model.
The bias measures the deficit between $k(X)$ and the perfect model $f(X)$,</description></item><item><title>Unsupervised Learning: PCA</title><link>https://datumorphism.leima.is/wiki/machine-learning/unsupervised/pca/</link><pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/unsupervised/pca/</guid><description>We use the Einstein summation notation in this article. Principal Component Analysis (PCA) is a commonly used trick for dimensionality reduction so that the new features represents most of the variances of the data.
Representations of Dataset In theory, a dataset can be represented by a matrix if we specify the basis. However, the initial given basis is not always the most convinient one. Suppose we find a new set of basis for the dataset, the matrix representation may be simpler and easier to use.
For convenience, we do not distinguish the representation and the abstract dataset in this article.</description></item><item><title>Contrastive Model: Instance-Instance</title><link>https://datumorphism.leima.is/wiki/machine-learning/contrastive-models/instance-instance/</link><pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/contrastive-models/instance-instance/</guid><description>It was discovered that the success of mutual information based contrastive learning Contrastive Model: Context-Instance In contrastive methods, we can manipulate the data to create data entries and infer the changes using a model. These methods are models that &amp;ldquo;predict relative position&amp;rdquo;1. Common tricks are shuffling image sections like jigsaw, and rotate the image. We can also adjust the model to discriminate the similarities and differences. For example, to generate contrast, we can also use Mutual Information Mutual Information Mutual information is defined as $$ I(X;Y) = \mathbb E_{p_{XY}} \ln â€¦ is more related to the encoder architecture and the negative sampling strategy1.</description></item><item><title>Generative Model: Flow</title><link>https://datumorphism.leima.is/wiki/machine-learning/generative-models/flow/</link><pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/generative-models/flow/</guid><description>For a probability density $p(x)$ and a transformation of coordinate $x=g(z)$ or $z=f(x)$, the density can be expressed using the coordinate transformations, i.e.,
$$ \begin{align} p(x) &amp;= \tilde p (f(x)) \lvert \operatorname{det} \operatorname{D} g(f(x)) \rvert^{-1} \\ &amp;= \tilde p(f(x)) \lvert \operatorname{det}\operatorname{D} f(x) \rvert \end{align} $$
where the Jacobian is
$$ \operatorname{D} g(z) \to \frac{\partial }{\partial z} g. $$
The operation $g_{}\circ \tilde p(z)$ is the push forward of $\tilde p(z)$. The operation $g_{}$ will pushforward simple distribution $\tilde p(z)$ to a more complex distribution $p(x)$.
The generative direction: sample $z$ from distribution $\tilde p(z)$, apply transformation $g(z)$; The normalizing direction: &amp;ldquo;simplify&amp;rdquo; $p(x)$ to some simple distribution $\tilde p(z)$.</description></item><item><title>infoGAN</title><link>https://datumorphism.leima.is/wiki/machine-learning/adversarial-models/infogan/</link><pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/adversarial-models/infogan/</guid><description>In GAN, the latent space input is usually random noise, e.g., Gaussian noise. The objective of GAN is a very generic one. It doesn&amp;rsquo;t say anything about how exactly the latent space will be used. This is not desirable in many problems. We would like to have more interpretability in the latent space. InfoGAN introduced constraints to the objective to enforce interpretability of the latent space1.
Constraint The constraint InfoGAN proposed is Mutual Information Mutual Information Mutual information is defined as $$ I(X;Y) = \mathbb E_{p_{XY}} \ln \frac{P_{XY}}{P_X P_Y}. $$ In the case that $X$ and $Y$ are independent variables, we have $P_{XY} = P_X P_Y$, thus $I(X;Y) = 0$.</description></item><item><title>Logistic Regression</title><link>https://datumorphism.leima.is/wiki/machine-learning/linear/logistic-regression/</link><pubDate>Thu, 27 May 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/linear/logistic-regression/</guid><description>In a classification problem, given a list of features values $x$ and their corresponding classes $\{c_i\}$, the posterior for of the classes, aka conditional probability of the classes, is
$$ p(C=c_i\mid X=x). $$
Likelihood
The likelihood of the data is
$$ p(X=x\mid C=c_i). $$
Logistic Regression for Two Classes For two classes, the simplest model for the posterior is a linear model,
$$ \log \frac{p(C=c_1\mid X=x) }{p(C=c_2\mid X=x)} = \beta_0 + \beta_1 \cdot x, $$
which is equivalent to
$$ p(C=c_1\mid X=x) = \exp\left(\beta_0 + \beta_1 \cdot x\right) p(C=c_2\mid X=x) . $$
Why
The reason that we proposing a linear model for the quantity</description></item><item><title>Random Forest</title><link>https://datumorphism.leima.is/wiki/machine-learning/tree-based/random-forest/</link><pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/tree-based/random-forest/</guid><description>Random forest is an ensemble method based on decision trees. Instead of using one decision tree and model on all the features, the decision tree method can model on a random set of features (feature subspace) using many decision trees and make decisions by democratizing the trees.
Given a proper dataset $\mathscr D(\mathbf X, \mathbf y)$, the ensemble of trees is denoted as ${f_i(\mathbf X)}$, will predict an ensemble of results. There are several key ideas in random forests.
Are the predicted results representative? How to democratize the ensemble of results? What determines the quality of the predictions? Margin, Strength, and Correlations The margin of the model, the strength of the trees, and the correlation between the trees are crucial to answer the questions.</description></item><item><title>Tensor Factorization</title><link>https://datumorphism.leima.is/wiki/machine-learning/factorization/tensor-factorization/</link><pubDate>Mon, 17 Jun 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/factorization/tensor-factorization/</guid><description>Tensors We will be talking about tensors but we will skip the introduction to tensor for now.
In this article, we follow a commonly used convention for tensors in physics, the abstract index notation. We will denote tensors as $T^{ab\cdots}_ {\phantom{ab\cdots}cd\cdots}$, where the latin indices such as $^{a}$ are simply a placebo for the slot for this &amp;ldquo;tensor machine&amp;rdquo;. For a given basis (coordinate system), we can write down the components of this tensor $T^{\alpha\beta\cdots} _ {\phantom{\alpha\beta\cdots}\gamma\delta\cdots}$.
Okay, But Why
What is usually seen in blog posts is the use of component forms of tensors, $T^{\alpha\beta\cdots}_{\phantom{\alpha\beta\cdots}\gamma\delta\cdots}$. Those are the numbers for a given basis.</description></item><item><title>Unsupervised Learning: SVM</title><link>https://datumorphism.leima.is/wiki/machine-learning/unsupervised/svm/</link><pubDate>Fri, 17 Aug 2018 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/unsupervised/svm/</guid><description>SVM is calculating a hyperplane to separate the data points into groups according to the label.
Hyperplane A hyperplane is defined to be of the following form
$$ \begin{equation} \boldsymbol{\beta} \cdot \mathbf x = \beta_0. \end{equation} $$
where $\boldsymbol\beta$ is the normal vector to the plane and is required to be constant.
It is straight forward to show that the distance $d$ from an arbitrary point $\mathbf x'$ to the hyperplane is
$$ \begin{equation} d = \boldsymbol\beta \cdot \mathbf x' - \beta_0. \end{equation} $$
A Few Key Concepts in SVM Though the concept of SVM is simple, one might find the algorithm to be quite complicated at first glance.</description></item><item><title>Generative Model: Auto-Encoder</title><link>https://datumorphism.leima.is/wiki/machine-learning/generative-models/autoencoder/</link><pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/generative-models/autoencoder/</guid><description>The simplest auto-encoder is rather simple.
The loss can be chosen based on the demand, e.g., cross entropy for binary labels.</description></item><item><title>Deep Autoregressive Network</title><link>https://datumorphism.leima.is/wiki/machine-learning/neural-networks/deep-autoregressive-networks/</link><pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/neural-networks/deep-autoregressive-networks/</guid><description>There are two levels of autoregressiveness in the DARN network:
Inlayer autoregressive connections of the nodes, Intralayer autoregressive connections of nodes. The network is trained on MDL loss.</description></item><item><title>Variational Auto-Encoder</title><link>https://datumorphism.leima.is/wiki/machine-learning/generative-models/variational-autoencoder/</link><pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/generative-models/variational-autoencoder/</guid><description>Variational Auto-Encoder (VAE) is very different from Generative Model: Auto-Encoder Generative Model: Auto-Encoder The simplest auto-encoder is rather simple. The loss can be chosen based on the demand, e.g., cross entropy for binary labels. . In VAE, we introduce a variational distribution $q$ to help us work out the weighted integral after introducing the latent space variable $z$,
$$ \begin{align} \ln p_\theta(x) &amp;= \int \left(\ln p_\theta (x\mid z) \right)p(z) \,\mathrm d z \\ &amp;= \int \left(\ln\frac{q_{\phi}(z\mid x)}{q_{\phi}(z\mid x)} p_\theta (x\mid z) \right) p(z) \, \mathrm d z \end{align} $$
In the above derivation,
${}_\theta$ is the model for inference, and ${}_\phi$ is the model for variational approximation.</description></item><item><title>Centered Kernel Alignment (CKA)</title><link>https://datumorphism.leima.is/cards/machine-learning/measurement/centered-kernel-alignment/</link><pubDate>Mon, 08 Nov 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/machine-learning/measurement/centered-kernel-alignment/</guid><description>Centered Kernel Alignment (CKA) is a similarity metric designed to measure the similarity of between representations of features in neural networks1.
Definition of CKA CKA is based on the Hilbert-Schmidt Independence Criterion (HSIC) Hilbert-Schmidt Independence Criterion (HSIC) Given two kernels of the feature representations $K=k(x,x)$ and $L=l(y,y)$, HSIC is defined as12 $$ \operatorname{HSIC}(K, L) = \frac{1}{(n-1)^2} \operatorname{tr}( K H L H ), $$ where $x$, $y$ are the representations of features, $n$ is the dimension of the representation of the features, $H$ is the so-called centering matrix Centering Matrix Useful when centering a vector around its mean . We can choose different kernel functions $k$ and $l$.</description></item><item><title>Hilbert-Schmidt Independence Criterion (HSIC)</title><link>https://datumorphism.leima.is/cards/machine-learning/measurement/hilbert-schmidt-independence-criterion/</link><pubDate>Mon, 08 Nov 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/machine-learning/measurement/hilbert-schmidt-independence-criterion/</guid><description>Given two kernels of the feature representations $K=k(x,x)$ and $L=l(y,y)$, HSIC is defined as12
$$ \operatorname{HSIC}(K, L) = \frac{1}{(n-1)^2} \operatorname{tr}( K H L H ), $$
where
$x$, $y$ are the representations of features, $n$ is the dimension of the representation of the features, $H$ is the so-called centering matrix Centering Matrix Useful when centering a vector around its mean . We can choose different kernel functions $k$ and $l$. For example, if $k$ and $l$ are linear kernels, we have $k(x, y) = l(x, y) = x \cdot y$. In this linear case, HSIC is simply $\parallel\operatorname{cov}(x^T,y^T) \parallel^2_{\text{Frobenius}}$.</description></item><item><title>Differential Learning Rates in PyTorch</title><link>https://datumorphism.leima.is/til/machine-learning/pytorch/pytorch-differential-learning-rates/</link><pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/til/machine-learning/pytorch/pytorch-differential-learning-rates/</guid><description>Using different learning rates in different layers of our artificial neural network.</description></item><item><title>The log-sum-exp Trick</title><link>https://datumorphism.leima.is/cards/machine-learning/neural-networks/log-sum-exp-trick/</link><pubDate>Wed, 28 Jul 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/machine-learning/neural-networks/log-sum-exp-trick/</guid><description>The cross entropy for a binary class is
$$ p \ln \hat p + (1-p) \ln (1-\hat p), $$
where $p$ is the probability of the label A and $\hat p$ is the predicted probability of label A. Since we have binary classes, $p$ is either 1 or 0. However, the predicted probabilities can be any value between $[0,1]$.
Probability
For a very simple case, $\hat p$ might be a sigmoid like expression with exponential in it,
$$ p \sim \frac{1}{1 + \exp(-x)}, $$
where $x$ is some kind of input or intermediate input.
The problem is, exponentials may blow up if $p\to 0$.</description></item><item><title>Evidence Lower Bound: ELBO</title><link>https://datumorphism.leima.is/wiki/machine-learning/bayesian/elbo/</link><pubDate>Mon, 12 Apr 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/bayesian/elbo/</guid><description>This article reuses a lot of materials from the references. Please see the references for more details on ELBO. Given a probability distribution density $p(X)$ and a latent variable $Z$, we have the marginalization of the joint probability
$$ \int dZ p(X, Z) = p(X). $$
Using Jensen&amp;rsquo;s Inequality In many models, we are interested in the log probability density $\log p(X)$ which can be decomposed using an auxiliary density of the latent variable $q(Z)$,
$$ \begin{align} \log p(X) =&amp; \log \int dZ p(X, Z) \\ =&amp; \log \int dZ p(X, Z) \frac{q(Z)}{q(Z)} \\ =&amp; \log \int dZ q(Z) \frac{p(X, Z)}{q(Z)} \\ =&amp; \log \mathbb E_q \left[ \frac{p(X, Z)}{q(Z)} \right].</description></item><item><title>Valid Confidence Sets in Multiclass and Multilabel Prediction</title><link>https://datumorphism.leima.is/wiki/machine-learning/classification/valid-confidence-sets-in-multiclass-multilabel-prediction/</link><pubDate>Thu, 08 Apr 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/classification/valid-confidence-sets-in-multiclass-multilabel-prediction/</guid><description>Ask for valid confidence:
&amp;ldquo;Valid&amp;rdquo;: validate for test data, train data, or the generating process? &amp;ldquo;Confidence&amp;rdquo;: $P(Y \notin C(X)) \le \alpha$ To avoid too much attention on data based validation, a framework called conformal inference was proposed by Vovk et al. in 2005,
$n$ observations, desired confidence level $1-\alpha$, construct confidence sets $C(x)$ using conform methods so that the sets capture the underlying the distribution a new pair $(X_{n+1}, Y_{n+1})$ from the same distribution, $P(Y_{n+1}\in C(X_{n+1})) \le 1-\alpha$</description></item><item><title>Hierarchical Classification</title><link>https://datumorphism.leima.is/wiki/machine-learning/classification/hierarchical-classification/</link><pubDate>Tue, 30 Mar 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/classification/hierarchical-classification/</guid><description>Hierarchical Classification Problem Hierarchical classification labels involves hierarchical class labels. The hierarchical class labels maybe predefined or inferred. 1
Class Taxonomy A hierarchical classification problem comes with a class taxonomy.
&amp;ldquo;IS-A&amp;rdquo; operator: $\prec$, &amp;ldquo;IS-NOT-A&amp;rdquo; operator: $\nprec$ A IS-A relationship of the labels $c_a$ class set $C$ is
one root $R$ in the tree, asymmetric, i.e., $c_i \prec c_j$ and $c_j\prec c_i$ can not be both true, anti-reflexive, i.e., $c_i \nprec c_i$, transitive, i.e., $c_i \prec c_j$ and $c_j\prec c_k$ $\Rightarrow$ $c_i \prec c_k$. There are different representations of the hierarchical taxonomies.
Figure 2 in Silla2011, showing the difference between tree taxonomy and DAG taxonomy.</description></item><item><title>Classifier Chains for Multilabel Classification</title><link>https://datumorphism.leima.is/wiki/machine-learning/classification/classifier-chains/</link><pubDate>Wed, 24 Mar 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/classification/classifier-chains/</guid><description>Multi-label problem In some classification problems, we have multilabel labels to be predicted. Many different approaches are proposed to solve such problems.
Algorithm Level Develop algorithms for multilabel problems, such as
Decision trees, AdaBoost. Problem Transformation On problem or data level, we can transform the multi-label problem to one or more single label problems.
Binary Relevance Method Binary relevance method, aka BM, transforms the problem into a single label problem by training a binary classifier for each label.
By doing so, the correlations between the target labels are lost.
Label Combination Method Label combination method (label power-set method), aka CM, combines the labels into single labels.</description></item><item><title>McCulloch-Pitts Model</title><link>https://datumorphism.leima.is/cards/machine-learning/neural-networks/mcculloch-pitts-model/</link><pubDate>Thu, 25 Feb 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/machine-learning/neural-networks/mcculloch-pitts-model/</guid><description>The McCulloch-Pitts model maps the input $\{x_1, x_2,\cdots, x_i \cdots, x_N \}$ into a scalar $y\in\{1,-1\}$,
$$ y = \operatorname{sign}( w\cdot x - b). $$
Since $w\cdot x - b = 0$ is a hyperplane, the McCulloch-Pitts model separates the state space using this hyperplane. The shift $b$ determines the interception, and $w$ decides the slope.</description></item><item><title>Rosenblatt's Perceptron</title><link>https://datumorphism.leima.is/cards/machine-learning/neural-networks/rosenblatt-perceptron/</link><pubDate>Thu, 25 Feb 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/machine-learning/neural-networks/rosenblatt-perceptron/</guid><description>Rosenblatt&amp;rsquo;s perceptron connects McCulloch-Pitts neurons in levels.
Rosenblatt proposed that we fix all the weights and leave the weights of the last neuron free.
The first few layers but the last layer is used as a transformation of the input data ${x_1, \cdots, x_i, \cdots, x_N}$ into a new space ${z_1, \cdots, z_i, \cdots, z_{N'}}$. The classification is done on the ${z_1, \cdots, z_i, \cdots, z_{N'}}$ space by tuning the last neuron.
Initially, we set $w=0$. At step $k$,
if the sign prediction by the perceptron $( w_k \cdot z_{k+1} )$ is the same as the data $y_{k+1}$, i.</description></item><item><title>Empirical Loss</title><link>https://datumorphism.leima.is/cards/machine-learning/measurement/empirical-loss/</link><pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/machine-learning/measurement/empirical-loss/</guid><description>Given a dataset with records $\{x_i, y_i\}$ and a model $\hat y_i = f(x_i)$ the empirical loss is calculated on all the records
$$ \begin{align} \mathcal L_{E} = \frac{1}{n} \sum_i^n d(y_i, f(x_i)), \end{align} $$
where $d(y_i, f(x_i))$ is the distance defined between $y_i$ and $f(x_i)$.</description></item><item><title>Population Loss</title><link>https://datumorphism.leima.is/cards/machine-learning/measurement/population-loss/</link><pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/machine-learning/measurement/population-loss/</guid><description>Given a dataset with records $\{x_i, y_i\}$ and a model $\hat y_i = f(x_i)$. Suppose we know the actual generating process of the dataset and the joint probability density distribution of all the data points is $p(x, y)$, the population loss is defined on the whole assumed population,
$$ \begin{align} \mathcal L_{P} = \mathop{\mathbb{E}}_{p(x,y)}[ d(y, f(x))], \end{align} $$
where $d(y, f(x))$ is the distance defined between $y$ and $f(x)$.</description></item><item><title>Machine as a Hologram</title><link>https://datumorphism.leima.is/projects/hologram/</link><pubDate>Sun, 31 Jan 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/projects/hologram/</guid><description>Tutorials on machine learning and data science productivity articles</description></item><item><title>Latent Variable Models</title><link>https://datumorphism.leima.is/wiki/machine-learning/bayesian/latent-variable-models/</link><pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/bayesian/latent-variable-models/</guid><description>In the view of statistics, we know everything about a physical system if we know the probability $p(\mathbf s)$ of all possible states of the physical system $\mathbf s$. Time can also be part of the state specification.
As an example, we will classify fruits into oranges and non oranges. We will have the state vector $\mathbf s = (\text{is orange}, \text{texture } x)$. Our goal is to find the joint probability $p(\text{is orange}, x)$.
The reality, we only have sample data. This sample data usually can not cover all the possible states of the system. Thus a direct calculation to find the joint probability $p(\mathbf s)$ is not feasible.</description></item><item><title>PyTorch: Initialize Parameters</title><link>https://datumorphism.leima.is/til/machine-learning/pytorch/pytorch-initial-params/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/til/machine-learning/pytorch/pytorch-initial-params/</guid><description>We can set the parameters in a for loop. We take some of the initialization methods from Lippe1.
To set based on the input dimension of the layer ( Initialize Artificial Neural Networks Initialize Artificial Neural Networks Initialize a neural network is important for the training and performance. Some initializations simply don&amp;#39;t work, some will degrade the performance of the model. We should choose wisely. ) (normalized initialization),
for name, param in model.named_parameters(): if name.endswith(&amp;#34;.bias&amp;#34;): param.data.fill_(0) else: bound = math.sqrt(6)/math.sqrt(param.shape[0]+param.shape[1]) param.data.uniform_(-bound, bound) or set the parameters based on the input size of each layer
for name, param in model.</description></item><item><title>Pandas Groupby Does Not Guarantee Unique Content in Groupby Columns</title><link>https://datumorphism.leima.is/til/machine-learning/pandas-groupby-caveats/</link><pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/til/machine-learning/pandas-groupby-caveats/</guid><description>Pandas Groupby Does Not Guarantee Unique Content in Groupby Columns, it also considers the datatypes. Dealing with mixed types requires additional attention.</description></item><item><title>Data Types</title><link>https://datumorphism.leima.is/cards/machine-learning/datatypes/data-types/</link><pubDate>Thu, 16 Jan 2020 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/machine-learning/datatypes/data-types/</guid><description/></item><item><title>Gini Impurity</title><link>https://datumorphism.leima.is/cards/machine-learning/measurement/gini-impurity/</link><pubDate>Thu, 16 Jan 2020 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/machine-learning/measurement/gini-impurity/</guid><description>The code used in this article can be found in this repo. Suppose we have a dataset $\{0,1\}^{10}$, which has 10 records and 2 possible classes of objects $\{0,1\}$ in each record.
The first example we investigate is a pure 0 dataset.
object 0 0 0 0 0 0 0 0 0 0 0 0 For such an all-0 dataset, we would like to define its impurity as 0.</description></item><item><title>Information Gain</title><link>https://datumorphism.leima.is/cards/machine-learning/measurement/information-gain/</link><pubDate>Thu, 16 Jan 2020 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/machine-learning/measurement/information-gain/</guid><description>Information gain is a frequently used metric in calculating the gain during a split in tree-based methods.
First o all, the entropy of a dataset if defined as
$$ S = - sum_i p_i \log p_i - sum_i (1-p_i)\log p_i, $$
where $p_i$ is the probability of a class.
The information gain is the difference between the entropy.
For example, in a decision tree algorithm, we would split a node. Before splitting, we assign a label $m$ to the node,
$$ S_m = - p_m \log p_m - (1-p_m)\log p_m. $$
After the splitting, we have two groups that contributes to the entropy, group $L$ and group $R$,</description></item><item><title>Dealing with Missing Data in Machine Learning</title><link>https://datumorphism.leima.is/wiki/machine-learning/feature-engineering/missing-data/</link><pubDate>Mon, 05 Aug 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/feature-engineering/missing-data/</guid><description>How to Deal with Missing Data Remove Listwise deletion: Remove the whole record; Works if the missing values are random. Removing values causes problem in many aspects. For example, we can not just delete data when applying our models. Replace with most frequent value central tendency: median, mean, etc fixed value: a string etc New Category: define a new category for missing data Convert the column to a binary valued column indicating if the feature is missing or not. Tools pandas sklearn: Imputer @ResidentMario/missingno : visualize missing data</description></item></channel></rss>