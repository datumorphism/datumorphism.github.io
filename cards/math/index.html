<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.69.2"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Math | Datumorphism | Lei Ma</title><meta name=description content="Knowledge cards about math"><meta name=robots content="noindex"><meta name=author content="Lei Ma"><meta property="og:title" content="Math"><meta property="og:description" content="Knowledge cards about math"><meta property="og:type" content="website"><meta property="og:url" content="/cards/math/"><meta property="og:updated_time" content="2020-12-27T00:00:00+00:00"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-140452515-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><link href=/cards/math/index.xml rel=alternate type=application/rss+xml title=Datumorphism><link rel=canonical href=/cards/math/><link rel="shortcut icon" type=image/png href=/logos/logo-square.png><link rel=stylesheet href=/css/bulma.css><link rel=stylesheet href=/css/bulma-divider.min.css><link rel=stylesheet href=/assets/css/bulma-ribbon.min.css><link rel=stylesheet href=/assets/css/tooltip.css><link rel=stylesheet href=https://jenil.github.io/bulmaswatch/united/bulmaswatch.min.css><link rel=stylesheet href=/css/custom.css><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],tags:'ams'},svg:{fontCache:'global'}};</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js></script><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>mermaid.initialize({startOnLoad:true});</script><script src=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/js/all.min.js integrity="sha256-KzZiKy0DWYsnwMF+X1DvQngQ2/FxF7MF3Ff72XcpuPs=" crossorigin=anonymous></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin=anonymous></head><body><header><nav class="navbar is-transparent"><div class=navbar-brand><a class=navbar-item href=/><img src=/site/intelligence.png alt=Datumorphism height=28 style=margin-right:.5em> Datumorphism</a><div class="navbar-burger burger" data-target=navMenu><span></span><span></span><span></span></div></div><div class=navbar-menu id=navMenu><div class=navbar-start><div class="navbar-item has-dropdown is-hoverable"><a href=/projects class=navbar-link>Notebooks</a><div class=navbar-dropdown><a href=/awesome/ class=navbar-item>Awesome</a>
<a href=/blog/ class=navbar-item>Blog</a>
<a href=/cards/ class=navbar-item>Cards</a>
<a href=/reading/ class=navbar-item>Reading Notes</a>
<a href=/til/ class=navbar-item>TIL</a>
<a href=/wiki/ class=navbar-item>Wiki</a></div></div></div><span class=navbar-burger><span></span><span></span><span></span></span><div class=navbar-end><div class=navbar-item><a class=navbar-item href=/blog/>Blog</a>
<a class=navbar-item href=/tags/><i class="fas fa-tags"></i></a><a class=navbar-item href=/graph><i class="fas fa-project-diagram"></i></a><a class=navbar-item target=blank href=https://github.com/datumorphism><span class=icon><i class="fab fa-github"></i></span></a></div></div></div></nav><script>document.addEventListener('DOMContentLoaded',()=>{const $navbarBurgers=Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'),0);if($navbarBurgers.length>0){$navbarBurgers.forEach(el=>{el.addEventListener('click',()=>{const target=el.dataset.target;const $target=document.getElementById(target);el.classList.toggle('is-active');$target.classList.toggle('is-active');});});}});</script></header><main><section><div class="hero is-dark is-medium"><div class=hero-body><div class="container has-text-centered"><h1 class="title is-1">Math</h1><h2 class="subtitle is-3">Knowledge cards about math</h2></div></div></div></section><div class="columns is-fullheight"><div class=column><section class="hero is-default is-bold"><div class=hero-body><div class=container><div class="columns is-desktop is-multiline"><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><a href=/cards/math/multiset-mset-bag/ itemprop=headline>Multiset, mset or bag</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2020-12-27T00:00:00+00:00>2020-12-27</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i>Category: { Math }</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/sets style=margin-right:.5em><span class="tag is-warning is-small is-light">#Sets</span></a>
<a href=/tags/basics style=margin-right:.5em><span class="tag is-warning is-small is-light">#Basics</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: A bag is a set in which duplicate elements are allowed.
An ordered bag is a list that we use in programming.</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><a href=/cards/math/mahalanobis-distance/ itemprop=headline>Mahalanobis Distance</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2020-03-11T00:00:00+00:00>2020-03-11</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i>Category: { Math }</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/distance style=margin-right:.5em><span class="tag is-warning is-small is-light">#Distance</span></a>
<a href=/tags/metric style=margin-right:.5em><span class="tag is-warning is-small is-light">#Metric</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://en.wikipedia.org/wiki/Mahalanobis_distance>Mahalanobis distance @ Wikipedia</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: Distance between a point and a distribution by measuring the distance between the point and the mean of the distribution using the coordinate system defined by the principal components.</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><a href=/cards/math/diagonalize-matrix/ itemprop=headline>Diagnolize Matrices</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2020-03-11T00:00:00+00:00>2020-03-11</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i>Category: { Math }</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/linear-algebra style=margin-right:.5em><span class="tag is-warning is-small is-light">#Linear Algebra</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: Diagnolizing a matrix is a transformation using its eigen space.</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><a href=/cards/math/tucker-decomposition/ itemprop=headline>Tucker Decomposition</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2019-06-18T00:00:00+00:00>2019-06-18</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i>Category: { Math }</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/tensor style=margin-right:.5em><span class="tag is-warning is-small is-light">#Tensor</span></a>
<a href=/tags/factorization style=margin-right:.5em><span class="tag is-warning is-small is-light">#Factorization</span></a>
<a href=/tags/linear-algebra style=margin-right:.5em><span class="tag is-warning is-small is-light">#Linear Algebra</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=http://statmath.wu.ac.at/research/talks/resources/talkfreudenthaler.pdf>Matrix and Tensor Factorization from a Machine Learning Perspective</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: Tucker decomposition of a generalization of SVD to higher ranks</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><a href=/cards/math/svd/ itemprop=headline>SVD: Singular Value Decomposition</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2019-06-18T00:00:00+00:00>2019-06-18</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i>Category: { Math }</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/matrix style=margin-right:.5em><span class="tag is-warning is-small is-light">#Matrix</span></a>
<a href=/tags/factorization style=margin-right:.5em><span class="tag is-warning is-small is-light">#Factorization</span></a>
<a href=/tags/linear-algebra style=margin-right:.5em><span class="tag is-warning is-small is-light">#Linear Algebra</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=http://statmath.wu.ac.at/research/talks/resources/talkfreudenthaler.pdf>Matrix and Tensor Factorization from a Machine Learning Perspective</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: Given a matrix $\mathbf X \to X_{m}^{\phantom{m}n}$, we can decompose it into three matrices
$$ X_{m}^{\phantom{m}n} = U_{m}^{\phantom{m}k} D_{k}^{\phantom{k}l} (V_{n}^{\phantom{n}l} )^{\mathrm T}, $$
where $D_{k}^{\phantom{k}l}$ is diagonal.
Here we have $\mathbf U$ being constructed by the eigenvectors of $\mathbf X \mathbf X^{\mathrm T}$, while $\mathbf V$ is being constructed by the eigenvectors of $\mathbf X^{\mathrm T} \mathbf X$ (which is also the reason we keep the transpose).
I find this slide from Christoph Freudenthaler very useful.</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><a href=/cards/math/modes-and-slices-of-tensor/ itemprop=headline>Modes and Slices of Tensors</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2019-06-18T00:00:00+00:00>2019-06-18</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i>Category: { Math }</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/tensor style=margin-right:.5em><span class="tag is-warning is-small is-light">#Tensor</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://www.sandia.gov/~tgkolda/pubs/pubfiles/SAND2007-6702.pdf>Tensor Decompositions and Applications by Tamara G. Kolda and Brett W. Bader</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: Simple decomposition of tensors</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><a href=/cards/math/khatri-rao/ itemprop=headline>Khatri-Rao Product</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2019-06-18T00:00:00+00:00>2019-06-18</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i>Category: { Math }</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/tensor style=margin-right:.5em><span class="tag is-warning is-small is-light">#Tensor</span></a>
<a href=/tags/linear-algebra style=margin-right:.5em><span class="tag is-warning is-small is-light">#Linear Algebra</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://en.wikipedia.org/wiki/Kronecker_product#Khatri%E2%80%93Rao_product>Kronecker product</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: Choose X from N is
$$ C_N^X = \frac{N!}{ X! (N-X)! } $$</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><a href=/cards/math/canonical-decomposition/ itemprop=headline>Canonical Decomposition</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2019-06-18T00:00:00+00:00>2019-06-18</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i>Category: { Math }</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/tensor style=margin-right:.5em><span class="tag is-warning is-small is-light">#Tensor</span></a>
<a href=/tags/factorization style=margin-right:.5em><span class="tag is-warning is-small is-light">#Factorization</span></a>
<a href=/tags/linear-algebra style=margin-right:.5em><span class="tag is-warning is-small is-light">#Linear Algebra</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=http://statmath.wu.ac.at/research/talks/resources/talkfreudenthaler.pdf>Matrix and Tensor Factorization from a Machine Learning Perspective</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: Canonical decomposition</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><a href=/cards/math/n-gram/ itemprop=headline>n-gram</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2019-05-19T00:00:00+00:00>2019-05-19</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i>Category: { Math }</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/nlp style=margin-right:.5em><span class="tag is-warning is-small is-light">#NLP</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://github.com/words/n-gram/blob/master/index.js>words/n-gram</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: n-gram is a method to split words into set of substring elements so that those can be used to match words.
Examples Use the following examples to get your first idea about it. I created two columns so that we could compare the n-grams of two different words side-by-side.
n in n-gram is Word One Clean Word: (( sentenceOneWords )) n-grams: (( sentenceOneWordsnGram )) Word Two Clean Word: (( sentenceTwoWords )) n-grams: (( sentenceTwoWordsnGram )) /*************************/ /** The function nGram is a copy of https://github.</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><a href=/cards/math/levenshtein-distance/ itemprop=headline>Levenshtein Distance</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2019-05-19T00:00:00+00:00>2019-05-19</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i>Category: { Math }</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/distance style=margin-right:.5em><span class="tag is-warning is-small is-light">#Distance</span></a>
<a href=/tags/nlp style=margin-right:.5em><span class="tag is-warning is-small is-light">#NLP</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://github.com/trekhleb/javascript-algorithms/tree/master/src/algorithms/string/levenshtein-distance>levenshtein-distance @ trekhleb/javascript-algorithms</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: Levenshtein distance calculates the number of operations needed to change one word to another by applying single-character edits (insertions, deletions or substitutions).
The reference explains this concept very well. For consistency, I extracted a paragraph from it which explains the operations in Levenshtein algorithm. The source of the following paragraph is the first reference of this article.
Levenshtein Matrix
Cell (0:1) contains red number 1. It means that we need 1 operation to transform M to an empty string.</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><a href=/cards/math/tf-idf/ itemprop=headline>Term Frequency - Inverse Document Frequency</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2019-05-06T00:00:00+00:00>2019-05-06</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i>Category: { Math }</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/nlp style=margin-right:.5em><span class="tag is-warning is-small is-light">#NLP</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://en.wikipedia.org/wiki/Tf%E2%80%93idf>Tf-idf</a></span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=http://www.tfidf.com/>tf-idf</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary:</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><a href=/cards/math/jaccard-similarity/ itemprop=headline>Jaccard Similarity</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2019-05-06T00:00:00+00:00>2019-05-06</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i>Category: { Math }</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/set style=margin-right:.5em><span class="tag is-warning is-small is-light">#Set</span></a>
<a href=/tags/distance style=margin-right:.5em><span class="tag is-warning is-small is-light">#Distance</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://en.wikipedia.org/wiki/Jaccard_index>Jaccard index</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: Jaccard index is the ratio of the size of the intersect of the set and the size of the union of the set.
$$ J(A, B) = \frac{ \vert A \cap B \vert }{ \vert A \cup B \vert } $$
Jaccard distance $d_J(A,B)$ is defined as
$$ d_J(A,B) = 1 - J(A,B). $$
Properties If the two sets are the same, $A=B$, we have $J(A,B)=1$ or $d_J(A,B)=0$. We have maximum similarity.</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><a href=/cards/math/eigendecomposition/ itemprop=headline>Eigenvalues and Eigenvectors</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2019-05-06T00:00:00+00:00>2019-05-06</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i>Category: { Math }</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/linear-algebra style=margin-right:.5em><span class="tag is-warning is-small is-light">#Linear Algebra</span></a>
<a href=/tags/basics style=margin-right:.5em><span class="tag is-warning is-small is-light">#Basics</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://setosa.io/ev/eigenvectors-and-eigenvalues/>Eigenvectors and Eigenvalues @ Explained Visually</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: To find the eigenvectors $\mathbf x$ of a matrix $\mathbf A$, we construct the eigen equation
$$ \mathbf A \mathbf x = \lambda \mathbf x, $$
where $\lambda$ is the eigenvalue.
We rewrite it in the components form,
$$ \begin{equation} A_{ij} x_j = \lambda x_i. \label{eqn-eigen-decomp-def} \end{equation} $$
Mathematically speaking, it is straightforward to find the eigenvectors and eigenvalues.
Eigenvectors are Special Directions Judging from the definition in Eq.($\ref{eqn-eigen-decomp-def}$), the eigenvectors do not change direction under the operation of the matrix $\mathbf A$.</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><a href=/cards/math/cosine-similarity/ itemprop=headline>Cosine Similarity</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2019-05-06T00:00:00+00:00>2019-05-06</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i>Category: { Math }</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/set style=margin-right:.5em><span class="tag is-warning is-small is-light">#Set</span></a>
<a href=/tags/distance style=margin-right:.5em><span class="tag is-warning is-small is-light">#Distance</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://en.wikipedia.org/wiki/Cosine_similarity>Cosine Similarity</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: As simple as the inner product of two vectors
$$ d_{cos} = \frac{\vec A}{\vert \vec A \vert} \cdot \frac{\vec B }{ \vert \vec B \vert} $$
Examples To use cosine similarity, we have to vectorize the words first. There are many different methods to achieve this. For the purpose of illustrating cosine similarity, we use term frequency.
Term frequency is the occurrence of the words. We do not deal with duplications so duplicate words will have some effect on the similarity.</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><a href=/cards/math/combinations/ itemprop=headline>Combinations</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2019-04-07T00:00:00+00:00>2019-04-07</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i>Category: { Math }</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/combinations style=margin-right:.5em><span class="tag is-warning is-small is-light">#Combinations</span></a>
<a href=/tags/basics style=margin-right:.5em><span class="tag is-warning is-small is-light">#Basics</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: Choose X from N is
$$ C_N^X = \frac{N!}{ X! (N-X)! } $$</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div></div></div><br><div class=container></div></div></section></div></div></main><footer><footer class=footer><div class=container><div class="content has-text-centered"><p>Created and maintained by <a href=/>Lei Ma</a>.
Acknowledgement: <a href=https://gohugo.io/>Hugo</a>,
<a href=https://themes.gohugo.io/bulma/>Bulma</a>, <a href=https://kausalflow.com>KausalFlow</a>.
<strong>love</strong>.<br><a class=tag href=/about>About</a>
<a class=tag href=/index.xml>Feed</a>
<a class=tag href=/data.json>JSON Data</a></p></div></div></footer></footer><script async type=text/javascript src=/js/bulma.js></script></body></html>