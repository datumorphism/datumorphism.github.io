<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Statistics on Datumorphism</title><link>/cards/statistics/</link><description>Recent content in Statistics on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Tue, 27 Oct 2020 00:00:00 +0000</lastBuildDate><atom:link href="/cards/statistics/index.xml" rel="self" type="application/rss+xml"/><item><title>Conditional Probability Table</title><link>/cards/statistics/conditional-probability-table/</link><pubDate>Tue, 27 Oct 2020 00:00:00 +0000</pubDate><guid>/cards/statistics/conditional-probability-table/</guid><description>The conditional probability table, aka CPT, is used to calculate conditional probabilities from a dataset.
Given a dataset with features $\mathbf X$ and their corresponding classes $\mathbf Y$, the conditional probabilities of each class given a certain feature value can be calculated using a CPT which in turn can be calculated using a contigency table Detecting correlations using correlations for numeric data .</description></item><item><title>Arcsine Distribution</title><link>/cards/statistics/distributions/arcsine/</link><pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate><guid>/cards/statistics/distributions/arcsine/</guid><description>Arcsine Distribution The PDF is
$$ \frac{1}{\pi\sqrt{x(1-x)}} $$
for $x\in [0,1]$.
It can also be generalized to
$$ \frac{1}{\pi\sqrt{(x-1)(b-x)}} $$
for $x\in [a,b]$.
Visualize</description></item><item><title>Bernoulli Distribution</title><link>/cards/statistics/distributions/bernoulli/</link><pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate><guid>/cards/statistics/distributions/bernoulli/</guid><description>Two categories with probability $p$ and $1-p$ respectively.
For each experiment, the sample space is $\{A, B\}$. The probability for state $A$ is given by $p$ and the probability for state $B$ is given by $1-p$. The Bernoulli distribution describes the probability of $K$ results with state $s$ being $s=A$ and $N-K$ results with state $s$ being $B$ after $N$ experiments,
$$ P\left(\sum_i^N s_i = K \right) = C _ N^K p^K (1 - p)^{N-K}.</description></item><item><title>Beta Distribution</title><link>/cards/statistics/distributions/beta/</link><pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate><guid>/cards/statistics/distributions/beta/</guid><description>Beta Distribution Interact {% include extras/vue.html %}
((makeGraph))</description></item><item><title>Binomial Distribution</title><link>/cards/statistics/distributions/binomial/</link><pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate><guid>/cards/statistics/distributions/binomial/</guid><description>The number of successes in $n$ independent events where each trial has a success rate of $p$.
PMF:
$$ C_n^k p^k (1-p)^{n-k} $$</description></item><item><title>Categorical Distribution</title><link>/cards/statistics/distributions/categorical/</link><pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate><guid>/cards/statistics/distributions/categorical/</guid><description>By generalizing the Bernoulli distribution to $k$ states, we get a categorical distribution. The sample space is $\{s_1, s_2, \cdots, s_k\}$. The corresponding probabilities for each state are $\{p_1, p_2, \cdots, p_k\}$ with the constraint $\sum_{i=1}^k p_i = 1$.</description></item><item><title>Cauchy-Lorentz Distribution</title><link>/cards/statistics/distributions/cauchy/</link><pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate><guid>/cards/statistics/distributions/cauchy/</guid><description>Cauchy-Lorentz Distribution .. ratio of two independent normally distributed random variables with mean zero.
Source: https://en.wikipedia.org/wiki/Cauchy_distribution
Lorentz distribution is frequently used in physics.
PDF:
$$ \frac{1}{\pi\gamma} \left( \frac{\gamma^2}{ (x-x_0)^2 + \gamma^2} \right) $$
The median and mode of the Cauchy-Lorentz distribution is always $x_0$. $\gamma$ is the FWHM.
Visualize</description></item><item><title>Gamma Distribution</title><link>/cards/statistics/distributions/gamma/</link><pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate><guid>/cards/statistics/distributions/gamma/</guid><description>Gamma Distribution PDF:
$$ \frac{\beta^\alpha x^{\alpha-1} e^{-\beta x}}{\Gamma(\alpha)} $$
Visualize</description></item><item><title>Covariance Matrix</title><link>/cards/statistics/covariance-matrix/</link><pubDate>Tue, 10 Mar 2020 00:00:00 +0000</pubDate><guid>/cards/statistics/covariance-matrix/</guid><description>We use Einstein&amp;rsquo;s summation convention. Covariance of two discrete series $A$ and $B$ is defined as
$$ \text{Cov} ({A,B}) = \sigma_{A,B}^2 = \frac{ (a_i - \bar A) (b_i - \bar B) }{ n- 1 }, $$
where $n$ is the length of the series. The normalization factor is set to $1/(n-1)$ to mitigate the bias for small $n$.
One could show that
$$ \mathrm{Cov}({A,B}) = E( A,B ) - \bar A \bar B.</description></item><item><title>Jackknife Resampling</title><link>/cards/statistics/jacknife-resampling/</link><pubDate>Sun, 26 Jan 2020 00:00:00 +0000</pubDate><guid>/cards/statistics/jacknife-resampling/</guid><description>Jackknife resampling is a method for estimation of the mean and higher order moments.
Given a sample $\{x_i\}$ of size $n$ for the distribution $X$, the jackknife resampling estimates the mean by leaving out each data point systematically. $n$ estimations of the mean will be obtained, with each of the estimations $x_i$
$$ \bar x_i = \frac{1}{n-1} \sum_{j\neq i} x_j. $$
The mean of the sample is
$$ \bar x = \frac{1}{n}\sum_i \bar x_i = \frac{1}{n} \sum_i \left(\frac{1}{n-1} \sum_{j\neq i} x_j\right) = \frac{1}{n}\sum_i x_i.</description></item><item><title>Kendall Tau Correlation</title><link>/cards/statistics/kendall-correlation-coefficient/</link><pubDate>Sat, 20 Jul 2019 00:00:00 +0000</pubDate><guid>/cards/statistics/kendall-correlation-coefficient/</guid><description>Definition two series of data: $X$ and $Y$ cooccurance of them: $(x_i, x_j)$, and we assume that $i&amp;lt;j$ concordant: $x_i &amp;lt; x_j$ and $y_i &amp;lt; y_j$; $x_i &amp;gt; x_j$ and $y_i &amp;gt; y_j$; denoted as $C$ discordant: $x_i &amp;lt; x_j$ and $y_i &amp;gt; y_j$; $x_i &amp;gt; x_j$ and $y_i &amp;lt; y_j$; denoted as $D$ neither concordant nor discordant: whenever equal sign happens Kendall&amp;rsquo;s tau is defined as
$$ \begin{equation} \tau = \frac{C- D}{\text{all possible pairs of comparison}} = \frac{C- D}{n^2/2 - n/2} \end{equation} $$</description></item><item><title>Bayes' Theorem</title><link>/cards/statistics/bayes-theorem/</link><pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate><guid>/cards/statistics/bayes-theorem/</guid><description>Bayes&amp;rsquo; Theorem is stated as
$$ P(A\mid B) = \frac{P(B \mid A) P(A)}{P(B)} $$
$P(A\mid B)$: likelihood of A given B $P(A)$: marginal probability of A There is a nice tree diagram for the Bayes&amp;rsquo; theorem on Wikipedia.
Tree diagram of Bayes&amp;rsquo; theorem</description></item><item><title>Poisson Process</title><link>/cards/statistics/poisson-process/</link><pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate><guid>/cards/statistics/poisson-process/</guid><description>Poisson Process Statistics // define getUnixTime Date.prototype.getUnixTime = function () { return this.getTime() / 1000 | 0 }; if (!Date.now) Date.now = function () { return new Date(); } Date.time = function () { return Date.now().getUnixTime(); } POISSON_EVENT_RATE = 1 function get_event_time() { var time = new Date(); return time } all_event = [] all_event_diff = [] var data = [{ x: [get_event_time], y: [1], mode: 'markers', line: { color: '#80CAF6' } }] var layout = { title: { text: 'Poisson Process' }, xaxis: { title: { text: 'Event Time' }, } }; var layout_rate = { title: { text: 'Average Rate of the Poisson Process' }, xaxis: { title: { text: 'Event Time' }, }, yaxis: { title: { text: 'Average Event Rate per Second' }, rangemode: 'tozero' } }; var data_rate = [{ x: [get_event_time], y: [POISSON_EVENT_RATE], mode: 'lines+markers', line: { color: '#80CAF6' } }] Plotly.</description></item><item><title>Akaike Information Criterion</title><link>/cards/statistics/aic/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/cards/statistics/aic/</guid><description>Suppose we have a model that describes the data generation process behind a dataset. The distribution by the model is denoted as $\hat f$. The actual data generation process is described by a distribution $f$.
We ask the question:
How good is the approximation using $\hat f$?
To be more precise, how much information is lost if we use our model dist $\hat f$ to substitute the actual data generation distribution $f$?</description></item><item><title>Bayes Factors</title><link>/cards/statistics/bayes-factors/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/cards/statistics/bayes-factors/</guid><description>$$ \frac{p(\mathscr M_1|y)}{ p(\mathscr M_2|y) } = \frac{p(\mathscr M_1)}{ p(\mathscr M_2) }\frac{p(y|\mathscr M_1)}{ p(y|\mathscr M_2) } $$
Bayes factor
$$ \mathrm{BF_{12}} = \frac{m(y|\mathscr M_1)}{m(y|\mathscr M_2)} $$
$\mathrm{BF_{12}}$: how many time more likely is model $\mathscr M_1$ than $\mathscr M_2$.</description></item><item><title>Bayesian Information Criterion</title><link>/cards/statistics/bic/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/cards/statistics/bic/</guid><description>BIC is Bayesian information criterion, it replaced the $+2k$ term in AIC with $k\ln n$
$$ \mathrm{BIC} = -2\ln p(y|\hat\theta) + k\ln n = \ln \left(\frac{n^k}{p^2}\right) $$
$n$ is the observations. We prefer the model with a small BIC.</description></item><item><title>Fisher Information Approximation</title><link>/cards/statistics/fia/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/cards/statistics/fia/</guid><description>#FIA is a method to describe the [[minimum-description-length|minimum description length ( #MDL )]] of models,
$$ \mathrm{FIA} = -\ln p(y | \hat\theta) + \frac{k}{2} \ln \frac{n}{2\pi} + \ln \int_\Theta \sqrt{ \operatorname{det}[I(\theta)] d\theta } $$
$I(\theta)$: Fisher information matrix of sample size 1. $$I_{i,j}(\theta) = E\left( \frac{\partial \ln p(y| \theta)}{\partial \theta_i}\frac{ \partial \ln p (y | \theta) }{ \partial \theta_j } \right)$$.</description></item><item><title>Kolmogorov Complexity</title><link>/cards/statistics/kolmogorov-complexity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/cards/statistics/kolmogorov-complexity/</guid><description>Description:
$\Sigma=\{0,1\}$, a map $f:\Sigma^* \to\Sigma^*$. To describe a string of 0 and 1 $\sigma$, the description is a map so that $f(\tau)=\sigma$.
Kolmogorov complexity $C_f$
$$ C_f(x) = \begin{cases} min\{ \vert p \vert : f(p) = x &amp; \text{if x} \\ \infty &amp; \text{otherwise} \} \end{cases} $$ $f$ can be a universal turing machine.</description></item><item><title>Minimum Description Length</title><link>/cards/statistics/mdl/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/cards/statistics/mdl/</guid><description>The minimum description length ( #MDL ) is based on the idea of compression of the data.
MDL looks for the model that compresses the data well. To compress data, we need to find the regularity in the data.
There are many versions of MDL.
crude two-part code Fisher information approximation ( # FIA ) Normalized Maximum likelihood ( #NML )</description></item><item><title>Normalized Maximum Likelihood</title><link>/cards/statistics/nml/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/cards/statistics/nml/</guid><description>$$ \mathrm{NML} = \frac{ p(y| \hat \theta(y)) }{ \int_X p( x| \hat \theta (x) ) dx } $$</description></item></channel></rss>