<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Measurement on Datumorphism</title><link>/cards/machine-learning/measurement/</link><description>Recent content in Measurement on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Thu, 16 Jan 2020 00:00:00 +0000</lastBuildDate><atom:link href="/cards/machine-learning/measurement/index.xml" rel="self" type="application/rss+xml"/><item><title>Gini Impurity</title><link>/cards/machine-learning/measurement/gini-impurity/</link><pubDate>Thu, 16 Jan 2020 00:00:00 +0000</pubDate><guid>/cards/machine-learning/measurement/gini-impurity/</guid><description>The code used in this article can be found in this repo. Suppose we have a dataset $\{0,1\}^{10}$, which has 10 records and 2 possible classes of objects $\{0,1\}$ in each record.
The first example we investigate is a pure 0 dataset.
object 0 0 0 0 0 0 0 0 0 0 0 0 For such an all-0 dataset, we would like to define its impurity as 0.</description></item><item><title>Information Gain</title><link>/cards/machine-learning/measurement/information-gain/</link><pubDate>Thu, 16 Jan 2020 00:00:00 +0000</pubDate><guid>/cards/machine-learning/measurement/information-gain/</guid><description>Information gain is a frequently used metric in calculating the gain during a split in tree-based methods.
First o all, the entropy of a dataset if defined as
$$ S = - sum_i p_i \log p_i - sum_i (1-p_i)\log p_i, $$
where $p_i$ is the probability of a class.
The information gain is the difference between the entropy.
For example, in a decision tree algorithm, we would split a node. Before splitting, we assign a label $m$ to the node,</description></item></channel></rss>