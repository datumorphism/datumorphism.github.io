<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>wiki/pattern-mining/association-rules.md on Datumorphism</title><link>https://datumorphism.leima.is/links/wiki/pattern-mining/association-rules.md/</link><description>Recent content in wiki/pattern-mining/association-rules.md on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="https://datumorphism.leima.is/links/wiki/pattern-mining/association-rules.md/index.xml" rel="self" type="application/rss+xml"/><item><title>Naive Bayes</title><link>https://datumorphism.leima.is/wiki/machine-learning/bayesian/naive-bayes/</link><pubDate>Mon, 17 Jun 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/bayesian/naive-bayes/</guid><description>Naive Bayesian is a classifier using [[Bayes&amp;#39; Theorem]] Bayes&amp;#39; Theorem Bayes&amp;rsquo; Theorem is stated as $$ P(A\mid B) = \frac{P(B \mid A) P(A)}{P(B)} $$ $P(A\mid B)$: likelihood of A given B $P(A)$: marginal probability of A There is a nice tree diagram for the Bayes&amp;rsquo; theorem on Wikipedia. Tree diagram of Bayes&amp;rsquo; theorem with &amp;rsquo;naive&amp;rsquo; assumptions.
Problems with Conditional Probability Calculation By definition, the conditional probability of event $\mathbf Y$ given features $\mathbf X$ is $$ \begin{equation} P(\mathbf Y\mid \mathbf X) = \frac{P(\mathbf Y, \mathbf X)}{ P(\mathbf X) }, \label{def-cp-y-given-x} \end{equation} $$
where
$P(\mathbf X)$ is probability of an event having the features $\mathbf X$, $P(\mathbf Y, \mathbf X)$ is the probability of the event $Y$ with features $\mathbf X$.</description></item></channel></rss>