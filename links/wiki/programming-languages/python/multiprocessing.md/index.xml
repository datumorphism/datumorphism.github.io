<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>wiki/programming-languages/python/multiprocessing.md on Datumorphism</title><link>https://datumorphism.leima.is/links/wiki/programming-languages/python/multiprocessing.md/</link><description>Recent content in wiki/programming-languages/python/multiprocessing.md on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="https://datumorphism.leima.is/links/wiki/programming-languages/python/multiprocessing.md/index.xml" rel="self" type="application/rss+xml"/><item><title>Pandas with MultiProcessing</title><link>https://datumorphism.leima.is/til/programming/pandas/pandas-parallel-multiprocessing/</link><pubDate>Sun, 09 Sep 2018 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/til/programming/pandas/pandas-parallel-multiprocessing/</guid><description>Define number of processes, prs; Split dataframe into prs dataframes; Process each dataframe with one process; Merge processed dataframes into one. A piece of demo code is shown below.
from multiprocessing.dummy import Pool as ThreadPool import pandas as pd # Create a dataframe to be processed df = pd.read_csv(&amp;#39;somedata.csv&amp;#39;).reset_index(drop=True) # Define a function to be applied to the dataframe def nice_func(name, age): return (name,age) # Apply to dataframe def apply_to_df(df_chunks): df_chunks[&amp;#39;tupled&amp;#39;] = df_chunks.apply( lambda x: nice_func( x[&amp;#39;host_name&amp;#39;], x[&amp;#39;host_country&amp;#39;]), axis=1 ) return df_chunks print(&amp;#39;finished chunk&amp;#39;) # Divide dataframe to chunks prs = 100 # define the number of processes chunk_size = int(df.</description></item></channel></rss>