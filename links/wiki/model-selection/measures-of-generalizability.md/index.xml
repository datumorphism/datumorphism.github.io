<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>wiki/model-selection/measures-of-generalizability.md on Datumorphism</title><link>/links/wiki/model-selection/measures-of-generalizability.md/</link><description>Recent content in wiki/model-selection/measures-of-generalizability.md on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="/links/wiki/model-selection/measures-of-generalizability.md/index.xml" rel="self" type="application/rss+xml"/><item><title>Model Selection</title><link>/wiki/model-selection/model-selection/</link><pubDate>Sun, 08 Nov 2020 00:00:00 +0000</pubDate><guid>/wiki/model-selection/model-selection/</guid><description>Suppose we have a generating process that generates some numbers based on a distribution. Based on a data sample, we could reconstruct some sort of theoretical models to represent the actual generating process.
Which is a Good Model? (1)The black curve represent the generating process. The red rectangle is a very simple model that captures some major samples. The blue step-wise model is capturing more sample data but with more parameters.</description></item><item><title>Goodness-of-fit</title><link>/wiki/model-selection/goodness-of-fit/</link><pubDate>Sun, 08 Nov 2020 00:00:00 +0000</pubDate><guid>/wiki/model-selection/goodness-of-fit/</guid><description>Does the data agree with the model?
Calculate the distance between data and model predictions. Apply Bayesian methods such as likelihood estimation: likelihood of observing the data if we assume the model; the results will be a set of fitting parameters. &amp;hellip; Why don&amp;rsquo;t we always use goodness-of-fit as a measure of the goodness of a model?
We may experience overfitting. The model may not be intuitive. This is why we would like to balance it with parsimony using some measures of generalizability.</description></item><item><title>Parsimony of Models</title><link>/wiki/model-selection/parsimony-of-models/</link><pubDate>Sun, 08 Nov 2020 00:00:00 +0000</pubDate><guid>/wiki/model-selection/parsimony-of-models/</guid><description>For models with a lot of parameters, the goodness-of-fit is very likely to be very high. However, it is also likely to generalize bad. So we need measure of generalizability
Here parsinomy gives us a few advantages.
easy to perceive better generalizations</description></item><item><title>Empirical Loss</title><link>/cards/machine-learning/measurement/empirical-loss/</link><pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate><guid>/cards/machine-learning/measurement/empirical-loss/</guid><description>Given a dataset with records $\{x_i, y_i\}$ and a model $\hat y_i = f(x_i)$ the empirical loss is calculated on all the records
$$ \begin{align} \mathcal L_{E} = \frac{1}{n} \sum_i^n d(y_i, f(x_i)), \end{align} $$ where $d(y_i, f(x_i))$ is the distance defined between $y_i$ and $f(x_i)$.</description></item><item><title>Population Loss</title><link>/cards/machine-learning/measurement/population-loss/</link><pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate><guid>/cards/machine-learning/measurement/population-loss/</guid><description>Given a dataset with records $\{x_i, y_i\}$ and a model $\hat y_i = f(x_i)$. Suppose we know the actual generating process of the dataset and the joint probability density distribution of all the data points is $p(x, y)$, the population loss is defined on the whole assumed population,
$$ \begin{align} \mathcal L_{P} = \mathop{\mathbb{E}}_{p(x,y)}[ d(y, f(x))], \end{align} $$ where $d(y, f(x))$ is the distance defined between $y$ and $f(x)$.</description></item></channel></rss>