<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>wiki/model-selection/goodness-of-fit.md on Datumorphism</title><link>/links/wiki/model-selection/goodness-of-fit.md/</link><description>Recent content in wiki/model-selection/goodness-of-fit.md on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="/links/wiki/model-selection/goodness-of-fit.md/index.xml" rel="self" type="application/rss+xml"/><item><title>Model Selection</title><link>/wiki/model-selection/model-selection/</link><pubDate>Sun, 08 Nov 2020 00:00:00 +0000</pubDate><guid>/wiki/model-selection/model-selection/</guid><description>Suppose we have a generating process that generates some numbers based on a distribution. Based on a data sample, we could reconstruct some sort of theoretical models to represent the actual generating process.
Which is a Good Model? (1)The black curve represent the generating process. The red rectangle is a very simple model that captures some major samples. The blue step-wise model is capturing more sample data but with more parameters.</description></item><item><title>Parsimony of Models</title><link>/wiki/model-selection/parsimony-of-models/</link><pubDate>Sun, 08 Nov 2020 00:00:00 +0000</pubDate><guid>/wiki/model-selection/parsimony-of-models/</guid><description>For models with a lot of parameters, the goodness-of-fit is very likely to be very high. However, it is also likely to generalize bad. So we need measure of generalizability
Here parsinomy gives us a few advantages.
easy to perceive better generalizations</description></item><item><title>Akaike Information Criterion</title><link>/cards/statistics/aic/</link><pubDate>Sun, 08 Nov 2020 00:00:00 +0000</pubDate><guid>/cards/statistics/aic/</guid><description>Suppose we have a model that describes the data generation process behind a dataset. The distribution by the model is denoted as $\hat f$. The actual data generation process is described by a distribution $f$.
We ask the question:
How good is the approximation using $\hat f$?
To be more precise, how much information is lost if we use our model dist $\hat f$ to substitute the actual data generation distribution $f$?</description></item><item><title>Bayesian Information Criterion</title><link>/cards/statistics/bic/</link><pubDate>Sun, 08 Nov 2020 00:00:00 +0000</pubDate><guid>/cards/statistics/bic/</guid><description>BIC is Bayesian information criterion, it replaced the $+2k$ term in AIC Suppose we have a model that describes the data generation process behind a dataset. The distribution by the model is denoted as $\hat f$. The actual data generation process is described by a distribution $f$. We ask the question: How good is the approximation using $\hat f$? To be more precise, how much information is lost if we use our model dist $\hat f$ to substitute the actual data generation distribution $f$?</description></item></channel></rss>