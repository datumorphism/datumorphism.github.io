<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>wiki/machine-learning/contrastive-models/context-instance.md on Datumorphism</title><link>https://datumorphism.leima.is/links/wiki/machine-learning/contrastive-models/context-instance.md/</link><description>Recent content in wiki/machine-learning/contrastive-models/context-instance.md on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="https://datumorphism.leima.is/links/wiki/machine-learning/contrastive-models/context-instance.md/index.xml" rel="self" type="application/rss+xml"/><item><title>Contrastive Predictive Coding</title><link>https://datumorphism.leima.is/wiki/machine-learning/contrastive-models/contrastive-predictive-codeing/</link><pubDate>Wed, 08 Sep 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/contrastive-models/contrastive-predictive-codeing/</guid><description>Contrastive Predictive Coding, aka CPC, is an autoregressive model combined with InfoNCE loss1.
There are two key ideas in CPC:
Autoregressive models in latent space, and InfoNCE loss that combines mutual information and NCE Noise Contrastive Estimation: NCE Noise contrastive estimation (NCE) objective function is1 $$ \mathcal L = \mathbb E_{x, x^{+}, x^{-}} \left[ - \ln \frac{ C(x, x^{+})}{ C(x,x^{+}) + C(x,x^{-}) } \right], $$ where $x^{+}$ represents data similar to $x$, $x^{-}$ represents data dissimilar to $x$, $C(\cdot, \cdot)$ is a function to compute the similarities. For example, we can use $$ C(x, x^{+}) = e^{ f(x)^T f(x^{+}) }, $$ so that the objective function becomes $$ \mathcal L = \mathbb E_{x, x^{+}, x^{-}} \left[ - \ln \frac{ e^{ â€¦ .</description></item><item><title>Deep Infomax</title><link>https://datumorphism.leima.is/wiki/machine-learning/contrastive-models/deep-infomax/</link><pubDate>Wed, 08 Sep 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/contrastive-models/deep-infomax/</guid><description>Max Global Mutual Information
Why not just use the global mutual information of the input and encoder output as the objective?
&amp;hellip; maximizing MI between the complete input and the encoder output (i.e.,globalMI) is ofteninsufficient for learning useful representations.
&amp;ndash; Devon et al[^Devon2018]
Mutual information Mutual Information Mutual information is defined as $$ I(X;Y) = \mathbb E_{p_{XY}} \ln \frac{P_{XY}}{P_X P_Y}. $$ In the case that $X$ and $Y$ are independent variables, we have $P_{XY} = P_X P_Y$, thus $I(X;Y) = 0$. This makes sense as there would be no &amp;ldquo;mutual&amp;rdquo; information if the two variables are independent of each other.</description></item></channel></rss>