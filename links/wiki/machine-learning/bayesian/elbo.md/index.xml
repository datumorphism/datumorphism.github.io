<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>wiki/machine-learning/bayesian/elbo.md on Datumorphism</title><link>https://datumorphism.leima.is/links/wiki/machine-learning/bayesian/elbo.md/</link><description>Recent content in wiki/machine-learning/bayesian/elbo.md on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="https://datumorphism.leima.is/links/wiki/machine-learning/bayesian/elbo.md/index.xml" rel="self" type="application/rss+xml"/><item><title>Variational Auto-Encoder</title><link>https://datumorphism.leima.is/wiki/machine-learning/generative-models/variational-autoencoder/</link><pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/generative-models/variational-autoencoder/</guid><description>In an inference problem, $p(z\vert x)$, which is used to infer $z$ from $x$.
$$ p(z\vert x) = \frac{p(x, z)}{p(x)}. $$
For example, we have an observable $x$ and a latent space $z$, we would like to find a good latent space for the observable $x$. However, $p(x)$ is something we don&amp;rsquo;t really know. We would like to use some simpler quantities to help us inferring $z$ from $x$ or generating $x$ from $z$.
Now we introduce a simple distribution $q(z\vert x)$. We want to make sure this $q(z\vert x)$ is doing a good job of replacing $p(z\vert x)$, i.e., minimizing the [[KL divergence]] KL Divergence Kullbackâ€“Leibler divergence indicates the differences between two distributions ,</description></item><item><title>Diffusion Models for Forecasting</title><link>https://datumorphism.leima.is/wiki/machine-learning/energy-based-model/diffusion-model/</link><pubDate>Fri, 10 Feb 2023 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/energy-based-model/diffusion-model/</guid><description>Objective In a denoising diffusion model, given
an input $\mathbf x^0$ drawn from a complicated and unknown distribution $q(\mathbf x^0)$, we find
a latent space with a simple and manageable distribution, e.g., normal distribution, and the transformations from $\mathbf x^0$ to $\mathbf x^n$, as well as the transformations from $\mathbf x^n$ to $\mathbf x^0$. An Example For example, with $N=5$, the forward process is
flowchart LR x0 -- x1 -- x2 -- x3 -- x4 -- x5 and the reverse process is
flowchart LR x5 -- x4 -- x3 -- x2 -- x1 -- x0 The joint distribution we are searching for is</description></item></channel></rss>