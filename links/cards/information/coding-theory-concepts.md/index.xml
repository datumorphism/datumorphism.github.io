<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>cards/information/coding-theory-concepts.md on Datumorphism</title><link>https://datumorphism.leima.is/links/cards/information/coding-theory-concepts.md/</link><description>Recent content in cards/information/coding-theory-concepts.md on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="https://datumorphism.leima.is/links/cards/information/coding-theory-concepts.md/index.xml" rel="self" type="application/rss+xml"/><item><title>MDL and Neural Networks</title><link>https://datumorphism.leima.is/wiki/model-selection/mdl-and-neural-networks/</link><pubDate>Sun, 14 Feb 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/model-selection/mdl-and-neural-networks/</guid><description>Minimum Description Length ( MDL MDL is a measure of how well a model compresses data by minimizing the combined cost of the description of the model and the misfit. ) can be used to construct a concise network. A fully connected network has great expressing power but it is easily overfitting.
One strategy is to apply constraints to the networks:
Limit the connections; Shared weights in subgroups of the network; Constrain the weights using some probability distributions.</description></item></channel></rss>