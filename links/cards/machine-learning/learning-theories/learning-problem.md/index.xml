<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>cards/machine-learning/learning-theories/learning-problem.md on Datumorphism</title><link>https://datumorphism.leima.is/links/cards/machine-learning/learning-theories/learning-problem.md/</link><description>Recent content in cards/machine-learning/learning-theories/learning-problem.md on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="https://datumorphism.leima.is/links/cards/machine-learning/learning-theories/learning-problem.md/index.xml" rel="self" type="application/rss+xml"/><item><title>Machine Learning Overview</title><link>https://datumorphism.leima.is/wiki/machine-learning/overview/</link><pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/overview/</guid><description>What is Machine Learning There are many objectives in machine learning. Two of the most applied objectives are classifications and regressions. In classifications and regression, the following four factors are relevant.
A simple framework of machine learning. The dataset $\tilde{\mathscr D}$ is first encoded by $\mathscr T$, $\mathscr D(\mathbf X, \mathbf Y) = \mathscr T(\tilde{\mathscr D})$. The dataset is feeded into the model, $\bar{\mathbf Y} = f(\mathbf X;\mathbf \theta)$.</description></item><item><title>Cross Validation</title><link>https://datumorphism.leima.is/cards/machine-learning/learning-theories/cross-validation/</link><pubDate>Thu, 06 May 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/machine-learning/learning-theories/cross-validation/</guid><description>Cross validation is a method to estimate the risk The Learning Problem The learning problem posed by Vapnik:1 Given a sample: $\{z_i\}$ in the probability space $Z$; Assuming a probability measure on the probability space $Z$; Assuming a set of functions $Q(z, \alpha)$ (e.g. loss functions), where $\alpha$ is a set of parameters; A risk functional to be minimized by tunning &amp;ldquo;the handles&amp;rdquo; $\alpha$, $R(\alpha)$. The risk functional is $$ R(\alpha) = \int Q(z, \alpha) \,\mathrm d F(z).</description></item><item><title>ERM: Empirical Risk Minimization</title><link>https://datumorphism.leima.is/cards/machine-learning/learning-theories/empirical-risk-minimization/</link><pubDate>Thu, 18 Feb 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/machine-learning/learning-theories/empirical-risk-minimization/</guid><description>In a learning problem The Learning Problem The learning problem posed by Vapnik:1 Given a sample: $\{z_i\}$ in the probability space $Z$; Assuming a probability measure on the probability space $Z$; Assuming a set of functions $Q(z, \alpha)$ (e.g. loss functions), where $\alpha$ is a set of parameters; A risk functional to be minimized by tunning &amp;ldquo;the handles&amp;rdquo; $\alpha$, $R(\alpha)$. The risk functional is $$ R(\alpha) = \int Q(z, \alpha) \,\mathrm d F(z).</description></item><item><title>SRM: Structural Risk Minimization</title><link>https://datumorphism.leima.is/cards/machine-learning/learning-theories/structural-risk-minimization/</link><pubDate>Thu, 18 Feb 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/machine-learning/learning-theories/structural-risk-minimization/</guid><description>ERM ERM: Empirical Risk Minimization In a learning problem The Learning Problem The learning problem posed by Vapnik:1 Given a sample: $\{z_i\}$ in the probability space $Z$; Assuming a probability measure on the probability space $Z$; Assuming a set of functions $Q(z, \alpha)$ (e.g. loss functions), where $\alpha$ is a set of parameters; A risk functional to be minimized by tunning &amp;ldquo;the handles&amp;rdquo; $\alpha$, $R(\alpha)$. The risk functional is $$ R(\alpha) = \int Q(z, \alpha) \,\mathrm d F(z).</description></item></channel></rss>