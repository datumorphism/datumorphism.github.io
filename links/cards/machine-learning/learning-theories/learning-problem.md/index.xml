<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>cards/machine-learning/learning-theories/learning-problem.md on Datumorphism</title><link>https://datumorphism.leima.is/links/cards/machine-learning/learning-theories/learning-problem.md/</link><description>Recent content in cards/machine-learning/learning-theories/learning-problem.md on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="https://datumorphism.leima.is/links/cards/machine-learning/learning-theories/learning-problem.md/index.xml" rel="self" type="application/rss+xml"/><item><title>Machine Learning Overview</title><link>https://datumorphism.leima.is/wiki/machine-learning/overview/</link><pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/overview/</guid><description>What is Machine Learning In the core of machine learning models, we have three components1:
Representation: encode data and problem representation, i.e., propose a space to set a stage. Evaluation: an objective function to be evaluated that guides the model. Optimization: an algorithm to optimize the model so it learns what we want it to do. Table from Domingos2012
Machine Learning Workflow There are many objectives in machine learning.</description></item><item><title>Cross Validation</title><link>https://datumorphism.leima.is/cards/machine-learning/learning-theories/cross-validation/</link><pubDate>Thu, 06 May 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/machine-learning/learning-theories/cross-validation/</guid><description>Cross validation is a method to estimate the risk The Learning Problem The learning problem posed by Vapnik:1 Given a sample: $\{z_i\}$ in the probability space $Z$; Assuming a probability measure on the probability space $Z$; Assuming a set of functions $Q(z, \alpha)$ (e.g. loss functions), where $\alpha$ is a set of parameters; A risk functional to be minimized by tunning &amp;ldquo;the handles&amp;rdquo; $\alpha$, $R(\alpha)$. The risk functional is $$ R(\alpha) = \int Q(z, \alpha) \,\mathrm d F(z).</description></item><item><title>ERM: Empirical Risk Minimization</title><link>https://datumorphism.leima.is/cards/machine-learning/learning-theories/empirical-risk-minimization/</link><pubDate>Thu, 18 Feb 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/machine-learning/learning-theories/empirical-risk-minimization/</guid><description>In a learning problem The Learning Problem The learning problem posed by Vapnik:1 Given a sample: $\{z_i\}$ in the probability space $Z$; Assuming a probability measure on the probability space $Z$; Assuming a set of functions $Q(z, \alpha)$ (e.g. loss functions), where $\alpha$ is a set of parameters; A risk functional to be minimized by tunning &amp;ldquo;the handles&amp;rdquo; $\alpha$, $R(\alpha)$. The risk functional is $$ R(\alpha) = \int Q(z, \alpha) \,\mathrm d F(z).</description></item><item><title>SRM: Structural Risk Minimization</title><link>https://datumorphism.leima.is/cards/machine-learning/learning-theories/structural-risk-minimization/</link><pubDate>Thu, 18 Feb 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/machine-learning/learning-theories/structural-risk-minimization/</guid><description>ERM ERM: Empirical Risk Minimization In a learning problem The Learning Problem The learning problem posed by Vapnik:1 Given a sample: $\{z_i\}$ in the probability space $Z$; Assuming a probability measure on the probability space $Z$; Assuming a set of functions $Q(z, \alpha)$ (e.g. loss functions), where $\alpha$ is a set of parameters; A risk functional to be minimized by tunning &amp;ldquo;the handles&amp;rdquo; $\alpha$, $R(\alpha)$. The risk functional is $$ R(\alpha) = \int Q(z, \alpha) \,\mathrm d F(z).</description></item></channel></rss>