<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>cards/machine-learning/neural-networks/mcculloch-pitts-model.md on Datumorphism</title><link>/links/cards/machine-learning/neural-networks/mcculloch-pitts-model.md/</link><description>Recent content in cards/machine-learning/neural-networks/mcculloch-pitts-model.md on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="/links/cards/machine-learning/neural-networks/mcculloch-pitts-model.md/index.xml" rel="self" type="application/rss+xml"/><item><title>Rosenblatt's Perceptron</title><link>/cards/machine-learning/neural-networks/rosenblatt-perceptron/</link><pubDate>Thu, 25 Feb 2021 00:00:00 +0000</pubDate><guid>/cards/machine-learning/neural-networks/rosenblatt-perceptron/</guid><description>Rosenblatt&amp;rsquo;s perceptron connects McCulloch-Pitts neurons in levels.
Rosenblatt proprosed that we fix all the weights and leave the weights of the last neuron free.
The first few layers but the last layer is used as a transformation of the input data ${x_1, \cdots, x_i, \cdots, x_N}$ into a new space ${z_1, \cdots, z_i, \cdots, z_{N&amp;rsquo;}}$. The classification is done on the ${z_1, \cdots, z_i, \cdots, z_{N&amp;rsquo;}}$ space by tuning the last neuron.</description></item></channel></rss>