<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>cards/statistics/fia.md on Datumorphism</title><link>/links/cards/statistics/fia.md/</link><description>Recent content in cards/statistics/fia.md on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="/links/cards/statistics/fia.md/index.xml" rel="self" type="application/rss+xml"/><item><title>Minimum Description Length</title><link>/cards/statistics/mdl/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/cards/statistics/mdl/</guid><description>The minimum description length ( #MDL ) is based on the idea of compression of the data.
MDL looks for the model that compresses the data well. To compress data, we need to find the regularity in the data.
There are many versions of MDL.
crude two-part code Fisher information approximation ( # FIA ) Normalized Maximum likelihood ( #NML )</description></item><item><title>Model Comparison</title><link>/wiki/model-selection/model-selection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/wiki/model-selection/model-selection/</guid><description>The parsimony model comes from the idea of Occam&amp;rsquo;s razor: We choose the simple model that has more explanatory power.
The instance theory is a good model to explain the lexical decision task but it is not the only one. However, it simply makes it popular.
What is a Good Model? A good model should be presumably
plausibility balance of parsimony and goodness-of-fit coherence of the underlying assumptions easy to understand when it breaks down consistency with known results especially with the simple and basic phenomena ability to explain rather than describe data extent to which model predictions can be falsified through experiments.</description></item></channel></rss>