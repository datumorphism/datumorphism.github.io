<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>reading/normalizing-flow-introduction-1908.09257.md on Datumorphism</title><link>https://datumorphism.leima.is/links/reading/normalizing-flow-introduction-1908.09257.md/</link><description>Recent content in reading/normalizing-flow-introduction-1908.09257.md on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="https://datumorphism.leima.is/links/reading/normalizing-flow-introduction-1908.09257.md/index.xml" rel="self" type="application/rss+xml"/><item><title>Generative Model: Normalizing Flow</title><link>https://datumorphism.leima.is/wiki/machine-learning/generative-models/flow/</link><pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/machine-learning/generative-models/flow/</guid><description>Normalizing flow is a method to convert a complicated distribution $p(x)$ to a simpler distribution $\tilde p(z)$ by building up a map $z=f(y)$ for the variable $x$ to $z$. The relations between the two distributions is established using the conservation law for distributions, $\int p(x) \mathrm d x = \int \tilde p (z) \mathrm d z = 1$. One could imagine that changing the variable also brings in the Jacobian.
Liu X, Zhang F, Hou Z, Wang Z, Mian L, Zhang J, et al. Self-supervised Learning: Generative or Contrastive. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2006.08218
Normalizing Flows: An Introduction and Review of Current Methods To generate complicated distributions step by step from a simple and interpretable distribution.</description></item></channel></rss>