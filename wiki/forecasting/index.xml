<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Forecasting on Datumorphism</title><link>https://datumorphism.leima.is/wiki/forecasting/</link><description>Recent content in Forecasting on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Sun, 24 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://datumorphism.leima.is/wiki/forecasting/index.xml" rel="self" type="application/rss+xml"/><item><title>The Time Series Forecasting Problem</title><link>https://datumorphism.leima.is/wiki/forecasting/forecasting-problem/</link><pubDate>Sun, 24 Apr 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/forecasting/forecasting-problem/</guid><description>Forecasting Problem A time series forecasting problem can be formulated as the following.
Given a dataset $\mathcal D$, with
$y^{(i)}_t$, the sequential variable to be forecasted, $x^{(i)}_t$, exogenous data for the time series data, $u^{(i)}_t$, some features that can be obtained or planned in advance, where ${}^{(i)}$ indicates the $i$th variable, ${}_ t$ denotes time. In a forecasting task, we use $y^{(i)} _ {t-K:t}$, $x^{(i) _ {t-K:t}}$, and $u^{(i)} _ {t-K:t+H}$, to forecast the future $y^{(i)} _ {t+1:t+H}$.
A model $f$ will use $x^{(i)} _ {t-K:t}$ and $u^{(i)} _ {t-K:t+H}$ to forecast $y^{(i)} _ {t+1:t+H}$.
The Time Delay Embedding Representation The time delay embedding representation of a time series forecasting problem is a concise representation of the forecasting problem.</description></item><item><title>Time Series Forecasting with Deep Learning</title><link>https://datumorphism.leima.is/wiki/forecasting/forecasting-with-deep-learning/</link><pubDate>Sun, 24 Apr 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/forecasting/forecasting-with-deep-learning/</guid><description>The Encoder-Decoder Framework Many of the models for [[time series forecasting]] The Time Series Forecasting Problem Forecasting time series using deep learning are following some sort of encoder-decoder architecture.
Encoder: $g_{\text{enc}}(x^{(i)} _ {t-K:t}, u^{(i)} _ {t-K:t}) \to z_t$, Decoder: $g_{\text{dec}}(z_t, u^{(i)} _ {t+1: t+H}) \to y_{t+1:t+H}$.</description></item><item><title>Evaluating Time Series Models</title><link>https://datumorphism.leima.is/wiki/forecasting/evalutate-time-series-models/</link><pubDate>Fri, 08 Apr 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/forecasting/evalutate-time-series-models/</guid><description>Evaluating time series models is usually different from most other machine learning tasks as we usually don&amp;rsquo;t have i.i.d. data.
Out-of-sample Out-of-Sample with Sliding Window
If the sliding window size is 1, then we have the simplest out-of-sample holdout scenario.
Prequential Prequential with Gap
Prequential with Growing Train
Prequential with Sliding Blocks
Cross-validation Cross-validation
Cross-validation with Neighbor removed</description></item></channel></rss>