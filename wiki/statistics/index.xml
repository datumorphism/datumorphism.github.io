<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Statistics on Datumorphism</title><link>https://datumorphism.leima.is/wiki/statistics/</link><description>Recent content in Statistics on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Sun, 07 Mar 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://datumorphism.leima.is/wiki/statistics/index.xml" rel="self" type="application/rss+xml"/><item><title>What is Statistics</title><link>https://datumorphism.leima.is/wiki/statistics/what-is-statistics/</link><pubDate>Fri, 18 Jan 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/statistics/what-is-statistics/</guid><description>A Case Study We have a problem.
In our lab, we found a huge amount of similar robots on a planet (physical population). To know more about the weight of these robots (statistical population), we first need to choose some of them (physical sample), then obtain the weight of them (statistical sample).
To describe the data, we could calculate the mean of the weight. We found that the mean weight is 93kg (descriptive statistics).
We could simply give a number to standard for the mean weight of all the robots. (point estimate) We could tell a number as the mean weight of all the robots together with a range that tells us how disperse our measurement is.</description></item><item><title>Jargons</title><link>https://datumorphism.leima.is/wiki/statistics/jargons/</link><pubDate>Sat, 24 Nov 2018 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/statistics/jargons/</guid><description>Accuracy and Precision Accuracy: the measurement compared to the truth Precision: variability of repeated measurements; the more precise, the less variations during each measurement. Accurate Inaccurate Precise Close to true value, small variations in each measurement Far from true value, small variations in each measurement Imprecise Close to true value, large variations in each measurement Far from true value, large variations in each measurement Here is an example. Suppose we have a huge population (with true mean $M_0$) and we draw samples from it. For the first time, we have sample $S_1$.</description></item><item><title>Chi-square Correlation Test for Nominal Data</title><link>https://datumorphism.leima.is/wiki/statistics/correlation-analysis-chi-square/</link><pubDate>Sun, 18 Nov 2018 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/statistics/correlation-analysis-chi-square/</guid><description>In this article, we will discuss the chi-square correlation test for detecting correlations between two series.
Steps Find out all the possible values of the two nominal series A and B; Count the co-occurrences of the combinations (A, B); Calculate the expected co-occurrences of the combinations (A, B); Calculate chi-square; Determine whether the hypothesis can be rejected. Define the Series Suppose we are analyzing two series A and B. Series A can take values $a_1$ and $a_2$, while series B can take values $b_1$ , $b_2$ and $b_3$.
$$ \begin{align} A &amp;:= \{a1, a2\} \\ B &amp;:= \{b1,b2,b3\} \end{align} $$</description></item><item><title>Correlation Coefficient and Covariance for Numeric Data</title><link>https://datumorphism.leima.is/wiki/statistics/correlation-coefficient/</link><pubDate>Sun, 18 Nov 2018 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/statistics/correlation-coefficient/</guid><description>Covariances Correlation coefficient is also known as the Pearson&amp;rsquo;s product moment coefficient. Review of Standard Deviation For a series of data A, we have the standard deviations
$$ \sigma_A = \sqrt{ \frac{ \sum (a_i - \bar A)^2 }{ n } }, $$
where $n$ is the number of elements in series A.
The standard deviation is very easy to understand. It is basically the average Eucleadian distance between the data points and the average value. In this article, we will take another point of view.
Now imagine we have two series $(a_i - \bar A)$ and $(a_j - \bar A)$.</description></item><item><title>Normalization Methods for Numeric Data</title><link>https://datumorphism.leima.is/wiki/statistics/normalization-methods/</link><pubDate>Sun, 18 Nov 2018 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/statistics/normalization-methods/</guid><description>Normalization of data is critical for statistical analysis and feature engineering.
Min-max Normalization This method is linear and straightforward.
Suppose we are analyzing series A, with elements $a_i$. We already know the min and max of the series, $a_{min}$ and $a_{max}$.
Now we would like to normalize the series to be within the range $[a_{min}', a_{max}']$. We simply solve the value of $a' _ i$ in $$ \frac{(a'i - a{min}')}{ ( a'{max} - a'{min} ) } = \frac{(a_i - a_{min})}{ ( a_{max} - a_{min} ) }, $$ where everything on the right hand side is known and $a_{min}'$ and $a_{max}'$ are chosen as the new min and max to be scaled to.</description></item><item><title>Linear Regression</title><link>https://datumorphism.leima.is/wiki/statistics/linear-regression/</link><pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/statistics/linear-regression/</guid><description>In this article, we will use the Einstein summation convention. For example, $$ X_{ij}\beta_ j $$ is equivalent to $$ \sum_j X_{ij}\beta_ j $$ In statistics, we have at least three categories of quantities:
data and labels abstract theoretical quantities parameters and predictions of models The convention is that quantities with $\hat {}$ are the model quantities. Sometimes we do not distinguish the abstract theoretical quantities and model quantities.
If it is necessary to use different notations for the abstract theoretical quantities and the model quantities, we would use bold symbols ($\mathbf Y$) or latin sub/super indices ( $Y_a$ ) for theoretical quantities and greek letters ( $Y_\alpha$ ) for model quantities.</description></item><item><title>Describing Multi-dimensional Data</title><link>https://datumorphism.leima.is/wiki/statistics/multidimensional-data/</link><pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/statistics/multidimensional-data/</guid><description>Descriptions of Multidimensional Data Dispersion Matrix As defined in Correlation Coefficient and Covariance for Numeric Data, covariance is about the variance of two series. This property makes it easy to generalize it to multidimensional data.
The generalized quantity is named as dispersion matrix. Suppose we have a $p$ dimensional dataset $X$,
index $x_1$ $x_2$ &amp;hellip; $x_p$ 1 2.3 12.3 83.2 9.3 &amp;hellip; &amp;hellip; &amp;hellip; &amp;hellip; &amp;hellip; N 3.1 5.6 23.6 8.2 We could then calculate the pairwise covariance between the different dimensions.
$x_1$ $x_2$ &amp;hellip; $x_p$ $x_1$ $x_2$ &amp;hellip; $x_p$</description></item><item><title>ANOVA</title><link>https://datumorphism.leima.is/wiki/statistics/anova/</link><pubDate>Sun, 07 Mar 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/statistics/anova/</guid><description>In many problems, we have to test if several distributions associated with several groups of experiments are the same. The null hypothesis to be used is
The distributions of several groups are the same.
ANOVA tests the null hypothesis by comparing the variability between groups and within groups. If the variability between groups are significantly larger than the variability within groups, we are more confident that the distributions of different groups are different.
We will use two-group experiments as an example. We use a fake dataset:
Group A $x^A_1$ $x^A_2$ &amp;hellip; $x^A_{N_A}$ Group B $x^B_1$ $x^B_2$ &amp;hellip; $x^B_{N_B}$ Within Group Variability The within group variability is proportional to</description></item></channel></rss>