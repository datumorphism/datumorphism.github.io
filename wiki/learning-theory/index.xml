<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Learning Theory on Datumorphism</title><link>https://datumorphism.leima.is/wiki/learning-theory/</link><description>Recent content in Learning Theory on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Sun, 21 Feb 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://datumorphism.leima.is/wiki/learning-theory/index.xml" rel="self" type="application/rss+xml"/><item><title>VC Dimension</title><link>https://datumorphism.leima.is/wiki/learning-theory/vc-dimension/</link><pubDate>Sun, 21 Feb 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/learning-theory/vc-dimension/</guid><description>Two of the key elements in a learning problem are:
a set of hypothesis $\mathcal H$, and a set of data samples $\mathcal S$. $\mathcal H$
Inside $\mathcal H$, we have a lot of hypotheses, for example, $\mathcal h$. Given some input, e.g., $x_1$ and $x_2$, we can produce some outputs, e.g., $h(x_1)$ and $h(x_2)$. $\mathcal S$
A sample $\mathcal S$ is a fair sample drawn from all the possible inputs $\mathcal X$, where $\mathcal X$ is called the input space. A dataset $\mathcal S$ can be used as a probe of the hypothesis set $\mathcal H$.</description></item></channel></rss>