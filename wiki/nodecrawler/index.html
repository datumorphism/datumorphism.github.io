<!doctype html><html lang=en-us>
<head>
<meta name=generator content="Hugo 0.89.4">
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1">
<title>Node Crawler | Datumorphism | L Ma </title>
<meta name=description content="Write a crawler using nodejs">
<meta name=robots content="noindex">
<meta name=author content="L Ma">
<meta property="og:title" content="Node Crawler">
<meta property="og:description" content="Write a crawler using nodejs">
<meta property="og:type" content="website">
<meta property="og:url" content="https://datumorphism.leima.is/wiki/nodecrawler/">
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-140452515-1','auto'),ga('send','pageview'))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
<link href=https://datumorphism.leima.is/wiki/nodecrawler/index.xml rel=alternate type=application/rss+xml title=Datumorphism>
<link rel=canonical href=https://datumorphism.leima.is/wiki/nodecrawler/> <link rel="shortcut icon" type=image/png href=/logos/logo-square.png>
<link rel=stylesheet href=/css/bulma.css>
<link rel=stylesheet href=/css/bulma-divider.min.css>
<link rel=stylesheet href=/assets/css/bulma-ribbon.min.css>
<link rel=stylesheet href=/assets/css/tooltip.css>
<link rel=stylesheet href=https://jenil.github.io/bulmaswatch/united/bulmaswatch.min.css>
<link rel=stylesheet href=/css/custom.css>
<script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],tags:'ams',processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:['script','noscript','style','textarea','pre']},svg:{fontCache:'global'}},window.addEventListener('load',a=>{document.querySelectorAll("mjx-container").forEach(function(a){a.parentElement.classList+='has-jax'})})</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script>
<script>mermaid.initialize({startOnLoad:!0})</script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/js/all.min.js integrity="sha256-KzZiKy0DWYsnwMF+X1DvQngQ2/FxF7MF3Ff72XcpuPs=" crossorigin=anonymous></script>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin=anonymous>
</head>
<body>
<header> <nav class="navbar is-transparent">
<div class=navbar-brand>
<a class=navbar-item href=/>
<img src=/site/intelligence.png alt=Datumorphism height=28 style=margin-right:.5em> Datumorphism
</a>
<div class="navbar-burger burger" style=color:#000 data-target=navMenu>
<span></span>
<span></span>
<span></span>
</div>
</div>
<div class=navbar-menu id=navMenu>
<div class=navbar-start>
<div class="navbar-item has-dropdown is-hoverable">
<a href=/projects class=navbar-link>
Notebooks
</a>
<div class=navbar-dropdown>
<a href=https://datumorphism.leima.is/awesome/ class=navbar-item>
Awesome
</a>
<a href=https://datumorphism.leima.is/blog/ class=navbar-item>
Blog
</a>
<a href=https://datumorphism.leima.is/cards/ class=navbar-item>
Cards
</a>
<a href=https://datumorphism.leima.is/hologram/ class=navbar-item>
Hologram
</a>
<a href=https://datumorphism.leima.is/reading/ class=navbar-item>
Reading Notes
</a>
<a href=https://datumorphism.leima.is/til/ class=navbar-item>
TIL
</a>
<a href=https://datumorphism.leima.is/wiki/ class=navbar-item>
Wiki
</a>
</div>
</div>
<div class="navbar-item has-dropdown is-hoverable">
<a class=navbar-item href=https://neuronstar.kausalflow.com/cpe-docs/>
Probability Estimation
</a>
</div>
</div>
<span class=navbar-burger>
<span></span>
<span></span>
<span></span>
</span>
<div class=navbar-end>
<div class=navbar-item>
<a class=navbar-item href=/blog/>
Blog
</a>
<a class=navbar-item href=/amneumarkt/>
AmNeumarkt
</a>
<a class=navbar-item href=/>
<i class="fas fa-search"></i>
</a>
<a class=navbar-item href=/tags/>
<i class="fas fa-tags"></i>
</a>
<a class=navbar-item href=/graph>
<i class="fas fa-project-diagram"></i>
</a>
<a class=navbar-item href=https://t.me/amneumarkt>
<i class="fab fa-telegram"></i>
</a>
<a class=navbar-item target=blank href=https://github.com/datumorphism>
<span class=icon>
<i class="fab fa-github"></i>
</span>
</a>
</div>
</div>
</div>
</nav>
<script>document.addEventListener('DOMContentLoaded',()=>{const a=Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'),0);a.length>0&&a.forEach(a=>{a.addEventListener('click',()=>{const b=a.dataset.target,c=document.getElementById(b);a.classList.toggle('is-active'),c.classList.toggle('is-active')})})})</script> </header>
<main>
<section>
<div class="hero is-primary is-medium">
<div class=hero-body>
<div class="container has-text-centered">
<h1 class="title is-1">
Node Crawler
</h1>
<h2 class="subtitle is-3">
Write a crawler using nodejs
</h2>
</div>
</div>
</div>
</section>
<div class="columns is-fullheight">
<div class=column>
<section class="hero is-default is-bold">
<div class=hero-body>
<div class=container>
<nav class="breadcrumb has-succeeds-separator is-small" aria-label=breadcrumbs>
<ul>
<li>
<a href=https://datumorphism.leima.is/>Datumorphism</a>
</li>
<li>
<a href=https://datumorphism.leima.is/wiki/>Wiki</a>
</li>
<li class=active>
<a href=https://datumorphism.leima.is/wiki/nodecrawler/>Node Crawler</a>
</li>
</ul>
</nav>
<div class="columns is-multiline is-variable is-1-mobile is-0-tablet is-3-desktop is-8-widescreen is-2-fullhd is-desktop">
<div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork>
<h1 class=blog-timestamp>
</h1>
<h1 class=title>
<sup>5</sup> <a href=https://datumorphism.leima.is/wiki/nodecrawler/optimization/ itemprop=headline> Optimization</a>
</h1>
<div style=margin-left:2em>
<span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>
Published: <time datetime=2018-07-19T00:00:00+00:00>2018-07-19</time>
</span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i> Category: { Node Crawler }
</span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i> Tags: <div class="tags is-small" style=display:inline>
<a href=/tags/node style=margin-right:.5em><span class="tag is-warning is-small is-light">#Node</span></a>
<a href=/tags/crawler style=margin-right:.5em><span class="tag is-warning is-small is-light">#Crawler</span></a>
</div>
</span>
</div>
<div style=margin-left:2em><span style=display:block;font-size:90%>
<i class="fa fa-paperclip" aria-hidden=true></i> References:</span>
<span style=display:block;font-size:90%;padding-left:1em> - <a href=https://nintha.github.io/2018/07/10/node_spider_compass/05-lite_optimization/>05-微小的优化@ninthakeey</a></span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%>
<i class="far fa-star"></i> Summary: In this article, we will be optimizing the crawler to get better performance.
Batch Jobs In the article about using MongoDB as data storage, we write the data to database whenever we get it. In practice, this is not efficient at all. Here comes the batch jobs. It would be much better if one write to database with batch jobs.
If you recall, the code we used to write to database is
// ...other code localdb.test.save(data, (err, res)=>{ // do something }) The function save takes in not only one entry of document but an array of documents:
const array = [] for(let i = INI_ID ; i &lt; MAX_ID; i++){ // fetch data from website const data = fetchData(i) array.</span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%>
<i class="far fa-list-alt"></i> Pages: 5</span>
</div>
</div>
<div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div>
<div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork>
<h1 class=blog-timestamp>
</h1>
<h1 class=title>
<sup>4</sup> <a href=https://datumorphism.leima.is/wiki/nodecrawler/restrictions/ itemprop=headline> Restrictions of Websites</a>
</h1>
<div style=margin-left:2em>
<span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>
Published: <time datetime=2018-07-19T00:00:00+00:00>2018-07-19</time>
</span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i> Category: { Node Crawler }
</span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i> Tags: <div class="tags is-small" style=display:inline>
<a href=/tags/node style=margin-right:.5em><span class="tag is-warning is-small is-light">#Node</span></a>
<a href=/tags/crawler style=margin-right:.5em><span class="tag is-warning is-small is-light">#Crawler</span></a>
</div>
</span>
</div>
<div style=margin-left:2em><span style=display:block;font-size:90%>
<i class="fa fa-paperclip" aria-hidden=true></i> References:</span>
<span style=display:block;font-size:90%;padding-left:1em> - <a href=https://nintha.github.io/2018/07/08/node_spider_compass/04-against_website_limitation/>04-应对网站的限制@ninthakeey</a></span>
<span style=display:block;font-size:90%;padding-left:1em> - <a href=https://medium.com/platformer-blog/node-js-concurrency-with-async-await-and-promises-b4c4ae8f4510>Node.JS Concurrency with Async/Await and Promises!</a></span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%>
<i class="far fa-star"></i> Summary: Beware that scraping data off websites is neither always allowed nor as easy as a few lines of code. The preceding articles enable you to scrape many data, however, man websites have counter measures. In this article, we will be dealing with some of the common ones.
Request Frequency Some websites have limitations on the frequency of API requests. The solution to this is simply a brief pause after each request. In Node.js, the function setInterval enables this.
// ... require packages here // define the function fetch to get data const fetch = (aid) => superagent .get('https://api.bilibili.com/x/web-interface/archive/stat') .query({ aid:aid }) .</span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%>
<i class="far fa-list-alt"></i> Pages: 5</span>
</div>
</div>
<div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div>
<div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork>
<h1 class=blog-timestamp>
</h1>
<h1 class=title>
<sup>3</sup> <a href=https://datumorphism.leima.is/wiki/nodecrawler/manage-data-using-mongodb/ itemprop=headline> Manage Data Using MongoDB</a>
</h1>
<div style=margin-left:2em>
<span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>
Published: <time datetime=2018-07-18T00:00:00+00:00>2018-07-18</time>
</span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i> Category: { Node Crawler }
</span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i> Tags: <div class="tags is-small" style=display:inline>
<a href=/tags/node style=margin-right:.5em><span class="tag is-warning is-small is-light">#Node</span></a>
<a href=/tags/crawler style=margin-right:.5em><span class="tag is-warning is-small is-light">#Crawler</span></a>
</div>
</span>
</div>
<div style=margin-left:2em><span style=display:block;font-size:90%>
<i class="fa fa-paperclip" aria-hidden=true></i> References:</span>
<span style=display:block;font-size:90%;padding-left:1em> - <a href=https://nintha.github.io/2018/07/08/node_spider_compass/03-save_into_db/>03-保存数据到数据库@ninthakeey</a></span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%>
<i class="far fa-star"></i> Summary: In most cases, databases makes the management of data quite convenient. In this article, we would scrape data using the code we discussed before but write data into MongoDB.
For installation of MongoDB, please refer to the official documentation.
The Code To write data to MongoDB using Node.js, we choose the package mongojs, which provides almost exactly the standard MongoDB syntax.
To install mongojs,
npm i mongojs --save Here is a module that can write data to MongoDB. We create a file named dao.js and copy/paste the following code into it.
// use mongojs const mongojs = require('mongojs') // connect to the database 'simple_spider' in MongoDB and use collection 'test' const localdb = mongojs('simple_spider', ['test']) // a function that saves data to MongoDB const saveData = (data,cb) => { localdb.</span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%>
<i class="far fa-list-alt"></i> Pages: 5</span>
</div>
</div>
<div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div>
<div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork>
<h1 class=blog-timestamp>
</h1>
<h1 class=title>
<sup>2</sup> <a href=https://datumorphism.leima.is/wiki/nodecrawler/basic-crawler/ itemprop=headline> Basic Node Crawler</a>
</h1>
<div style=margin-left:2em>
<span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>
Published: <time datetime=2018-07-15T00:00:00+00:00>2018-07-15</time>
</span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i> Category: { Node Crawler }
</span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i> Tags: <div class="tags is-small" style=display:inline>
<a href=/tags/node style=margin-right:.5em><span class="tag is-warning is-small is-light">#Node</span></a>
<a href=/tags/crawler style=margin-right:.5em><span class="tag is-warning is-small is-light">#Crawler</span></a>
</div>
</span>
</div>
<div style=margin-left:2em><span style=display:block;font-size:90%>
<i class="fa fa-paperclip" aria-hidden=true></i> References:</span>
<span style=display:block;font-size:90%;padding-left:1em> - <a href=https://nintha.github.io/2018/07/08/node_spider_compass/02-impl_a_simple_spider/>02-实现一个简单的爬虫@ninthakeey</a></span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%>
<i class="far fa-star"></i> Summary: Prerequisites Nodejs >= 8.9 Overview A model for a crawler is as follows.
A crawler requests data from the server, while the server responds with some data. Here is a graphic illustration
+----------+ +-----------+ | | HTTP Request | | | +----------------> | | Nodejs | | Servers | | &lt;----------------+ | | | HTTP Response | | +----------+ +-----------+ HTTP Requests For a good introduction of HTTP requests, please refer to this video on youtube: Explained HTTP, HTTPS, SSL/TLS API As for the first step, we need to find which url to request.</span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%>
<i class="far fa-list-alt"></i> Pages: 5</span>
</div>
</div>
<div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div>
<div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork>
<h1 class=blog-timestamp>
</h1>
<h1 class=title>
<sup>1</sup> <a href=https://datumorphism.leima.is/wiki/nodecrawler/node-crawler-introduction/ itemprop=headline> Introduction to Node Crawler Series</a>
</h1>
<div style=margin-left:2em>
<span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>
Published: <time datetime=2018-07-15T00:00:00+00:00>2018-07-15</time>
</span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%><i class="far fa-folder" aria-hidden=true></i> Category: { Node Crawler }
</span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i> Tags: <div class="tags is-small" style=display:inline>
<a href=/tags/node style=margin-right:.5em><span class="tag is-warning is-small is-light">#Node</span></a>
<a href=/tags/crawler style=margin-right:.5em><span class="tag is-warning is-small is-light">#Crawler</span></a>
</div>
</span>
</div>
<div style=margin-left:2em><span style=display:block;font-size:90%>
<i class="fa fa-paperclip" aria-hidden=true></i> References:</span>
<span style=display:block;font-size:90%;padding-left:1em> - <a href=https://nintha.github.io/2018/07/08/node_spider_compass/01-base_env/>01-基础环境搭建@ninthakeey</a></span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%>
<i class="far fa-star"></i> Summary: Installing node.js and mongodb.</span>
</div>
<div style=margin-left:2em>
<span style=display:block;font-size:90%>
<i class="far fa-list-alt"></i> Pages: 5</span>
</div>
</div>
<div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div>
</div>
</div>
<br>
<div class=container>
</div>
</div>
</section>
</div>
</div>
</main>
<footer>
<footer class=footer>
<div class=container>
<div class="content has-text-centered">
<p>
Created and maintained by <a href=https://leima.is>L Ma</a>.
Acknowledgement: <a href=https://gohugo.io/>Hugo</a>,
<a href=https://themes.gohugo.io/bulma/>Bulma</a>, <a href=https://kausalflow.com>KausalFlow</a>.
<strong>love</strong>.
<br>
<a class=tag href=/about>About</a>
<a class=tag href=/index.xml>Feed</a>
<a class=tag href=/data.json>JSON Data</a>
</p>
</div>
</div>
</footer>
</footer>
<script async type=text/javascript src=/js/bulma.js></script>
</body>
</html>