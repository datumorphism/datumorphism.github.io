<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.69.2"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Generative Model: Variational Auto-Encoder | Datumorphism | Lei Ma</title><meta name=author content="Lei Ma"><meta property="og:title" content="Generative Model: Variational Auto-Encoder"><meta property="og:description" content="Variational Auto-Encoder (VAE) is very different from Generative Model: Auto-Encoder  Generative Model: Auto-Encoder The simplest auto-encoder is rather simple. The loss can be chosen based on the demand, e.g., cross entropy for binary labels.   . In VAE, we introduce a variational distribution $q$ to help us work out the weighted integral after introducing the latent space variable $z$,
$$ \begin{align} \ln p_\theta(x) &= \ln \int p_\theta (x\mid z) p(z) \,\mathrm d z \\ &= \ln \int \frac{q_{\phi}(z\mid x)}{q_{\phi}(z\mid x)} p_\theta (x\mid z) p(z) \, \mathrm d z\\ & \geq - \left[ D_{\mathrm{KL}} ( q_{\phi}(z\mid x) \mathrel{\Vert} p(z) ) - \mathbb E_q ( \ln p_\theta (x\mid z) ) \right] \\ &\equiv - F(x)."><meta property="og:type" content="article"><meta property="og:url" content="https://datumorphism.leima.is/wiki/machine-learning/self-supervised-learning/generative-variational-autoencoder/"><meta property="article:published_time" content="2021-08-13T00:00:00+00:00"><meta property="article:modified_time" content="2021-08-13T00:00:00+00:00"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-140452515-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><link rel=canonical href=https://datumorphism.leima.is/wiki/machine-learning/self-supervised-learning/generative-variational-autoencoder/><link rel="shortcut icon" type=image/png href=/logos/logo-square.png><link rel=stylesheet href=/css/bulma.css><link rel=stylesheet href=/css/bulma-divider.min.css><link rel=stylesheet href=/assets/css/bulma-ribbon.min.css><link rel=stylesheet href=/assets/css/tooltip.css><link rel=stylesheet href=https://jenil.github.io/bulmaswatch/united/bulmaswatch.min.css><link rel=stylesheet href=/css/custom.css><link rel=stylesheet href=/css/blog-post.css><link rel=stylesheet href=/css/code-highlighting/dark.css><link rel=stylesheet href=/css/custom.css><link rel=stylesheet href=https://unpkg.com/applause-button/dist/applause-button.css><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],tags:'ams',processEscapes:true,processEnvironments:true},options:{skipHtmlTags:['script','noscript','style','textarea','pre']},svg:{fontCache:'global'}};window.addEventListener('load',(event)=>{document.querySelectorAll("mjx-container").forEach(function(x){x.parentElement.classList+='has-jax'})});</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>mermaid.initialize({startOnLoad:true});</script><script src=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/js/all.min.js integrity="sha256-KzZiKy0DWYsnwMF+X1DvQngQ2/FxF7MF3Ff72XcpuPs=" crossorigin=anonymous></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin=anonymous></head><body><header><nav class="navbar is-transparent"><div class=navbar-brand><a class=navbar-item href=/><img src=/site/intelligence.png alt=Datumorphism height=28 style=margin-right:.5em> Datumorphism</a><div class="navbar-burger burger" style=color:#000 data-target=navMenu><span></span><span></span><span></span></div></div><div class=navbar-menu id=navMenu><div class=navbar-start><div class="navbar-item has-dropdown is-hoverable"><a href=/projects class=navbar-link>Notebooks</a><div class=navbar-dropdown><a href=https://datumorphism.leima.is/awesome/ class=navbar-item>Awesome</a>
<a href=https://datumorphism.leima.is/blog/ class=navbar-item>Blog</a>
<a href=https://datumorphism.leima.is/cards/ class=navbar-item>Cards</a>
<a href=https://datumorphism.leima.is/hologram/ class=navbar-item>Hologram</a>
<a href=https://datumorphism.leima.is/reading/ class=navbar-item>Reading Notes</a>
<a href=https://datumorphism.leima.is/til/ class=navbar-item>TIL</a>
<a href=https://datumorphism.leima.is/wiki/ class=navbar-item>Wiki</a></div></div></div><span class=navbar-burger><span></span><span></span><span></span></span><div class=navbar-end><div class=navbar-item><a class=navbar-item href=/blog/>Blog</a>
<a class=navbar-item href=/><i class="fas fa-search"></i></a><a class=navbar-item href=/tags/><i class="fas fa-tags"></i></a><a class=navbar-item href=/graph><i class="fas fa-project-diagram"></i></a><a class=navbar-item href=https://t.me/amneumarkt><i class="fab fa-telegram"></i></a><a class=navbar-item target=blank href=https://github.com/datumorphism><span class=icon><i class="fab fa-github"></i></span></a></div></div></div></nav><script>document.addEventListener('DOMContentLoaded',()=>{const $navbarBurgers=Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'),0);if($navbarBurgers.length>0){$navbarBurgers.forEach(el=>{el.addEventListener('click',()=>{const target=el.dataset.target;const $target=document.getElementById(target);el.classList.toggle('is-active');$target.classList.toggle('is-active');});});}});</script></header><main><div class=container itemscope itemtype=http://schema.org/BlogPosting><meta itemprop=name content="Generative Model: Variational Auto-Encoder"><meta itemprop=description content="Variational Auto-Encoder (VAE) is very different from Generative Model: Auto-Encoder  Generative Model: Auto-Encoder The simplest auto-encoder is rather simple. The loss can be chosen based on the demand, e.g., cross entropy for binary labels.   . In VAE, we introduce a variational distribution $q$ to help us work out the weighted integral after introducing the latent space variable $z$,
$$ \begin{align} \ln p_\theta(x) &= \ln \int p_\theta (x\mid z) p(z) \,\mathrm d z \\ &= \ln \int \frac{q_{\phi}(z\mid x)}{q_{\phi}(z\mid x)} p_\theta (x\mid z) p(z) \, \mathrm d z\\ & \geq - \left[ D_{\mathrm{KL}} ( q_{\phi}(z\mid x) \mathrel{\Vert} p(z) ) - \mathbb E_q ( \ln p_\theta (x\mid z) ) \right] \\ &\equiv - F(x)."><meta itemprop=datePublished content="2021-08-13T00:00:00+00:00"><meta itemprop=dateModified content="2021-08-13T00:00:00+00:00"><meta itemprop=wordCount content="294"><meta itemprop=keywords content="Self-supervised Learning,Generative Model,VAE,Basics,"><section class=section><div class=container><article class=post><header class=post-header><nav class="breadcrumb has-succeeds-separator is-small" aria-label=breadcrumbs><ul><li><a href=https://datumorphism.leima.is/>Datumorphism</a></li><li><a href=https://datumorphism.leima.is/wiki/>Wiki</a></li><li><a href=https://datumorphism.leima.is/wiki/machine-learning/>Machine Learning</a></li><li><a href=https://datumorphism.leima.is/wiki/machine-learning/self-supervised-learning/>Self-supervised Learning</a></li><li class=active><a href=https://datumorphism.leima.is/wiki/machine-learning/self-supervised-learning/generative-variational-autoencoder/>Generative Model: Variational Auto-Encoder</a></li></ul></nav><h1 class="post-title has-text-centered is-size-1" itemprop="name headline">Generative Model: Variational Auto-Encoder</h1><h2 class="title is-6 has-text-centered"><i class="fas fa-tags" style=margin-right:.5em></i><a href=/tags/self-supervised-learning><span class="tag is-warning is-small is-light">#Self-supervised Learning</span></a>
<a href=/tags/generative-model><span class="tag is-warning is-small is-light">#Generative Model</span></a>
<a href=/tags/vae><span class="tag is-warning is-small is-light">#VAE</span></a>
<a href=/tags/basics><span class="tag is-warning is-small is-light">#Basics</span></a></h2></header><div class=columns><div class="column is-8"><div class=is-divider data-content=ARTICLE></div><div class="content blog-post section" itemprop=articleBody><p>Variational Auto-Encoder (VAE) is very different from
<span class=tooltip><a href=https://datumorphism.leima.is/wiki/machine-learning/self-supervised-learning/generative-autoencoder/>Generative Model: Auto-Encoder</a>
<span class=tooltiptext><span class=tooltip_title>Generative Model: Auto-Encoder</span>
<span class=tooltip_content>The simplest auto-encoder is rather simple.
The loss can be chosen based on the demand, e.g., cross entropy for binary labels.</span></span></span>
. In VAE, we introduce a variational distribution $q$ to help us work out the weighted integral after introducing the latent space variable $z$,</p><p>$$
\begin{align}
\ln p_\theta(x) &= \ln \int p_\theta (x\mid z) p(z) \,\mathrm d z \\
&= \ln \int \frac{q_{\phi}(z\mid x)}{q_{\phi}(z\mid x)} p_\theta (x\mid z) p(z) \, \mathrm d z\\
& \geq - \left[ D_{\mathrm{KL}} ( q_{\phi}(z\mid x) \mathrel{\Vert} p(z) ) - \mathbb E_q ( \ln p_\theta (x\mid z) ) \right] \\
&\equiv - F(x).
\end{align}
$$</p><p>$F(x)$ is the free energy, while the negative of it, $-F(x)$, is the so-called
<span class=tooltip><a href=https://datumorphism.leima.is/wiki/machine-learning/bayesian/elbo/>Evidence Lower Bound (ELBO)</a>
<span class=tooltiptext><span class=tooltip_title>Evidence Lower Bound: ELBO</span>
<span class=tooltip_content>ELBO is an very important concept in veraitional methods</span></span></span>
.</p><p>In the above derivation,</p><ul><li>${}_\theta$ is the model for inference, and</li><li>${}_\phi$ is the model for variational approximation.</li></ul><figure><img src=../assets/generative-variational-autoencoder/simple-vae.png alt="Structure of VAE"><figcaption><p>Structure of VAE</p></figcaption></figure><p>Doersch wrote a very nice tutorial on VAE<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. We can find the detailed structures of VAE.</p><p>Another key component of VAE is the
<span class=tooltip><a href=https://datumorphism.leima.is/cards/statistics/reparametrization-expectation-sampling/>reparametrization trick</a>
<span class=tooltiptext><span class=tooltip_title>Reparametrization in Expectation Sampling</span>
<span class=tooltip_content>Reparametrize the sampling distribution to simplify the sampling</span></span></span>
. The variational approximation $q_\phi$ is usually a Gaussian distribution. Once we get the parameters for the Gaussian distribution, we will have to sample from the Gaussian distribution based on the parameters. However, this sampling process prohibits us from propagating errors. The
<span class=tooltip><a href=https://datumorphism.leima.is/cards/statistics/reparametrization-expectation-sampling/>reparametrization trick</a>
<span class=tooltiptext><span class=tooltip_title>Reparametrization in Expectation Sampling</span>
<span class=tooltip_content>Reparametrize the sampling distribution to simplify the sampling</span></span></span>
solves this problem.</p><h2 id=loss-explanation>Loss Explanation</h2><figure><img src=../assets/generative-variational-autoencoder/vae-loss-explained.png alt="VAE Loss Explained [Doersch2016]"><figcaption><p>VAE Loss Explained [Doersch2016]</p></figcaption></figure><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p><a href=http://arxiv.org/abs/2006.08218 style=text-decoration:none>Liu X, Zhang F, Hou Z, Wang Z, Mian L, Zhang J, et al. Self-supervised Learning: Generative or Contrastive. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2006.08218</a>
<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></div><p><div class="has-text-right is-size-7"><span class=icon><i class="fas fa-pencil-alt"></i></span>Published: <time datetime=2021-08-13T00:00:00+00:00>2021-08-13</time>
by <span itemprop=author>Lei Ma</span>;</div></p><div class=is-divider></div><nav class="pagination is-centered" role=navigation aria-label=pagination><a href="https://datumorphism.leima.is/wiki/machine-learning/self-supervised-learning/generative-autoencoder/?ref=footer" class=pagination-previous>« Generative Model: Auto-Encoder</a></nav></div><div class="column is-4"><div class=is-divider data-content="Cite Me"></div><div class="box is-size-7 has-text-white has-background-black"><article class=media><div class=media-content><div class=content><p>Lei Ma
(2021). 'Generative Model: Variational Auto-Encoder', Datumorphism, 08 April. Available at: https://datumorphism.leima.is/wiki/machine-learning/self-supervised-learning/generative-variational-autoencoder/.</p></div></div></article></div><style>#TableOfContents>ul{list-style-type:lower-greek;padding-left:0}#TableOfContents>ul>li ul{list-style-type:none;padding-left:1em}</style><div class=is-divider data-content=ToC></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><details><summary>Table of Contents</summary><div><div><nav id=TableOfContents><ul><li><a href=#loss-explanation>Loss Explanation</a></li></ul></nav></div></div></details></div></div></article></div><script>const el=document.querySelector('details summary')
el.onclick=()=>{(function(l,o,a,d,e,r){e=o.createElement(a),r=o.getElementsByTagName(a)[0];e.async=1;e.src=d;r.parentNode.insertBefore(e,r)})(window,document,'script','/js/smoothscroll.js');el.onclick=null}
document.querySelectorAll('#TableOfContents a').forEach(link=>{link.addEventListener('click',()=>{document.querySelector(link.href.slice(link.href.indexOf('#'))).scrollIntoView({behavior:'smooth'})})})</script><div class=is-divider data-content=REFERENCES></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><p><strong>References:</strong><br><ol><li class=has-text-weight-bold><a href=http://arxiv.org/abs/2006.08218 style=text-decoration:none>Liu X, Zhang F, Hou Z, Wang Z, Mian L, Zhang J, et al. Self-supervised Learning: Generative or Contrastive. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2006.08218</a></li><li class=has-text-weight-bold><a name=Doersch2016 href=#Doersch2016 style=text-decoration:none><span class="tag is-link is-light">Doersch2016</span></a>
<a href=http://arxiv.org/abs/1606.05908 style=text-decoration:none>Doersch C. Tutorial on Variational Autoencoders. arXiv [stat.ML]. 2016. Available: http://arxiv.org/abs/1606.05908</a></li></ol></p></div></div></article></div><div class=is-divider data-content=CONNECTUME></div><div class="box is-size-7"><article class=media><div class=media-content style=width:100%><div class=content><p><strong>Current Ref:</strong><br><ul><li style=list-style:none><div>wiki/machine-learning/self-supervised-learning/generative-variational-autoencoder.md</div></li></ul></p></div></div></article></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><p><strong>Links to:</strong><div><a class=box href=https://datumorphism.leima.is/wiki/machine-learning/self-supervised-learning/generative-autoencoder/><div class=media-content><div class=content><h6>Generative Model: Auto-Encoder</h6><p>The simplest auto-encoder is rather simple.
The loss can be chosen based on the demand, e.g., …</p></div></div></a><a class=box href=https://datumorphism.leima.is/wiki/machine-learning/bayesian/elbo/><div class=media-content><div class=content><h6>Evidence Lower Bound: ELBO</h6><p>ELBO is an very important concept in veraitional methods</p></div></div></a><a class=box href=https://datumorphism.leima.is/wiki/machine-learning/bayesian/latent-variable-models/><div class=media-content><div class=content><h6>Latent Variable Models</h6><p>Latent variable models brings us new insights on identifying the patterns of some sample data.</p></div></div></a><a class=box href=https://datumorphism.leima.is/cards/statistics/reparametrization-expectation-sampling/><div class=media-content><div class=content><h6>Reparametrization in Expectation Sampling</h6><p>Reparametrize the sampling distribution to simplify the sampling</p></div></div></a></div></p></div></div></article></div><div id=comments class=is-divider data-content=COMMENTS></div><script src=https://giscus.app/client.js data-repo=datumorphism/comments data-repo-id="MDEwOlJlcG9zaXRvcnkxNjU5MDkyNDI=" data-category=Comments data-category-id=DIC_kwDOCeOS-s4B-Zxx data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=1 data-theme=light crossorigin=anonymous async></script></div></div></article></div></section></div><div class=navtools><a class="button is-primary is-light is-outlined" alt="Edit this page" href=https://github.com/datumorphism/datumorphism.github.io/edit/hugo/content/wiki/machine-learning/self-supervised-learning/generative-variational-autoencoder.md target=blank style=position:fixed;bottom:20px;right:10px;border-radius:9999px;width:35px;height:35px><i class="fas fa-pencil-alt"></i></a><a class="button is-primary is-light is-outlined" href=#comments alt=Comments style=position:fixed;bottom:60px;right:10px;border-radius:9999px;width:35px;height:35px><i class="far fa-comments"></i></a></div></main><footer><footer class=footer><div class=container><div class="content has-text-centered"><p>Created and maintained by <a href=https://leima.is>Lei Ma</a>.
Acknowledgement: <a href=https://gohugo.io/>Hugo</a>,
<a href=https://themes.gohugo.io/bulma/>Bulma</a>, <a href=https://kausalflow.com>KausalFlow</a>.
<strong>love</strong>.<br><a class=tag href=/about>About</a>
<a class=tag href=/index.xml>Feed</a>
<a class=tag href=/data.json>JSON Data</a></p></div></div></footer><script src=https://unpkg.com/applause-button/dist/applause-button.js></script></footer><script async type=text/javascript src=/js/bulma.js></script></body></html>