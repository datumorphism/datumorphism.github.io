<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.69.2"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Confusion Matrix (Contingency Table) | Datumorphism | Lei Ma</title><meta name=author content="Lei Ma"><meta property="og:title" content="Confusion Matrix (Contingency Table)"><meta property="og:description" content="Confusion Matrix It is much easier to understand the confusion matrix if we use a binary classification problem as an example. For example, we have a bunch of cat photos and the user labeled &ldquo;cute or not&rdquo; data. Now we are using the labeled data to train a cute-or-not binary classifier.
Then we apply the classifier on the test dataset and we would only find four different kinds of results."><meta property="og:type" content="article"><meta property="og:url" content="/wiki/machine-learning/basics/confusion-matrix/"><meta property="article:published_time" content="2019-05-31T00:00:00+00:00"><meta property="article:modified_time" content="2019-05-31T00:00:00+00:00"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-140452515-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><link rel=canonical href=/wiki/machine-learning/basics/confusion-matrix/><link rel="shortcut icon" type=image/png href=/logos/logo-square.png><link rel=stylesheet href=/css/bulma.css><link rel=stylesheet href=/css/bulma-divider.min.css><link rel=stylesheet href=/assets/css/bulma-ribbon.min.css><link rel=stylesheet href=/assets/css/tooltip.css><link rel=stylesheet href=https://jenil.github.io/bulmaswatch/united/bulmaswatch.min.css><link rel=stylesheet href=/css/custom.css><link rel=stylesheet href=/css/blog-post.css><link rel=stylesheet href=/css/code-highlighting/dark.css><link rel=stylesheet href=/css/custom.css><link rel=stylesheet href=https://unpkg.com/applause-button/dist/applause-button.css><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],tags:'ams',processEscapes:true,processEnvironments:true},options:{skipHtmlTags:['script','noscript','style','textarea','pre']},svg:{fontCache:'global'}};window.addEventListener('load',(event)=>{document.querySelectorAll("mjx-container").forEach(function(x){x.parentElement.classList+='has-jax'})});</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>mermaid.initialize({startOnLoad:true});</script><script src=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/js/all.min.js integrity="sha256-KzZiKy0DWYsnwMF+X1DvQngQ2/FxF7MF3Ff72XcpuPs=" crossorigin=anonymous></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin=anonymous></head><body><header><nav class="navbar is-transparent"><div class=navbar-brand><a class=navbar-item href=/><img src=/site/intelligence.png alt=Datumorphism height=28 style=margin-right:.5em> Datumorphism</a><div class="navbar-burger burger" data-target=navMenu><span></span><span></span><span></span></div></div><div class=navbar-menu id=navMenu><div class=navbar-start><div class="navbar-item has-dropdown is-hoverable"><a href=/projects class=navbar-link>Notebooks</a><div class=navbar-dropdown><a href=/awesome/ class=navbar-item>Awesome</a>
<a href=/blog/ class=navbar-item>Blog</a>
<a href=/cards/ class=navbar-item>Cards</a>
<a href=/hologram/ class=navbar-item>Hologram</a>
<a href=/reading/ class=navbar-item>Reading Notes</a>
<a href=/til/ class=navbar-item>TIL</a>
<a href=/wiki/ class=navbar-item>Wiki</a></div></div></div><span class=navbar-burger><span></span><span></span><span></span></span><div class=navbar-end><div class=navbar-item><a class=navbar-item href=/blog/>Blog</a>
<a class=navbar-item href=/tags/><i class="fas fa-tags"></i></a><a class=navbar-item href=/graph><i class="fas fa-project-diagram"></i></a><a class=navbar-item href=https://t.me/amneumarkt><i class="fab fa-telegram"></i></a><a class=navbar-item target=blank href=https://github.com/datumorphism><span class=icon><i class="fab fa-github"></i></span></a></div></div></div></nav><script>document.addEventListener('DOMContentLoaded',()=>{const $navbarBurgers=Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'),0);if($navbarBurgers.length>0){$navbarBurgers.forEach(el=>{el.addEventListener('click',()=>{const target=el.dataset.target;const $target=document.getElementById(target);el.classList.toggle('is-active');$target.classList.toggle('is-active');});});}});</script></header><main><div class=container itemscope itemtype=http://schema.org/BlogPosting><meta itemprop=name content="Confusion Matrix (Contingency Table)"><meta itemprop=description content="Confusion Matrix It is much easier to understand the confusion matrix if we use a binary classification problem as an example. For example, we have a bunch of cat photos and the user labeled &ldquo;cute or not&rdquo; data. Now we are using the labeled data to train a cute-or-not binary classifier.
Then we apply the classifier on the test dataset and we would only find four different kinds of results."><meta itemprop=datePublished content="2019-05-31T00:00:00+00:00"><meta itemprop=dateModified content="2019-05-31T00:00:00+00:00"><meta itemprop=wordCount content="837"><meta itemprop=keywords content="Statistical Learning,Basics,Learning Metrics,Classification,"><section class=section><div class=container><article class=post><header class=post-header><nav class="breadcrumb has-succeeds-separator is-small" aria-label=breadcrumbs><ul><li><a href=/>Datumorphism</a></li><li><a href=/wiki/>Wiki</a></li><li><a href=/wiki/machine-learning/>Machine Learning</a></li><li><a href=/wiki/machine-learning/basics/>Machine Learning Basics</a></li><li class=active><a href=/wiki/machine-learning/basics/confusion-matrix/>Confusion Matrix (Contingency Table)</a></li></ul></nav><h1 class="post-title has-text-centered is-size-1" itemprop="name headline">Confusion Matrix (Contingency Table)</h1><h2 class="title is-6 has-text-centered"><i class="fas fa-tags" style=margin-right:.5em></i><a href=/tags/statistical-learning><span class="tag is-warning is-small is-light">#Statistical Learning</span></a>
<a href=/tags/basics><span class="tag is-warning is-small is-light">#Basics</span></a>
<a href=/tags/learning-metrics><span class="tag is-warning is-small is-light">#Learning Metrics</span></a>
<a href=/tags/classification><span class="tag is-warning is-small is-light">#Classification</span></a></h2></header><div class=columns><div class="column is-8"><div class=is-divider data-content=ARTICLE></div><div class="content blog-post section" itemprop=articleBody><h2 id=confusion-matrix>Confusion Matrix</h2><p>It is much easier to understand the confusion matrix if we use a binary classification problem as an example. For example, we have a bunch of cat photos and the user labeled &ldquo;cute or not&rdquo; data. Now we are using the labeled data to train a cute-or-not binary classifier.</p><p>Then we apply the classifier on the test dataset and we would only find four different kinds of results.</p><table class=table><thead><tr><th></th><th>Labeled as Cute</th><th>Labeled as Not Cute</th></tr></thead><tbody><tr><th>Classifier Predicted to be Cute</th><td>True Positive (TP)</td><td>False Positive (FP)</td></tr><tr><th>Classifier Predicted to be Not Cute</th><td>False Negative (FN)</td><td>True Negative (TN)</td></tr></tbody></table><p>This table is easy enough to comprehend. We have discussed the Type I and Type II errors in <a href=/wiki/statistical-hypothesis-testing/type-1-error-and-type-2-error/>Types of Errors in Statistical Hypothesis Testing
</a>. Here False Positive (FP) is Type I error and False Negative (FN) is Type II error.</p><article class="message is-info is-light"><div class=message-header><p>Isn’t FN type I error?</p></div><div class=message-body><p>A first look at the table might lead us to conclude such as &ldquo;FN is type I error&rdquo; and &ldquo;FP is type II error&rdquo;.</p><p>But remember types of errors is about hypothesis testing and we usually test our null hypothesis. Here a null hypothesis is the negative labels.</p></div></article><p>Then we loop through all cats in the test dataset, find the results and put the numbers in the table.</p><p>There are a few things to look at whenever we have a table. First things first, we would like to know the sum of each row and columns.</p><ol><li>The sum of the row &ldquo;Classifier Predicted to be Cute&rdquo; tells us the total number of cats classified as cute, aka, <strong>Total Predicted Positives</strong> (<strong>PP</strong>);</li><li>The sum of the row &ldquo;Classifier Predicted to be Not Cute&rdquo; tells us the total number of cats classified as not cute, aka, <strong>Total Predicted Negatives</strong> (<strong>PN</strong>);</li><li>The sum of the column &ldquo;Labeled as Cute&rdquo; tells us the total number of cats labeled as cute in the test dataset, aka, <strong>Total Positives</strong> (<strong>P</strong>);</li><li>The sum of the column &ldquo;Labeled as Not Cute&rdquo; tells us the total number of cats labeled as not cute in the test dataset, aka, <strong>Total Negatives</strong> (<strong>N</strong>).</li><li>The sum of the diagonal elements tells us the total number of cases where the classifier classified the data correctly.</li></ol><h2 id=measures-defined>Measures Defined</h2><h3 id=property-of-the-dataset-itself>Property of the Dataset itself</h3><p>Apart from these trivial properties about the test dataset defined above, we can define the <strong>Prevalence</strong>:</p><p>$$
\frac{ \text{ Total Positives } }{ \text{ Total Sample, or Total Positives + Total Negatives} } = \frac{ \text{ Labeled as Cute } }{ \text{ All Cats, or Labeled as Cute + Labeled as Not Cute} }
$$</p><h3 id=performance-of-classifier>Performance of Classifier</h3><p>We could define some quite general measures.</p><ol><li><strong>Accuracy</strong>:
$$\frac{ \text{ TP + TN } }{ \text{P + N} }$$</li></ol><p>Now we recalculate the confusion matrix by dividing the values by some certain sums.</p><h4 id=confusion-matrix-divided-by-the-column-sums>Confusion Matrix divided by the Column Sums</h4><p>As mentioned in the previous sections, the sum of the columns are <strong>P</strong> (<strong>Total Positives</strong>) and <strong>N</strong> (<strong>Total Negatives</strong>). Dividing each column by the sum of the corresponding column gives us the prediction rate for each labels.</p><table class=table><thead><tr><th></th><th>Labeled as Cute</th><th>Labeled as Not Cute</th></tr></thead><tbody><tr><th>Classifier Predicted to be Cute</th><td>True Positive Rate (aka Recall) = TP/P</td><td>False Positive Rate = FP/N</td></tr><tr><th>Classifier Predicted to be Not Cute</th><td>False Negative Rate = FN/P</td><td>True Negative Rate (aka Specifity) = TN/N</td></tr></tbody></table><p>There are a few names to be emphasized.</p><ol><li><strong>Recall</strong>: True Positive Rate</li></ol><h4 id=confusion-matrix-divided-by-the-row-sums>Confusion Matrix divided by the Row Sums</h4><p>As mentioned, the sum of the rows indicates the</p><table class=table><thead><tr><th></th><th>Labeled as Cute</th><th>Labeled as Not Cute</th></tr></thead><tbody><tr><th>Classifier Predicted to be Cute</th><td>Positive Predictive Value (aka Precision) = TP/PP</td><td>False Discovery Rate = FP/PP</td></tr><tr><th>Classifier Predicted to be Not Cute</th><td>False Omission Rate = FN/PN</td><td>Negative Predictive Value = TN/PN</td></tr></tbody></table><p>There are a few names to be emphasized.</p><ol><li><strong>Precision</strong>: Positive Predictive Value</li></ol><h4 id=ratios-scores-and-more>Ratios, Scores, and More</h4><p>We also have some other definitions of ratios, please refer to the bottom left corner of the table on the corresponding Wikipedia page linked in the references.</p><p>We will only define the F1 score ($\mathrm F_1$) here. As a F-measure,</p>$$
\begin{align}
F_1 &= \frac{2}{ 1/\mathrm{Pression} + 1/\mathrm{Recall} } \\
& = \frac{2}{ \frac{PP}{TP} + \frac{P}{TP} } \\
& = \frac{2}{ \frac{PP+P}{TP} } \\
& = \frac{2}{ \frac{ (TP + FP) + (TP + FN) }{TP} } \\
& = \frac{1}{ 1 + \frac{ (FP + FN) }{2TP} }
\end{align}
$$<h2 id=confused-by-the-names>Confused by the Names?</h2><p>There is a nice chart on <a href=https://commons.wikimedia.org/wiki/File:Precisionrecall.svg>this Wikipedia page</a>.</p><p>The different metrics can be visualized using color blocks. We use green to represent the amount of TP, orange to represent the amount of FP.</p><figure><img src=../confusion-matrix/confusion-matrix-less-tp-more-fp.png alt="Low TP Rate;High FP Rate; Low Precision; Low Accuracy; Low Recall; Low F1"><figcaption><p>Low TP Rate;High FP Rate; Low Precision; Low Accuracy; Low Recall; Low F1</p></figcaption></figure><figure><img src=../confusion-matrix/confusion-matrix-more-tp-more-fp.png alt="High TP Rate;High FP Rate; Not so good Precision; Not so good Accuracy; High Recall; Not so good F1"><figcaption><p>High TP Rate;High FP Rate; Not so good Precision; Not so good Accuracy; High Recall; Not so good F1</p></figcaption></figure><figure><img src=../confusion-matrix/confusion-matrix-more-tp-less-fp.png alt="High TP Rate;Low FP Rate; Good Precision; Good Accuracy; High Recall; Good F1"><figcaption><p>High TP Rate;Low FP Rate; Good Precision; Good Accuracy; High Recall; Good F1</p></figcaption></figure><figure><img src=../confusion-matrix/confusion-matrix-less-tp-less-fp.png alt="Low TP Rate;Low FP Rate; Low Precision; Low Accuracy; Low Recall; Low F1"><figcaption><p>Low TP Rate;Low FP Rate; Low Precision; Low Accuracy; Low Recall; Low F1</p></figcaption></figure><figure><img src=../confusion-matrix/confusion-matrix-less-tp-lesser-fp.png alt="Low TP Rate;Low FP Rate; High Precision; Low Accuracy; Low Recall; Low F1"><figcaption><p>Low TP Rate;Low FP Rate; High Precision; Low Accuracy; Low Recall; Low F1</p></figcaption></figure></div><p><div class="has-text-right is-size-7"><span class=icon><i class="fas fa-pencil-alt"></i></span>Published: <time datetime=2019-05-31T00:00:00+00:00>2019-05-31</time>
by <span itemprop=author>Lei Ma</span>;</div></p><div class=is-divider></div><nav class="pagination is-centered" role=navigation aria-label=pagination><a class=pagination-next href="/wiki/machine-learning/basics/bias-variance/?ref=footer">Bias-Variance »</a></nav></div><div class="column is-4"><div class=is-divider data-content="Cite Me"></div><div class="box is-size-7 has-text-white has-background-black"><article class=media><div class=media-content><div class=content><p>Lei Ma
(2019). 'Confusion Matrix (Contingency Table)', Datumorphism, 05 April. Available at: /wiki/machine-learning/basics/confusion-matrix/.</p></div></div></article></div><style>#TableOfContents>ul{list-style-type:lower-greek;padding-left:0}#TableOfContents>ul>li ul{list-style-type:none;padding-left:1em}</style><div class=is-divider data-content=ToC></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><details><summary>Table of Contents</summary><div><div><nav id=TableOfContents><ul><li><a href=#confusion-matrix>Confusion Matrix</a></li><li><a href=#measures-defined>Measures Defined</a><ul><li><a href=#property-of-the-dataset-itself>Property of the Dataset itself</a></li><li><a href=#performance-of-classifier>Performance of Classifier</a></li></ul></li><li><a href=#confused-by-the-names>Confused by the Names?</a></li></ul></nav></div></div></details></div></div></article></div><script>const el=document.querySelector('details summary')
el.onclick=()=>{(function(l,o,a,d,e,r){e=o.createElement(a),r=o.getElementsByTagName(a)[0];e.async=1;e.src=d;r.parentNode.insertBefore(e,r)})(window,document,'script','/js/smoothscroll.js');el.onclick=null}
document.querySelectorAll('#TableOfContents a').forEach(link=>{link.addEventListener('click',()=>{document.querySelector(link.href.slice(link.href.indexOf('#'))).scrollIntoView({behavior:'smooth'})})})</script><div class=is-divider data-content=REFERENCES></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><p><strong>References:</strong><br><ol><li class=has-text-weight-bold><a href=https://doi.org/10.1016/j.patrec.2005.10.010 style=text-decoration:none>Fawcett, T. (2006). An introduction to ROC analysis. Pattern Recognition Letters, 27(8), 861–874.</a></li><li class=has-text-weight-bold><a href=https://en.wikipedia.org/wiki/Confusion_matrix#Table_of_confusion style=text-decoration:none>Confusion_matrix#Table_of_confusion @ Wikipedia</a></li><li class=has-text-weight-bold><a href=https://en.wikipedia.org/wiki/F1_score style=text-decoration:none>F1 Score</a></li></ol></p></div></div></article></div><div class=is-divider data-content=CONNECTUME></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><p><strong>Current Ref:</strong><br><ul><li style=list-style:none><span class="tag is-primary is-light has-text-weight-bold">wiki/machine-learning/basics/confusion-matrix.md</span></li></ul></p></div></div></article></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><p><strong>Links to:</strong><div><a class=box href=/wiki/statistical-hypothesis-testing/type-1-error-and-type-2-error/><div class=media-content><div class=content><h6>Types of Errors in Statistical Hypothesis Testing</h6><p>We all make mistakes. The question is, what kind of mistakes.</p></div></div></a></div></p></div></div></article></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><p><strong>Links from:</strong><div><a class=box href=/wiki/machine-learning/performance/roc/><div class=media-content><div class=content><h6>Receiver Operating Characteristics: ROC</h6><p>ROC is used to judging the performance of classifiers</p></div></div></a><a class=box href=/wiki/machine-learning/classification/classifier-chains/><div class=media-content><div class=content><h6>Classifier Chains for Multilabel Classification</h6><p>Classifier chains is a method to predict hierarchical class labels</p></div></div></a></div></p></div></div></article></div><div id=comments class=is-divider data-content=COMMENTS></div><script src=https://utteranc.es/client.js repo=datumorphism/comments issue-term=pathname theme=github-light crossorigin=anonymous async></script></div></div></article></div></section></div><div class=navtools><a class="button is-primary is-light is-outlined" alt="Edit this page" href=https://github.com/datumorphism/datumorphism.github.io/edit/hugo/content/wiki/machine-learning/basics/confusion-matrix.md target=blank style=position:fixed;bottom:20px;right:10px;border-radius:9999px;width:35px;height:35px><i class="fas fa-pencil-alt"></i></a><a class="button is-primary is-light is-outlined" href=#comments alt=Comments style=position:fixed;bottom:60px;right:10px;border-radius:9999px;width:35px;height:35px><i class="far fa-comments"></i></a><a class="button is-primary is-light is-outlined" data-lyket-type=updown data-lyket-id=confusion-matrix data-lyket-namespace=Datumorphism data-lyket-template=reddit style=width:35px;height:35px;position:fixed;bottom:120px;right:10px;border-radius:9999px></a></div></main><footer><footer class=footer><div class=container><div class="content has-text-centered"><p>Created and maintained by <a href=https://leima.is>Lei Ma</a>.
Acknowledgement: <a href=https://gohugo.io/>Hugo</a>,
<a href=https://themes.gohugo.io/bulma/>Bulma</a>, <a href=https://kausalflow.com>KausalFlow</a>.
<strong>love</strong>.<br><a class=tag href=/about>About</a>
<a class=tag href=/index.xml>Feed</a>
<a class=tag href=/data.json>JSON Data</a></p></div></div></footer><script src=https://unpkg.com/applause-button/dist/applause-button.js></script></footer><script async type=text/javascript src=/js/bulma.js></script><script src="https://unpkg.com/@lyket/widget@latest/dist/lyket.js?apiKey=4df20b7e32f469fed5dc53f5ab39d8&disableSessionId"></script></body></html>