<!doctype html><html lang=en-us>
<head>
<meta name=generator content="Hugo 0.89.4">
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1">
<title> Confusion Matrix (Contingency Table) | Datumorphism | L Ma </title>
<meta name=author content="L Ma">
<meta property="og:title" content="Confusion Matrix (Contingency Table)">
<meta property="og:description" content="Confusion Matrix It is much easier to understand the confusion matrix if we use a binary classification problem as an example. For example, we have a bunch of cat photos and the user labeled &ldquo;cute or not&rdquo; data. Now we are using the labeled data to train a cute-or-not binary classifier.
Then we apply the classifier on the test dataset and we would only find four different kinds of results.
   Labeled as Cute Labeled as Not Cute     Classifier Predicted to be Cute True Positive (TP) False Positive (FP)   Classifier Predicted to be Not Cute False Negative (FN) True Negative (TN)    This table is easy enough to comprehend.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://datumorphism.leima.is/wiki/machine-learning/basics/confusion-matrix/"><meta property="article:section" content="wiki">
<meta property="article:published_time" content="2019-05-31T00:00:00+00:00">
<meta property="article:modified_time" content="2019-05-31T00:00:00+00:00">
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-140452515-1','auto'),ga('send','pageview'))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
<link rel=canonical href=https://datumorphism.leima.is/wiki/machine-learning/basics/confusion-matrix/> <link rel="shortcut icon" type=image/png href=/logos/logo-square.png>
<link rel=stylesheet href=/css/bulma.css>
<link rel=stylesheet href=/css/bulma-divider.min.css>
<link rel=stylesheet href=/assets/css/bulma-ribbon.min.css>
<link rel=stylesheet href=/assets/css/tooltip.css>
<link rel=stylesheet href=https://jenil.github.io/bulmaswatch/united/bulmaswatch.min.css>
<link rel=stylesheet href=/css/custom.css>
<link rel=stylesheet href=/css/blog-post.css>
<link rel=stylesheet href=/css/code-highlighting/dark.css>
<link rel=stylesheet href=/css/custom.css>
<script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],tags:'ams',processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:['script','noscript','style','textarea','pre']},svg:{fontCache:'global'}},window.addEventListener('load',a=>{document.querySelectorAll("mjx-container").forEach(function(a){a.parentElement.classList+='has-jax'})})</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script>
<script>mermaid.initialize({startOnLoad:!0})</script>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css integrity="sha512-9usAa10IRO0HhonpyAIVpjrylPvoDwiPUiKdWk5t3PyolY1cOd4DSE0Ga+ri4AuTroPR5aQvXU9xC6qOPnzFeg==" crossorigin=anonymous referrerpolicy=no-referrer>
<script src=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/js/all.min.js integrity="sha512-yFjZbTYRCJodnuyGlsKamNE/LlEaEAxSUDe5+u61mV8zzqJVFOH7TnULE2/PP/l5vKWpUNnF4VGVkXh3MjgLsg==" crossorigin=anonymous referrerpolicy=no-referrer></script>
</head>
<body>
<header> <nav class="navbar is-transparent">
<div class=navbar-brand>
<a class=navbar-item href=/>
<img src=/site/intelligence.png alt=Datumorphism height=28 style=margin-right:.5em> Datumorphism
</a>
<div class="navbar-burger burger" style=color:#000 data-target=navMenu>
<span></span>
<span></span>
<span></span>
</div>
</div>
<div class=navbar-menu id=navMenu>
<div class=navbar-start>
<div class="navbar-item has-dropdown is-hoverable">
<a href=/projects class=navbar-link>
Notebooks
</a>
<div class=navbar-dropdown>
<a href=https://datumorphism.leima.is/awesome/ class=navbar-item>
Awesome
</a>
<a href=https://datumorphism.leima.is/blog/ class=navbar-item>
Blog
</a>
<a href=https://datumorphism.leima.is/cards/ class=navbar-item>
Cards
</a>
<a href=https://datumorphism.leima.is/hologram/ class=navbar-item>
Hologram
</a>
<a href=https://datumorphism.leima.is/reading/ class=navbar-item>
Reading Notes
</a>
<a href=https://datumorphism.leima.is/til/ class=navbar-item>
TIL
</a>
<a href=https://datumorphism.leima.is/wiki/ class=navbar-item>
Wiki
</a>
</div>
</div>
<div class="navbar-item has-dropdown is-hoverable">
<a class=navbar-item href=https://neuronstar.kausalflow.com/cpe-docs/>
Probability Estimation
</a>
</div>
</div>
<span class=navbar-burger>
<span></span>
<span></span>
<span></span>
</span>
<div class=navbar-end>
<div class=navbar-item>
<a class=navbar-item href=/blog/>
Blog
</a>
<a class=navbar-item href=/amneumarkt/>
AmNeumarkt
</a>
<a class=navbar-item href=/>
<i class="fas fa-search"></i>
</a>
<a class=navbar-item href=/tags/>
<i class="fas fa-tags"></i>
</a>
<a class=navbar-item href=/graph>
<i class="fas fa-project-diagram"></i>
</a>
<a class=navbar-item href=https://t.me/amneumarkt>
<i class="fab fa-telegram"></i>
</a>
<a class=navbar-item target=blank href=https://github.com/datumorphism>
<span class=icon>
<i class="fab fa-github"></i>
</span>
</a>
</div>
</div>
</div>
</nav>
<script>document.addEventListener('DOMContentLoaded',()=>{const a=Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'),0);a.length>0&&a.forEach(a=>{a.addEventListener('click',()=>{const b=a.dataset.target,c=document.getElementById(b);a.classList.toggle('is-active'),c.classList.toggle('is-active')})})})</script>
</header>
<main>
<div class=container itemscope itemtype=http://schema.org/BlogPosting>
<meta itemprop=name content="Confusion Matrix (Contingency Table)">
<meta itemprop=description content="Confusion Matrix It is much easier to understand the confusion matrix if we use a binary classification problem as an example. For example, we have a bunch of cat photos and the user labeled &ldquo;cute or not&rdquo; data. Now we are using the labeled data to train a cute-or-not binary classifier.
Then we apply the classifier on the test dataset and we would only find four different kinds of results.
   Labeled as Cute Labeled as Not Cute     Classifier Predicted to be Cute True Positive (TP) False Positive (FP)   Classifier Predicted to be Not Cute False Negative (FN) True Negative (TN)    This table is easy enough to comprehend."><meta itemprop=datePublished content="2019-05-31T00:00:00+00:00">
<meta itemprop=dateModified content="2019-05-31T00:00:00+00:00">
<meta itemprop=wordCount content="837">
<meta itemprop=keywords content="Statistical Learning,Basics,Learning Metrics,Classification,">
<section class=section>
<div class=container>
<article class=post>
<header class=post-header>
<nav class="breadcrumb has-succeeds-separator is-small" aria-label=breadcrumbs>
<ul>
<li>
<a href=https://datumorphism.leima.is/>Datumorphism</a>
</li>
<li>
<a href=https://datumorphism.leima.is/wiki/>Wiki</a>
</li>
<li>
<a href=https://datumorphism.leima.is/wiki/machine-learning/>Machine Learning</a>
</li>
<li>
<a href=https://datumorphism.leima.is/wiki/machine-learning/basics/>Machine Learning Basics</a>
</li>
<li class=active>
<a href=https://datumorphism.leima.is/wiki/machine-learning/basics/confusion-matrix/>Confusion Matrix (Contingency Table)</a>
</li>
</ul>
</nav>
<h1 class="post-title has-text-centered is-size-1" itemprop="name headline">
Confusion Matrix (Contingency Table)
</h1>
<h2 class="title is-6 has-text-centered">
<i class="fas fa-tags" style=margin-right:.5em></i>
<a href=/tags/statistical-learning><span class="tag is-warning is-small is-light">#Statistical Learning</span></a>
<a href=/tags/basics><span class="tag is-warning is-small is-light">#Basics</span></a>
<a href=/tags/learning-metrics><span class="tag is-warning is-small is-light">#Learning Metrics</span></a>
<a href=/tags/classification><span class="tag is-warning is-small is-light">#Classification</span></a>
</h2>
</header>
<div class=columns>
<div class="column is-8">
<div class=is-divider data-content=ARTICLE></div>
<div class="content blog-post section" itemprop=articleBody>
<h2 id=confusion-matrix>Confusion Matrix</h2>
<p>It is much easier to understand the confusion matrix if we use a binary classification problem as an example. For example, we have a bunch of cat photos and the user labeled &ldquo;cute or not&rdquo; data. Now we are using the labeled data to train a cute-or-not binary classifier.</p>
<p>Then we apply the classifier on the test dataset and we would only find four different kinds of results.</p>
<table class=table>
<thead>
<tr>
<th></th>
<th>Labeled as Cute</th>
<th>Labeled as Not Cute</th>
</tr>
</thead>
<tbody>
<tr>
<th>Classifier Predicted to be Cute</th>
<td>True Positive (TP)</td>
<td>False Positive (FP)</td>
</tr>
<tr>
<th>Classifier Predicted to be Not Cute</th>
<td>False Negative (FN)</td>
<td>True Negative (TN)</td>
</tr>
</tbody>
</table>
<p>This table is easy enough to comprehend. We have discussed the Type I and Type II errors in <a href=/wiki/statistical-hypothesis-testing/type-1-error-and-type-2-error/>Types of Errors in Statistical Hypothesis Testing
</a>. Here False Positive (FP) is Type I error and False Negative (FN) is Type II error.</p>
<article class="message is-info is-light">
<div class=message-header>
<p>Isnâ€™t FN type I error?</p>
</div>
<div class=message-body>
<p>A first look at the table might lead us to conclude such as &ldquo;FN is type I error&rdquo; and &ldquo;FP is type II error&rdquo;.</p>
<p>But remember types of errors is about hypothesis testing and we usually test our null hypothesis. Here a null hypothesis is the negative labels.</p>
</div>
</article>
<p>Then we loop through all cats in the test dataset, find the results and put the numbers in the table.</p>
<p>There are a few things to look at whenever we have a table. First things first, we would like to know the sum of each row and columns.</p>
<ol>
<li>The sum of the row &ldquo;Classifier Predicted to be Cute&rdquo; tells us the total number of cats classified as cute, aka, <strong>Total Predicted Positives</strong> (<strong>PP</strong>);</li>
<li>The sum of the row &ldquo;Classifier Predicted to be Not Cute&rdquo; tells us the total number of cats classified as not cute, aka, <strong>Total Predicted Negatives</strong> (<strong>PN</strong>);</li>
<li>The sum of the column &ldquo;Labeled as Cute&rdquo; tells us the total number of cats labeled as cute in the test dataset, aka, <strong>Total Positives</strong> (<strong>P</strong>);</li>
<li>The sum of the column &ldquo;Labeled as Not Cute&rdquo; tells us the total number of cats labeled as not cute in the test dataset, aka, <strong>Total Negatives</strong> (<strong>N</strong>).</li>
<li>The sum of the diagonal elements tells us the total number of cases where the classifier classified the data correctly.</li>
</ol>
<h2 id=measures-defined>Measures Defined</h2>
<h3 id=property-of-the-dataset-itself>Property of the Dataset itself</h3>
<p>Apart from these trivial properties about the test dataset defined above, we can define the <strong>Prevalence</strong>:</p>
<p>$$
\frac{ \text{ Total Positives } }{ \text{ Total Sample, or Total Positives + Total Negatives} } = \frac{ \text{ Labeled as Cute } }{ \text{ All Cats, or Labeled as Cute + Labeled as Not Cute} }
$$</p>
<h3 id=performance-of-classifier>Performance of Classifier</h3>
<p>We could define some quite general measures.</p>
<ol>
<li><strong>Accuracy</strong>:
$$\frac{ \text{ TP + TN } }{ \text{P + N} }$$</li>
</ol>
<p>Now we recalculate the confusion matrix by dividing the values by some certain sums.</p>
<h4 id=confusion-matrix-divided-by-the-column-sums>Confusion Matrix divided by the Column Sums</h4>
<p>As mentioned in the previous sections, the sum of the columns are <strong>P</strong> (<strong>Total Positives</strong>) and <strong>N</strong> (<strong>Total Negatives</strong>). Dividing each column by the sum of the corresponding column gives us the prediction rate for each labels.</p>
<table class=table>
<thead>
<tr>
<th></th>
<th>Labeled as Cute</th>
<th>Labeled as Not Cute</th>
</tr>
</thead>
<tbody>
<tr>
<th>Classifier Predicted to be Cute</th>
<td>True Positive Rate (aka Recall) = TP/P</td>
<td>False Positive Rate = FP/N</td>
</tr>
<tr>
<th>Classifier Predicted to be Not Cute</th>
<td>False Negative Rate = FN/P</td>
<td>True Negative Rate (aka Specifity) = TN/N</td>
</tr>
</tbody>
</table>
<p>There are a few names to be emphasized.</p>
<ol>
<li><strong>Recall</strong>: True Positive Rate</li>
</ol>
<h4 id=confusion-matrix-divided-by-the-row-sums>Confusion Matrix divided by the Row Sums</h4>
<p>As mentioned, the sum of the rows indicates the</p>
<table class=table>
<thead>
<tr>
<th></th>
<th>Labeled as Cute</th>
<th>Labeled as Not Cute</th>
</tr>
</thead>
<tbody>
<tr>
<th>Classifier Predicted to be Cute</th>
<td>Positive Predictive Value (aka Precision) = TP/PP</td>
<td>False Discovery Rate = FP/PP</td>
</tr>
<tr>
<th>Classifier Predicted to be Not Cute</th>
<td>False Omission Rate = FN/PN</td>
<td>Negative Predictive Value = TN/PN</td>
</tr>
</tbody>
</table>
<p>There are a few names to be emphasized.</p>
<ol>
<li><strong>Precision</strong>: Positive Predictive Value</li>
</ol>
<h4 id=ratios-scores-and-more>Ratios, Scores, and More</h4>
<p>We also have some other definitions of ratios, please refer to the bottom left corner of the table on the corresponding Wikipedia page linked in the references.</p>
<p>We will only define the F1 score ($\mathrm F_1$) here. As a F-measure,</p>
<p>$$
\begin{align}
F_1 &= \frac{2}{ 1/\mathrm{Pression} + 1/\mathrm{Recall} } \\
& = \frac{2}{ \frac{PP}{TP} + \frac{P}{TP} } \\
& = \frac{2}{ \frac{PP+P}{TP} } \\
& = \frac{2}{ \frac{ (TP + FP) + (TP + FN) }{TP} } \\
& = \frac{1}{ 1 + \frac{ (FP + FN) }{2TP} }
\end{align}
$$</p>
<h2 id=confused-by-the-names>Confused by the Names?</h2>
<p>There is a nice chart on <a href=https://commons.wikimedia.org/wiki/File:Precisionrecall.svg>this Wikipedia page</a>.</p>
<p>The different metrics can be visualized using color blocks. We use green to represent the amount of TP, orange to represent the amount of FP.</p>
<figure>
<img src=../confusion-matrix/confusion-matrix-less-tp-more-fp.png alt="Low TP Rate;High FP Rate; Low Precision; Low Accuracy; Low Recall; Low F1"> <figcaption>
<p>Low TP Rate;High FP Rate; Low Precision; Low Accuracy; Low Recall; Low F1</p>
</figcaption>
</figure>
<figure>
<img src=../confusion-matrix/confusion-matrix-more-tp-more-fp.png alt="High TP Rate;High FP Rate; Not so good Precision; Not so good Accuracy; High Recall; Not so good F1"> <figcaption>
<p>High TP Rate;High FP Rate; Not so good Precision; Not so good Accuracy; High Recall; Not so good F1</p>
</figcaption>
</figure>
<figure>
<img src=../confusion-matrix/confusion-matrix-more-tp-less-fp.png alt="High TP Rate;Low FP Rate; Good Precision; Good Accuracy; High Recall; Good F1"> <figcaption>
<p>High TP Rate;Low FP Rate; Good Precision; Good Accuracy; High Recall; Good F1</p>
</figcaption>
</figure>
<figure>
<img src=../confusion-matrix/confusion-matrix-less-tp-less-fp.png alt="Low TP Rate;Low FP Rate; Low Precision; Low Accuracy; Low Recall; Low F1"> <figcaption>
<p>Low TP Rate;Low FP Rate; Low Precision; Low Accuracy; Low Recall; Low F1</p>
</figcaption>
</figure>
<figure>
<img src=../confusion-matrix/confusion-matrix-less-tp-lesser-fp.png alt="Low TP Rate;Low FP Rate; High Precision; Low Accuracy; Low Recall; Low F1"> <figcaption>
<p>Low TP Rate;Low FP Rate; High Precision; Low Accuracy; Low Recall; Low F1</p>
</figcaption>
</figure>
</div>
<p><div class="has-text-right is-size-7">
<span class=icon>
<i class="fas fa-pencil-alt"></i>
</span>
Published: <time datetime=2019-05-31T00:00:00+00:00>2019-05-31</time>
by <span itemprop=author>L Ma</span>;
</div></p>
<div class=is-divider></div>
<nav class="pagination is-centered" role=navigation aria-label=pagination>
<a class=pagination-next href="https://datumorphism.leima.is/wiki/machine-learning/basics/bias-variance/?ref=footer">Bias-Variance Â»</a>
</nav>
</div>
<div class="column is-4">
<div class=is-divider data-content="Cite Me"></div>
<div class="box is-size-7 has-text-white has-background-black">
<article class=media>
<div class=media-content>
<div class=content>
<p>
L Ma
(2019). 'Confusion Matrix (Contingency Table)', Datumorphism, 05 April. Available at: https://datumorphism.leima.is/wiki/machine-learning/basics/confusion-matrix/.
</p>
</div>
</div>
</article>
</div>
<style>#TableOfContents>ul{list-style-type:lower-greek;padding-left:0}#TableOfContents>ul>li ul{list-style-type:none;padding-left:1em}</style>
<div class=is-divider data-content=ToC></div>
<div class="box is-size-7">
<article class=media>
<div class=media-content>
<div class=content>
<details>
<summary><i class="fa-solid fa-list-ol"></i> Table of Contents</summary>
<div>
<div>
<nav id=TableOfContents>
<ul>
<li><a href=#confusion-matrix>Confusion Matrix</a></li>
<li><a href=#measures-defined>Measures Defined</a>
<ul>
<li><a href=#property-of-the-dataset-itself>Property of the Dataset itself</a></li>
<li><a href=#performance-of-classifier>Performance of Classifier</a></li>
</ul>
</li>
<li><a href=#confused-by-the-names>Confused by the Names?</a></li>
</ul>
</nav>
</div>
</div>
</details>
</div>
</div>
</article>
</div>
<script>const el=document.querySelector('details summary');el.onclick=()=>{(function(f,c,d,e,a,b){a=c.createElement(d),b=c.getElementsByTagName(d)[0],a.async=1,a.src=e,b.parentNode.insertBefore(a,b)})(window,document,'script','/js/smoothscroll.js'),el.onclick=null},document.querySelectorAll('#TableOfContents a').forEach(a=>{a.addEventListener('click',()=>{document.querySelector(a.href.slice(a.href.indexOf('#'))).scrollIntoView({behavior:'smooth'})})})</script>
<div class=is-divider data-content=REFERENCES></div>
<div class="box is-size-7">
<article class=media>
<div class=media-content style=width:100%;word-break:break-word>
<div class=content>
<p>
<strong><i class="fa-solid fa-quote-left"></i> References: </strong><br>
<ol>
<li class=has-text-weight-bold><a href=https://doi.org/10.1016/j.patrec.2005.10.010 style=text-decoration:none>Fawcett, T. (2006). An introduction to ROC analysis. Pattern Recognition Letters, 27(8), 861â€“874.</a></li>
<li class=has-text-weight-bold><a href=https://en.wikipedia.org/wiki/Confusion_matrix#Table_of_confusion style=text-decoration:none>Confusion_matrix#Table_of_confusion @ Wikipedia</a></li>
<li class=has-text-weight-bold><a href=https://en.wikipedia.org/wiki/F1_score style=text-decoration:none>F1 Score</a></li>
</ol>
</p>
</div>
</div>
</article>
</div>
<div class=is-divider data-content=CONNECTUME></div>
<div class="box is-size-7">
<article class=media>
<div class=media-content style=width:100%>
<div class=content>
<p>
<strong><i class="fa-solid fa-fingerprint"></i> Current Ref: </strong><br>
<ul><li style=list-style:none>
<div>wiki/machine-learning/basics/confusion-matrix.md</div></li>
</ul>
</p>
</div>
</div>
</article>
</div>
<div class="box is-size-7">
<article class=media>
<div class=media-content>
<div class=content>
<p>
<strong><i class="fa-solid fa-turn-down"></i> Links from: </strong>
<div>
<a class=box href=https://datumorphism.leima.is/wiki/machine-learning/performance/roc/>
<div class=media-content>
<div class=content>
<div class="title is-6" style="padding-bottom:.8em;border-bottom:1px dotted #999">Receiver Operating Characteristics: ROC
<span style=float:right><i class="fa-solid fa-bookmark" style=color:#999></i></span>
</div>
<div style=font-size:80%>
ROC is used to judging the performance of classifiers
</div>
</div>
</div>
</a>
<a class=box href=https://datumorphism.leima.is/wiki/machine-learning/classification/classifier-chains/>
<div class=media-content>
<div class=content>
<div class="title is-6" style="padding-bottom:.8em;border-bottom:1px dotted #999">Classifier Chains for Multilabel Classification
<span style=float:right><i class="fa-solid fa-bookmark" style=color:#999></i></span>
</div>
<div style=font-size:80%>
Classifier chains is a method to predict hierarchical class labels
</div>
</div>
</div>
</a>
</div>
</p>
</div>
</div>
</article>
</div>
<div class="box is-size-7">
<article class=media>
<div class=media-content>
<div class=content>
<p>
<strong><i class="fa-solid fa-turn-up"></i> Links to: </strong>
<div>
<a class=box href=https://datumorphism.leima.is/wiki/statistical-hypothesis-testing/type-1-error-and-type-2-error/>
<div class=media-content>
<div class=content>
<div class="title is-6" style="padding-bottom:.8em;border-bottom:1px dotted #999">Types of Errors in Statistical Hypothesis Testing
<span style=float:right><i class="fa-solid fa-bookmark" style=color:#999></i></span>
</div>
<div style=font-size:80%>
We all make mistakes. The question is, what kind of mistakes.
</div>
</div>
</div>
</a>
</div>
</p>
</div>
</div>
</article>
</div>
<div id=comments class=is-divider data-content=COMMENTS>
</div>
<script src=https://giscus.app/client.js data-repo=datumorphism/comments data-repo-id="MDEwOlJlcG9zaXRvcnkxNjU5MDkyNDI=" data-category=Comments data-category-id=DIC_kwDOCeOS-s4B-Zxx data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=1 data-theme=light crossorigin=anonymous async></script>
</div>
</div>
</article>
</div>
</section>
</div>
<div class=navtools>
<a class="button is-primary is-light is-outlined" title alt="Edit this page" href=https://github.com/datumorphism/datumorphism.github.io/edit/hugo/content/wiki/machine-learning/basics/confusion-matrix.md target=blank style=position:fixed;bottom:20px;right:10px;border-radius:9999px;width:35px;height:35px>
<i class="fas fa-pencil-alt"></i>
</a>
<a class="button is-primary is-light is-outlined" href=#comments alt=Comments style=position:fixed;bottom:60px;right:10px;border-radius:9999px;width:35px;height:35px>
<i class="far fa-comments"></i>
</a>
</div>
</main>
<footer>
<footer class=footer>
<div class=container>
<div class="content has-text-centered">
<p>
Created and maintained by <a href=https://leima.is>L Ma</a>.
Acknowledgement: <a href=https://gohugo.io/>Hugo</a>,
<a href=https://themes.gohugo.io/bulma/>Bulma</a>, <a href=https://kausalflow.com>KausalFlow</a>.
<strong>love</strong>.
<br>
<a class=tag href=/about>About</a>
<a class=tag href=/index.xml>Feed</a>
<a class=tag href=/data.json>JSON Data</a>
</p>
</div>
</div>
</footer>
</footer>
<script async type=text/javascript src=/js/bulma.js></script>
</body>
</html>