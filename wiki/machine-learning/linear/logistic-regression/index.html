<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.69.2"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Logistic Regression | Datumorphism | Lei Ma</title><meta name=description content="logistics regression is a simple model for classification"><meta name=author content="Lei Ma"><meta property="og:title" content="Logistic Regression"><meta property="og:description" content="logistics regression is a simple model for classification"><meta property="og:type" content="article"><meta property="og:url" content="https://datumorphism.leima.is/wiki/machine-learning/linear/logistic-regression/"><meta property="article:published_time" content="2021-05-27T00:00:00+00:00"><meta property="article:modified_time" content="2021-05-27T00:00:00+00:00"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-140452515-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><link rel=canonical href=https://datumorphism.leima.is/wiki/machine-learning/linear/logistic-regression/><link rel="shortcut icon" type=image/png href=/logos/logo-square.png><link rel=stylesheet href=/css/bulma.css><link rel=stylesheet href=/css/bulma-divider.min.css><link rel=stylesheet href=/assets/css/bulma-ribbon.min.css><link rel=stylesheet href=/assets/css/tooltip.css><link rel=stylesheet href=https://jenil.github.io/bulmaswatch/united/bulmaswatch.min.css><link rel=stylesheet href=/css/custom.css><link rel=stylesheet href=/css/blog-post.css><link rel=stylesheet href=/css/code-highlighting/dark.css><link rel=stylesheet href=/css/custom.css><link rel=stylesheet href=https://unpkg.com/applause-button/dist/applause-button.css><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],tags:'ams',processEscapes:true,processEnvironments:true},options:{skipHtmlTags:['script','noscript','style','textarea','pre']},svg:{fontCache:'global'}};window.addEventListener('load',(event)=>{document.querySelectorAll("mjx-container").forEach(function(x){x.parentElement.classList+='has-jax'})});</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>mermaid.initialize({startOnLoad:true});</script><script src=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/js/all.min.js integrity="sha256-KzZiKy0DWYsnwMF+X1DvQngQ2/FxF7MF3Ff72XcpuPs=" crossorigin=anonymous></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin=anonymous></head><body><header><nav class="navbar is-transparent"><div class=navbar-brand><a class=navbar-item href=/><img src=/site/intelligence.png alt=Datumorphism height=28 style=margin-right:.5em> Datumorphism</a><div class="navbar-burger burger" style=color:#000 data-target=navMenu><span></span><span></span><span></span></div></div><div class=navbar-menu id=navMenu><div class=navbar-start><div class="navbar-item has-dropdown is-hoverable"><a href=/projects class=navbar-link>Notebooks</a><div class=navbar-dropdown><a href=https://datumorphism.leima.is/awesome/ class=navbar-item>Awesome</a>
<a href=https://datumorphism.leima.is/blog/ class=navbar-item>Blog</a>
<a href=https://datumorphism.leima.is/cards/ class=navbar-item>Cards</a>
<a href=https://datumorphism.leima.is/hologram/ class=navbar-item>Hologram</a>
<a href=https://datumorphism.leima.is/reading/ class=navbar-item>Reading Notes</a>
<a href=https://datumorphism.leima.is/til/ class=navbar-item>TIL</a>
<a href=https://datumorphism.leima.is/wiki/ class=navbar-item>Wiki</a></div></div></div><span class=navbar-burger><span></span><span></span><span></span></span><div class=navbar-end><div class=navbar-item><a class=navbar-item href=/blog/>Blog</a>
<a class=navbar-item href=/><i class="fas fa-search"></i></a><a class=navbar-item href=/tags/><i class="fas fa-tags"></i></a><a class=navbar-item href=/graph><i class="fas fa-project-diagram"></i></a><a class=navbar-item href=https://t.me/amneumarkt><i class="fab fa-telegram"></i></a><a class=navbar-item target=blank href=https://github.com/datumorphism><span class=icon><i class="fab fa-github"></i></span></a></div></div></div></nav><script>document.addEventListener('DOMContentLoaded',()=>{const $navbarBurgers=Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'),0);if($navbarBurgers.length>0){$navbarBurgers.forEach(el=>{el.addEventListener('click',()=>{const target=el.dataset.target;const $target=document.getElementById(target);el.classList.toggle('is-active');$target.classList.toggle('is-active');});});}});</script></header><main><div class=container itemscope itemtype=http://schema.org/BlogPosting><meta itemprop=name content="Logistic Regression"><meta itemprop=description content="logistics regression is a simple model for classification"><meta itemprop=datePublished content="2021-05-27T00:00:00+00:00"><meta itemprop=dateModified content="2021-05-27T00:00:00+00:00"><meta itemprop=wordCount content="432"><meta itemprop=keywords content="Unsupervised Learning,Statistical Learning,Basics,Linear Models,Supervised Learning,Classification,"><section class=section><div class=container><article class=post><header class=post-header><nav class="breadcrumb has-succeeds-separator is-small" aria-label=breadcrumbs><ul><li><a href=https://datumorphism.leima.is/>Datumorphism</a></li><li><a href=https://datumorphism.leima.is/wiki/>Wiki</a></li><li><a href=https://datumorphism.leima.is/wiki/machine-learning/>Machine Learning</a></li><li><a href=https://datumorphism.leima.is/wiki/machine-learning/linear/>Linear Models</a></li><li class=active><a href=https://datumorphism.leima.is/wiki/machine-learning/linear/logistic-regression/>Logistic Regression</a></li></ul></nav><h1 class="post-title has-text-centered is-size-1" itemprop="name headline">Logistic Regression</h1><h2 class="title is-6 has-text-centered"><i class="fas fa-tags" style=margin-right:.5em></i><a href=/tags/unsupervised-learning><span class="tag is-warning is-small is-light">#Unsupervised Learning</span></a>
<a href=/tags/statistical-learning><span class="tag is-warning is-small is-light">#Statistical Learning</span></a>
<a href=/tags/basics><span class="tag is-warning is-small is-light">#Basics</span></a>
<a href=/tags/linear-models><span class="tag is-warning is-small is-light">#Linear Models</span></a>
<a href=/tags/supervised-learning><span class="tag is-warning is-small is-light">#Supervised Learning</span></a>
<a href=/tags/classification><span class="tag is-warning is-small is-light">#Classification</span></a></h2></header><div class=columns><div class="column is-8"><div class=is-divider data-content=ARTICLE></div><div class="content blog-post section" itemprop=articleBody><p>In a classification problem, given a list of features values $x$ and their corresponding classes $\{c_i\}$, the posterior for of the classes, aka conditional probability of the classes, is</p><p>$$
p(C=c_i\mid X=x).
$$</p><article class="message is-info is-light"><div class=message-header><p>Likelihood</p></div><div class=message-body><p>The likelihood of the data is</p><p>$$
p(X=x\mid C=c_i).
$$</p></div></article><h2 id=logistic-regression-for-two-classes>Logistic Regression for Two Classes</h2><p>For two classes, the simplest model for the posterior is a linear model,</p><p>$$
\log \frac{p(C=c_1\mid X=x) }{p(C=c_2\mid X=x)} = \beta_0 + \beta_1 \cdot x,
$$</p><p>which is equivalent to</p><p>$$
p(C=c_1\mid X=x) = \exp\left(\beta_0 + \beta_1 \cdot x\right) p(C=c_2\mid X=x) .
$$</p><article class="message is-info is-light"><div class=message-header><p>Why</p></div><div class=message-body><p>The reason that we proposing a linear model for the quantity</p><p>$$
\log \frac{p(C=c_1\mid X=x) }{p(C=c_2\mid X=x)},
$$</p><p>is that it has a range from $-\infty$ to $\infty$ which matches the range of the linear model $ \beta_0 + \beta_1 \cdot x$.</p><p>We can also see in the following results that such relation guarantees that the conditional probabilities are restricted to 0 to 1 after applying the normalization constraint.</p></div></article><p>Using the normalization condition</p><p>$$
p(C=c_1\mid X=x) + p(C=c_2\mid X=x) = 1,
$$</p><p>we can derive the posterior for each classes</p><p>$$
\begin{align}
p(C=c_2\mid X=x) &= \frac{1}{1 +  \exp\left(\beta_0 + \beta_1 \cdot x\right)} \\
p(C=c_1\mid X=x) &= \frac{\exp\left(\beta_0 + \beta_1 \cdot x\right)}{1 + \exp\left(\beta_0 + \beta_1 \cdot x\right)}.
\end{align}
$$</p><figure><img src=../assets/logistic-regression/logistic_regression_two_class_probs.png alt="For simplicity, we are using $x'=\beta_0 + \beta_1 \cdot x$ in this figure."><figcaption><h4>The two conditional probabilities</h4><p>For simplicity, we are using $x'=\beta_0 + \beta_1 \cdot x$ in this figure.</p></figcaption></figure><article class="message is-info is-light"><div class=message-header><p>Limiting behavior</p></div><div class=message-body><ol><li>As $\beta_0 + \beta_1 \cdot x \to \infty$, we have $p(C=c_2\mid X=x) \to 0$ and $p(C=c_1\mid X=x)\to 1$.</li><li>As $\beta_0 + \beta_1 \cdot x \to 0$, we have $p(C=c_2\mid X=x) \to 0.5$ and $p(C=c_1\mid X=x)\to 0.5$.</li><li>As $\beta_0 + \beta_1 \cdot x \to -\infty$, we have $p(C=c_2\mid X=x) \to 1$ and $p(C=c_1\mid X=x)\to 0$.</li></ol></div></article><h2 id=logistic-regression-for-k-classes>Logistic Regression for $K$ Classes</h2><p>It is easily generalized to problems with $K$ classes.</p><p>$$
\begin{align}
p(C=c_K\mid X=x) &= \frac{1}{1 +  \sum_k\exp\left(\beta_{k0} + \beta_k \cdot x\right)} \\
p(C=c_k\mid X=x) &= \frac{\exp\left(\beta_{k0} + \beta_k \cdot x\right)}{1 + \sum_k\exp\left(\beta_{k0} + \beta_k \cdot x\right)}
\end{align}
$$</p><h2 id=why-not-non-linear>Why not non-linear</h2><p>The log of the posterior ratio can be more complex than linear models. In general, we have<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></p><p>$$
\log \frac{p(C=c_1\mid X=x) }{p(C=c_2\mid X=x)} = f(x),
$$</p><p>so that</p><p>$$
p(C=c_1\mid X=x) = \frac{\exp(f(x))}{ 1 + \exp(f(x)) }.
$$</p><p>The logistic regression model we mentioned in the previous sections require</p><p>$$
f(x) = \beta_0 + \beta_1 \cdot x.
$$</p><p>A more general additive model is</p><p>$$
f(x) = \sum_i f_i(x),
$$</p><p>where we can apply algorithms such as local scoring to fit such models<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>.</p><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p><a name=friedman2000 href=#friedman2000 style=text-decoration:none><span class="tag is-link is-light">friedman2000</span></a>
<a href=https://projecteuclid.org/journals/annals-of-statistics/volume-28/issue-2/Additive-logistic-regression--a-statistical-view-of-boosting-With/10.1214/aos/1016218223.full style=text-decoration:none>Friedman J, Hastie T, Tibshirani R. Additive Logistic Regression. The Annals of Statistics. 2000. pp. 337–374. doi:10.1214/aos/1016218223</a>
<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></div><p><div class="has-text-right is-size-7"><span class=icon><i class="fas fa-pencil-alt"></i></span>Published: <time datetime=2021-05-27T00:00:00+00:00>2021-05-27</time>
by <span itemprop=author>Lei Ma</span>;</div></p><div class=is-divider></div><nav class="pagination is-centered" role=navigation aria-label=pagination><a href="https://datumorphism.leima.is/wiki/machine-learning/linear/poisson-regression/?ref=footer" class=pagination-previous>« Poisson Regression</a></nav></div><div class="column is-4"><div class=is-divider data-content="Cite Me"></div><div class="box is-size-7 has-text-white has-background-black"><article class=media><div class=media-content><div class=content><p>Lei Ma
(2021). 'Logistic Regression', Datumorphism, 05 April. Available at: https://datumorphism.leima.is/wiki/machine-learning/linear/logistic-regression/.</p></div></div></article></div><style>#TableOfContents>ul{list-style-type:lower-greek;padding-left:0}#TableOfContents>ul>li ul{list-style-type:none;padding-left:1em}</style><div class=is-divider data-content=ToC></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><details><summary>Table of Contents</summary><div><div><nav id=TableOfContents><ul><li><a href=#logistic-regression-for-two-classes>Logistic Regression for Two Classes</a></li><li><a href=#logistic-regression-for-k-classes>Logistic Regression for $K$ Classes</a></li><li><a href=#why-not-non-linear>Why not non-linear</a></li></ul></nav></div></div></details></div></div></article></div><script>const el=document.querySelector('details summary')
el.onclick=()=>{(function(l,o,a,d,e,r){e=o.createElement(a),r=o.getElementsByTagName(a)[0];e.async=1;e.src=d;r.parentNode.insertBefore(e,r)})(window,document,'script','/js/smoothscroll.js');el.onclick=null}
document.querySelectorAll('#TableOfContents a').forEach(link=>{link.addEventListener('click',()=>{document.querySelector(link.href.slice(link.href.indexOf('#'))).scrollIntoView({behavior:'smooth'})})})</script><div class=is-divider data-content=REFERENCES></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><p><strong>References:</strong><br><ol><li class=has-text-weight-bold><a href="https://play.google.com/store/books/details?id=yPfZBwAAQBAJ" style=text-decoration:none>Hastie T, Tibshirani R, Friedman J. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Springer Science & Business Media; 2013. pp. 567–567. Available: https://play.google.com/store/books/details?id=yPfZBwAAQBAJ</a></li><li class=has-text-weight-bold><a name=friedman2000 href=#friedman2000 style=text-decoration:none><span class="tag is-link is-light">friedman2000</span></a>
<a href=https://projecteuclid.org/journals/annals-of-statistics/volume-28/issue-2/Additive-logistic-regression--a-statistical-view-of-boosting-With/10.1214/aos/1016218223.full style=text-decoration:none>Friedman J, Hastie T, Tibshirani R. Additive Logistic Regression. The Annals of Statistics. 2000. pp. 337–374. doi:10.1214/aos/1016218223</a></li></ol></p></div></div></article></div><div class=is-divider data-content=CONNECTUME></div><div class="box is-size-7"><article class=media><div class=media-content style=width:100%><div class=content><p><strong>Current Ref:</strong><br><ul><li style=list-style:none><div>wiki/machine-learning/linear/logistic-regression.md</div></li></ul></p></div></div></article></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><p><strong>Links to:</strong><div><a class=box href=https://datumorphism.leima.is/cards/statistics/likelihood/><div class=media-content><div class=content><h6>Likelihood</h6><p>Likelihood is not necessarily a pdf</p></div></div></a></div></p></div></div></article></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><p><strong>Links from:</strong><div><a class=box href=https://datumorphism.leima.is/wiki/machine-learning/performance/roc/><div class=media-content><div class=content><h6>Receiver Operating Characteristics: ROC</h6><p>ROC is used to judging the performance of classifiers</p></div></div></a></div></p></div></div></article></div><div id=comments class=is-divider data-content=COMMENTS></div><script src=https://giscus.app/client.js data-repo=datumorphism/comments data-repo-id="MDEwOlJlcG9zaXRvcnkxNjU5MDkyNDI=" data-category=Comments data-category-id=DIC_kwDOCeOS-s4B-Zxx data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=1 data-theme=light crossorigin=anonymous async></script></div></div></article></div></section></div><div class=navtools><a class="button is-primary is-light is-outlined" alt="Edit this page" href=https://github.com/datumorphism/datumorphism.github.io/edit/hugo/content/wiki/machine-learning/linear/logistic-regression.md target=blank style=position:fixed;bottom:20px;right:10px;border-radius:9999px;width:35px;height:35px><i class="fas fa-pencil-alt"></i></a><a class="button is-primary is-light is-outlined" href=#comments alt=Comments style=position:fixed;bottom:60px;right:10px;border-radius:9999px;width:35px;height:35px><i class="far fa-comments"></i></a></div></main><footer><footer class=footer><div class=container><div class="content has-text-centered"><p>Created and maintained by <a href=https://leima.is>Lei Ma</a>.
Acknowledgement: <a href=https://gohugo.io/>Hugo</a>,
<a href=https://themes.gohugo.io/bulma/>Bulma</a>, <a href=https://kausalflow.com>KausalFlow</a>.
<strong>love</strong>.<br><a class=tag href=/about>About</a>
<a class=tag href=/index.xml>Feed</a>
<a class=tag href=/data.json>JSON Data</a></p></div></div></footer><script src=https://unpkg.com/applause-button/dist/applause-button.js></script></footer><script async type=text/javascript src=/js/bulma.js></script></body></html>