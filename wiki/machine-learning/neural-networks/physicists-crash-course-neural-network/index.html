<!doctype html><html lang=en-us>
<head>
<meta name=generator content="Hugo 0.89.4">
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1">
<title> A Physicist's Crash Course on Artificial Neural Network | Datumorphism | L Ma </title>
<meta name=description content="A very very brief introduction to neural network for physicists">
<meta name=author content="L Ma">
<meta property="og:title" content="A Physicist's Crash Course on Artificial Neural Network">
<meta property="og:description" content="A very very brief introduction to neural network for physicists">
<meta property="og:type" content="article">
<meta property="og:url" content="https://datumorphism.leima.is/wiki/machine-learning/neural-networks/physicists-crash-course-neural-network/"><meta property="article:section" content="wiki">
<meta property="article:published_time" content="2015-05-02T00:00:00+00:00">
<meta property="article:modified_time" content="2015-05-02T00:00:00+00:00">
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-140452515-1','auto'),ga('send','pageview'))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
<link rel=canonical href=https://datumorphism.leima.is/wiki/machine-learning/neural-networks/physicists-crash-course-neural-network/> <link rel="shortcut icon" type=image/png href=/logos/logo-square.png>
<link rel=stylesheet href=/css/bulma.css>
<link rel=stylesheet href=/css/bulma-divider.min.css>
<link rel=stylesheet href=/assets/css/bulma-ribbon.min.css>
<link rel=stylesheet href=/assets/css/tooltip.css>
<link rel=stylesheet href=https://jenil.github.io/bulmaswatch/united/bulmaswatch.min.css>
<link rel=stylesheet href=/css/custom.css>
<link rel=stylesheet href=/css/blog-post.css>
<link rel=stylesheet href=/css/code-highlighting/dark.css>
<link rel=stylesheet href=/css/custom.css>
<link rel=stylesheet href=https://unpkg.com/applause-button/dist/applause-button.css>
<script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],tags:'ams',processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:['script','noscript','style','textarea','pre']},svg:{fontCache:'global'}},window.addEventListener('load',a=>{document.querySelectorAll("mjx-container").forEach(function(a){a.parentElement.classList+='has-jax'})})</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script>
<script>mermaid.initialize({startOnLoad:!0})</script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/js/all.min.js integrity="sha256-KzZiKy0DWYsnwMF+X1DvQngQ2/FxF7MF3Ff72XcpuPs=" crossorigin=anonymous></script>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin=anonymous>
</head>
<body>
<header> <nav class="navbar is-transparent">
<div class=navbar-brand>
<a class=navbar-item href=/>
<img src=/site/intelligence.png alt=Datumorphism height=28 style=margin-right:.5em> Datumorphism
</a>
<div class="navbar-burger burger" style=color:#000 data-target=navMenu>
<span></span>
<span></span>
<span></span>
</div>
</div>
<div class=navbar-menu id=navMenu>
<div class=navbar-start>
<div class="navbar-item has-dropdown is-hoverable">
<a href=/projects class=navbar-link>
Notebooks
</a>
<div class=navbar-dropdown>
<a href=https://datumorphism.leima.is/awesome/ class=navbar-item>
Awesome
</a>
<a href=https://datumorphism.leima.is/blog/ class=navbar-item>
Blog
</a>
<a href=https://datumorphism.leima.is/cards/ class=navbar-item>
Cards
</a>
<a href=https://datumorphism.leima.is/hologram/ class=navbar-item>
Hologram
</a>
<a href=https://datumorphism.leima.is/reading/ class=navbar-item>
Reading Notes
</a>
<a href=https://datumorphism.leima.is/til/ class=navbar-item>
TIL
</a>
<a href=https://datumorphism.leima.is/wiki/ class=navbar-item>
Wiki
</a>
</div>
</div>
<div class="navbar-item has-dropdown is-hoverable">
<a class=navbar-item href=https://neuronstar.kausalflow.com/cpe-docs/>
Probability Estimation
</a>
</div>
</div>
<span class=navbar-burger>
<span></span>
<span></span>
<span></span>
</span>
<div class=navbar-end>
<div class=navbar-item>
<a class=navbar-item href=/blog/>
Blog
</a>
<a class=navbar-item href=/amneumarkt/>
AmNeumarkt
</a>
<a class=navbar-item href=/>
<i class="fas fa-search"></i>
</a>
<a class=navbar-item href=/tags/>
<i class="fas fa-tags"></i>
</a>
<a class=navbar-item href=/graph>
<i class="fas fa-project-diagram"></i>
</a>
<a class=navbar-item href=https://t.me/amneumarkt>
<i class="fab fa-telegram"></i>
</a>
<a class=navbar-item target=blank href=https://github.com/datumorphism>
<span class=icon>
<i class="fab fa-github"></i>
</span>
</a>
</div>
</div>
</div>
</nav>
<script>document.addEventListener('DOMContentLoaded',()=>{const a=Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'),0);a.length>0&&a.forEach(a=>{a.addEventListener('click',()=>{const b=a.dataset.target,c=document.getElementById(b);a.classList.toggle('is-active'),c.classList.toggle('is-active')})})})</script>
</header>
<main>
<div class=container itemscope itemtype=http://schema.org/BlogPosting>
<meta itemprop=name content="A Physicist's Crash Course on Artificial Neural Network">
<meta itemprop=description content="A very very brief introduction to neural network for physicists"><meta itemprop=datePublished content="2015-05-02T00:00:00+00:00">
<meta itemprop=dateModified content="2015-05-02T00:00:00+00:00">
<meta itemprop=wordCount content="1418">
<meta itemprop=keywords content="Machine Learning,Artificial Neural Networks,Basics,">
<section class=section>
<div class=container>
<article class=post>
<header class=post-header>
<nav class="breadcrumb has-succeeds-separator is-small" aria-label=breadcrumbs>
<ul>
<li>
<a href=https://datumorphism.leima.is/>Datumorphism</a>
</li>
<li>
<a href=https://datumorphism.leima.is/wiki/>Wiki</a>
</li>
<li>
<a href=https://datumorphism.leima.is/wiki/machine-learning/>Machine Learning</a>
</li>
<li>
<a href=https://datumorphism.leima.is/wiki/machine-learning/neural-networks/>Artificial Neural Networks</a>
</li>
<li class=active>
<a href=https://datumorphism.leima.is/wiki/machine-learning/neural-networks/physicists-crash-course-neural-network/>A Physicist's Crash Course on Artificial Neural Network</a>
</li>
</ul>
</nav>
<h1 class="post-title has-text-centered is-size-1" itemprop="name headline">
A Physicist's Crash Course on Artificial Neural Network
</h1>
<h2 class="title is-6 has-text-centered">
<i class="fas fa-tags" style=margin-right:.5em></i>
<a href=/tags/machine-learning><span class="tag is-warning is-small is-light">#Machine Learning</span></a>
<a href=/tags/artificial-neural-networks><span class="tag is-warning is-small is-light">#Artificial Neural Networks</span></a>
<a href=/tags/basics><span class="tag is-warning is-small is-light">#Basics</span></a>
</h2>
</header>
<div class=columns>
<div class="column is-8">
<div class=is-divider data-content=NOTIFICATION></div>
<div class="notification is-warning is-light">
<p>
This is the notes for a class presentation when I was a student.
</p>
</div>
<div class=is-divider data-content=ARTICLE></div>
<div class="content blog-post section" itemprop=articleBody>
<h2 id=what-is-a-neuron>What is a Neuron</h2>
<p>What a neuron does is to response when a stimulation is given. This response could be strong or weak or even null. If I would draw a figure, of this behavior, it looks like this.</p>
<figure><img src=../assets/physicists-crash-course-neural-network/neuron-response.png><figcaption>
<h4>Neuron response</h4>
</figcaption>
</figure>
<p>Using simple single neuron responses, we could compose complicated responses. To achieve that, we study the transformations of the response first.</p>
<figure><img src=../assets/physicists-crash-course-neural-network/transformation-activation.png><figcaption>
<h4>transformations</h4>
</figcaption>
</figure>
<h2 id=artificial-neural-network>Artificial Neural Network</h2>
<p>A simple network is a collection of neurons that response to stimulations, which could be the responses of other neurons.</p>
<figure><img src=../assets/physicists-crash-course-neural-network/neural-network-simple.png><figcaption>
<h4>neural network</h4>
</figcaption>
</figure>
<p>A given input signal is spreaded onto three different neurons. The neurons respond to this signal separately then summed together with different weights. In the language of math, given input $x$, output $y(x)$ is</p>
<p>$$ y(x) = \sum_{k=1}^{3} x v_k * \text{activation}( w_k * x + u_k ) $$</p>
<p>where $\text{activation}$ is the activation function, i.e., the response behavior of the neuron. This is a single layer structure.</p>
<p>A lot of different ways could be used to extend this network.</p>
<ul>
<li>Increase the number of neurons on one layer.</li>
<li>One can extend the number of layers.</li>
</ul>
<figure><img src=../assets/physicists-crash-course-neural-network/multilayer.png><figcaption>
<h4>Multilayer</h4>
</figcaption>
</figure>
<ul>
<li>We could also include interactions between the neurons.</li>
<li>Even memory can be simulated.</li>
</ul>
<h2 id=how-it-works>How it works</h2>
<p>Here is an example of how the network works.</p>
<p>We are going to do two things.</p>
<ol>
<li>Find out which temperature is hot which is cold.</li>
<li>Find out which room is habitable in terms of temperature.</li>
</ol>
<p>The first task can be done using one neuron. If a set of parameters are properly chosen, a single neuron will finish the task.</p>
<p>We have a input temperature and a output that tells us which is high temperature which is low temperature. In the following example, $T_1$ is low temperature, $T_2$, $T_3$ are high temperatures.</p>
<figure><img src=../assets/physicists-crash-course-neural-network/one-neuron-classification.png><figcaption>
<h4>one neuron classification</h4>
</figcaption>
</figure>
<p>Suppose we have only two neurons in the network.</p>
<figure><img src=../assets/physicists-crash-course-neural-network/two-neuron-network.png><figcaption>
<h4>two neuron classification</h4>
</figcaption>
</figure>
<p>Seen from this example, we can expect neural network to be good at classification.</p>
<p>And how is this going to help us with the identification of habitable places? Suppose we have three room with temperature $T_1$, $T_2$, $T_3$ respectively. Only $T_2$ falls into the region of high output value which corresponds to the habitable temperature in our net.</p>
<figure><img src=../assets/physicists-crash-course-neural-network/two-neuron-classification-result.png><figcaption>
<h4>two neuron classification</h4>
</figcaption>
</figure>
<p>That reminds me of Fourier Analysis. And there is a connection. The activation functions here, which is for a general purpose, are chosen to be universal approximators. These activations can be used to approximate all smooth functions well using a finite number of neurons. Fourier analysis, on the other hand requires infinite to be exact. However in some cases we don&rsquo;t need infinite Fourier terms as we only need a good approximation.</p>
<h2 id=training>Training</h2>
<p>We have got a lot of parameters with the set up of the network. The parameters are the degree of freedom we have. <strong>The question is how to get the right parameters.</strong></p>
<p>The Network NEEDS TRAINING. Just like human learning, the neural network have to be trained using prepared data. One example would be</p>
<table>
<thead>
<tr>
<th style=text-align:center>input</th>
<th style=text-align:center>0</th>
<th style=text-align:center>1</th>
<th style=text-align:center>2</th>
<th style=text-align:center>3</th>
<th style=text-align:center>4</th>
<th style=text-align:center>5</th>
<th style=text-align:center>6</th>
<th style=text-align:center>7</th>
<th style=text-align:center>8</th>
<th style=text-align:center>9</th>
</tr>
</thead>
<tbody>
<tr>
<td style=text-align:center>output</td>
<td style=text-align:center>1</td>
<td style=text-align:center>0.37</td>
<td style=text-align:center>0.14</td>
<td style=text-align:center>0.050</td>
<td style=text-align:center>0.018</td>
<td style=text-align:center>0.0067</td>
<td style=text-align:center>0.0025</td>
<td style=text-align:center>0.00091</td>
<td style=text-align:center>0.0004</td>
<td style=text-align:center>0.00012</td>
</tr>
</tbody>
</table>
<p>This set of data, to have some insight, a human would put them on a plot.</p>
<figure><img src=../assets/physicists-crash-course-neural-network/data-points.png>
</figure>
<blockquote>
<p>Data</p>
<pre tabindex=0><code>thTrainingData1 = np.array([[0,1,2,3,4,5,6,7,8,9],[1,0.37,0.14,0.050,0.018,0.0067,0.0025,0.00091,0.0004,0.00012]])
plt.figure(figsize=(15,9))
plt.plot(thTrainingData1[0],thTrainingData1[1],'bs')
plt.title(&quot;We have data&quot;)
plt.show()
</code></pre></blockquote>
<p>A well-trained human immediately recognizes the pattern, which is somewhat close to a exponential decay behavior. However, we wouldn&rsquo;t do any numerical calculation of exponential functions. We just see it because we have seen a lot.</p>
<p>We also expect that if we have one more data point from the same mechanism to be placed on the graph, it should appear near a line of exponential decay.</p>
<figure><img src=../assets/physicists-crash-course-neural-network/data-fit.png>
</figure>
<blockquote>
<p>Data</p>
<pre tabindex=0><code>plt.figure(figsize=(15,9))
plt.plot(thTrainingData1[0],thTrainingData1[1],'bs',label='Old Data')
plt.plot(np.linspace(0,9,100),np.exp(-np.linspace(0,9,100)),'m',label='Exponential')
plt.plot(np.array([1.5]),np.array([0.21]),'ro',label='New Data')
plt.title(&quot;We have got new data&quot;)
plt.legend()
plt.show()
</code></pre></blockquote>
<p>OK. A red data point appears on the graph. It is close to the line of $f(x)=e^{-x}$. Not exactly on the line but close.</p>
<p>How do we teach a machine to do that? Train it using these 10 data point we have now.</p>
<p>We feed in one input, $0$, the net will give us a result. However, the result is not $1$ in general. Then we change the parameters until we have the output as $1$. We feed in another input $1$, and change the parameters until we have $0.37$. Hence the final outcome of this training process is that the machine gives us the right result given input in the data we have know.</p>
<p>After the training, we get a set of parameters, which should be preserved. This is the structure we need. The machine has learned everything.</p>
<p>Now keep the parameters fixed. Feed in a number $1.5$, the result from the net should be close to $2.2$. Now the net also learn the behavior of the data, nonetheless without calculating any exponential functions.</p>
<p>This is amazing. The machine doesn&rsquo;t have any idea of exponential but it can know the trend.</p>
<h2 id=problems>Problems</h2>
<p>Just as a human would do, the net can make mistakes. One of them is over-training. If we don&rsquo;t have enough degree of freedom and given to many data points, the network could be over-trained. It is going to be stubborn and resist to give the right trend.</p>
<h2 id=code-practice>Code Practice</h2>
<h3 id=solving-a-simple-differential-equation>Solving A Simple Differential Equation</h3>
<p>The problem to solve is the differential equation $\frac{d}{dt}y(t)= - y(t).$ Using the network, this is $$y_i= 1+t_i v_k f(t_i w_k+u_k).$$</p>
<p>The procedures are</p>
<p><strong>Deal with the function first.</strong></p>
<ol>
<li>
<p>The cost is $I=\sum_i\left( \frac{dy_i}{dt}+y_i \right)^2.$ Our purpose is to minimize this cost.</p>
</li>
<li>
<p>To calculate the differential of y, we can write down the explicit expression for it.</p>
<p>$$\frac{dy}{dt} = v_k f(t w_k+u_k) + t v_k f(tw_k+u_k) (1-f(tw_k+u_k))w_k,$$</p>
<p>where the function f is defined as a <code>trigf()</code>.</p>
</li>
<li>
<p>So the cost becomes</p>
<p>$$I = \sum_i \left( v_k f(t w_k+u_k) + t v_k f(tw_k+u_k) (1-f(tw_k+u_k)) w_k + y \right)^2.$$</p>
</li>
</ol>
<pre tabindex=0><code>def cost(v,w,u,t):
    v = np.array(v)   # Don't know why but np.asarray(v) doesn't work here.
    w = np.array(w)
    u = np.array(u)

    fvec = np.array(trigf(t*w + u) )  # This is a vector!!!
    yt = 1 + np.sum ( t * v * fvec  )  # For a given t, this calculates the value of y(t), given the parameters, v, w, u.

    return  ( np.sum (v*fvec + t * v* fvec * ( 1 -  fvec  ) * w ) + yt )   ** 2

    # return np.sum(np.array( v*np.array( trigf( np.array( t*w ) + u ) ) )  +  np.array( t*np.array( v*np.array( trigf(np.array( t*w ) + u)) )  )  * ( 1 - np.array( trigf( np.array( t*w )+u) ) ) * w + ( 1 + np.array( t*np.array( v*np.array( trigf( np.array(t*w)+u ) ) ) ) ) ) # trigf() should return an array with the same length of the input.
</code></pre><p><strong>Caution: a number times an array is not returned as array but instead as list. and list + list doesn&rsquo;t conserved the length of the list!</strong></p>
<p>Define the trigf() next, usually we use $$trigf(x)=\frac{1}{1+\exp(-x)}$$.</p>
<pre tabindex=0><code>def trigf(x):
    #return 1/(1+np.exp(-x)) #
    return expit(x)
</code></pre><p>Test cost function:</p>
<pre tabindex=0><code>test11 = np.ones(30)
cost(np.array([1,1,1]),[1,1,1],[1,1,1],1)
</code></pre><p>Next step is to optimize this cost. To do this we need the derivitive. But anyway let&rsquo;s try a simple minimization first.</p>
<pre tabindex=0><code>def costTotal(v,w,u,t):
    t = np.array(t)
    costt = 0
    for temp in t:
        costt = costt + cost(v,w,u,temp)

    return costt
</code></pre><p>Test total cost</p>
<pre tabindex=0><code>test11 = np.ones(30)
tlintest = np.linspace(0,1,2)
print costTotal(np.ones(10),np.ones(10),2*np.ones(10),tlintest)
print costTotal(np.ones(10),np.ones(10),np.ones(10),tlintest)
</code></pre><p>Suppose the parameters are five-dimensional and we have 10 data points.</p>
<pre tabindex=0><code>tlin = np.linspace(0,5,11)
print tlin
</code></pre><p>Define a list divider that splits an array into three arrays.</p>
<pre tabindex=0><code>## No need to define such a function! Use np.split(x,3) instead.
np.zeros(30)
</code></pre><pre tabindex=0><code># This is only an example of 2dimensional neural network.
costTotalF = lambda x: costTotal(np.split(x,3)[0],np.split(x,3)[1],np.split(x,3)[2],tlin)

initGuess = np.zeros(30)
# initGuess = np.random.rand(1,30)+2
start1 = timeit.default_timer()
minim=minimize(costTotalF,initGuess,method=&quot;Nelder-Mead&quot;)
# minimize(costTotalF,initGuess,method=&quot;L-BFGS-B&quot;)
# minimize(costTotalF,initGuess,method=&quot;TNC&quot;)
stop1 = timeit.default_timer()

print stop1 - start1
</code></pre><p>It shows that the minimization depends greatly on the initial guess. It is not true for a simple scenario with gradient descent however it could be the case if the landscape is too complicated.</p>
<h3 id=test-results>Test Results</h3>
<p>Plot!</p>
<pre tabindex=0><code>def functionYNNSt(v,w,u,t): # t is a single scalar value

    t = np.array(t)

    return 1 +  np.sum(t * v * trigf( t*w +u ) )



def functionYNN(v,w,u,t):

    t = np.array(t)

    func = np.asarray([])

    for temp in t:
        func = np.append(func, functionYNNSt(v,w,u,temp) )

    return np.array(func)

def functionY(t):

    return np.exp(-t)


xresult=minim.x

# This is the output of neural network
temp14 = np.array([])
for i in np.linspace(0,5,110):
    temp14 = np.append(temp14,functionYNN(np.split(xresult,3)[0],np.split(xresult,3)[1],np.split(xresult,3)[2],np.array([i]))[0])

testTLin = np.linspace(0,5,110)
plt.figure(figsize=(15,9))
plt.plot(testTLin,functionY(testTLin),'bs',label='Exact Solution') # This is the exact solution to the differential equation
plt.plot(testTLin,temp14,'r-',label='ANN Result')
plt.title(&quot;Test the training&quot;)
plt.legend()
plt.show()
</code></pre><figure><img src=../assets/physicists-crash-course-neural-network/fit.png>
</figure>
</div>
<p><div class="has-text-right is-size-7">
<span class=icon>
<i class="fas fa-pencil-alt"></i>
</span>
Published: <time datetime=2015-05-02T00:00:00+00:00>2015-05-02</time>
by <span itemprop=author>L Ma</span>;
</div></p>
<div class=is-divider></div>
<nav class="pagination is-centered" role=navigation aria-label=pagination>
<a href="https://datumorphism.leima.is/wiki/machine-learning/neural-networks/artificial-neural-networks/?ref=footer" class=pagination-previous>« Artificial Neural Networks</a>
<a class=pagination-next href="https://datumorphism.leima.is/wiki/machine-learning/neural-networks/deep-autoregressive-networks/?ref=footer">Deep Autoregressive Network »</a>
</nav>
</div>
<div class="column is-4">
<div class=is-divider data-content="Cite Me"></div>
<div class="box is-size-7 has-text-white has-background-black">
<article class=media>
<div class=media-content>
<div class=content>
<p>
L Ma
(2015). 'A Physicist's Crash Course on Artificial Neural Network', Datumorphism, 05 April. Available at: https://datumorphism.leima.is/wiki/machine-learning/neural-networks/physicists-crash-course-neural-network/.
</p>
</div>
</div>
</article>
</div>
<style>#TableOfContents>ul{list-style-type:lower-greek;padding-left:0}#TableOfContents>ul>li ul{list-style-type:none;padding-left:1em}</style>
<div class=is-divider data-content=ToC></div>
<div class="box is-size-7">
<article class=media>
<div class=media-content>
<div class=content>
<details>
<summary>Table of Contents</summary>
<div>
<div>
<nav id=TableOfContents>
<ul>
<li><a href=#what-is-a-neuron>What is a Neuron</a></li>
<li><a href=#artificial-neural-network>Artificial Neural Network</a></li>
<li><a href=#how-it-works>How it works</a></li>
<li><a href=#training>Training</a></li>
<li><a href=#problems>Problems</a></li>
<li><a href=#code-practice>Code Practice</a>
<ul>
<li><a href=#solving-a-simple-differential-equation>Solving A Simple Differential Equation</a></li>
<li><a href=#test-results>Test Results</a></li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</details>
</div>
</div>
</article>
</div>
<script>const el=document.querySelector('details summary');el.onclick=()=>{(function(f,c,d,e,a,b){a=c.createElement(d),b=c.getElementsByTagName(d)[0],a.async=1,a.src=e,b.parentNode.insertBefore(a,b)})(window,document,'script','/js/smoothscroll.js'),el.onclick=null},document.querySelectorAll('#TableOfContents a').forEach(a=>{a.addEventListener('click',()=>{document.querySelector(a.href.slice(a.href.indexOf('#'))).scrollIntoView({behavior:'smooth'})})})</script>
<div class=is-divider data-content=REFERENCES></div>
<div class="box is-size-7">
<article class=media>
<div class=media-content>
<div class=content>
<p>
<strong>References: </strong><br>
<ol>
<li class=has-text-weight-bold><a href style=text-decoration:none></a></li>
</ol>
</p>
</div>
</div>
</article>
</div>
<div class=is-divider data-content=CONNECTUME></div>
<div class="box is-size-7">
<article class=media>
<div class=media-content style=width:100%>
<div class=content>
<p>
<strong>Current Ref: </strong><br>
<ul><li style=list-style:none>
<div>wiki/machine-learning/neural-networks/physicists-crash-course-neural-network.md</div></li>
</ul>
</p>
</div>
</div>
</article>
</div>
<div id=comments class=is-divider data-content=COMMENTS>
</div>
<script src=https://giscus.app/client.js data-repo=datumorphism/comments data-repo-id="MDEwOlJlcG9zaXRvcnkxNjU5MDkyNDI=" data-category=Comments data-category-id=DIC_kwDOCeOS-s4B-Zxx data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=1 data-theme=light crossorigin=anonymous async></script>
</div>
</div>
</article>
</div>
</section>
</div>
<div class=navtools>
<a class="button is-primary is-light is-outlined" title alt="Edit this page" href=https://github.com/datumorphism/datumorphism.github.io/edit/hugo/content/wiki/machine-learning/neural-networks/physicists-crash-course-neural-network.md target=blank style=position:fixed;bottom:20px;right:10px;border-radius:9999px;width:35px;height:35px>
<i class="fas fa-pencil-alt"></i>
</a>
<a class="button is-primary is-light is-outlined" href=#comments alt=Comments style=position:fixed;bottom:60px;right:10px;border-radius:9999px;width:35px;height:35px>
<i class="far fa-comments"></i>
</a>
</div>
</main>
<footer>
<footer class=footer>
<div class=container>
<div class="content has-text-centered">
<p>
Created and maintained by <a href=https://leima.is>L Ma</a>.
Acknowledgement: <a href=https://gohugo.io/>Hugo</a>,
<a href=https://themes.gohugo.io/bulma/>Bulma</a>, <a href=https://kausalflow.com>KausalFlow</a>.
<strong>love</strong>.
<br>
<a class=tag href=/about>About</a>
<a class=tag href=/index.xml>Feed</a>
<a class=tag href=/data.json>JSON Data</a>
</p>
</div>
</div>
</footer>
<script src=https://unpkg.com/applause-button/dist/applause-button.js></script>
</footer>
<script async type=text/javascript src=/js/bulma.js></script>
</body>
</html>