<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.69.2"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Random Forest | Datumorphism | Lei Ma</title><meta name=description content="random forest in machine learning"><meta name=author content="Lei Ma"><meta property="og:title" content="Random Forest"><meta property="og:description" content="random forest in machine learning"><meta property="og:type" content="article"><meta property="og:url" content="/wiki/machine-learning/tree-based/random-forest/"><meta property="article:published_time" content="2019-12-25T00:00:00+00:00"><meta property="article:modified_time" content="2019-12-25T00:00:00+00:00"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-140452515-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><link rel=canonical href=/wiki/machine-learning/tree-based/random-forest/><link rel="shortcut icon" type=image/png href=/logos/logo-square.png><link rel=stylesheet href=/css/bulma.css><link rel=stylesheet href=/css/bulma-divider.min.css><link rel=stylesheet href=/assets/css/bulma-ribbon.min.css><link rel=stylesheet href=/assets/css/tooltip.css><link rel=stylesheet href=https://jenil.github.io/bulmaswatch/united/bulmaswatch.min.css><link rel=stylesheet href=/css/custom.css><link rel=stylesheet href=/css/blog-post.css><link rel=stylesheet href=/css/code-highlighting/dark.css><link rel=stylesheet href=/css/custom.css><link rel=stylesheet href=https://unpkg.com/applause-button/dist/applause-button.css><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],tags:'ams'},svg:{fontCache:'global'}};</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js></script><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>mermaid.initialize({startOnLoad:true});</script><script src=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/js/all.min.js integrity="sha256-KzZiKy0DWYsnwMF+X1DvQngQ2/FxF7MF3Ff72XcpuPs=" crossorigin=anonymous></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin=anonymous></head><body><header><nav class="navbar is-transparent"><div class=navbar-brand><a class=navbar-item href=/><img src=/site/intelligence.png alt=Datumorphism height=28 style=margin-right:.5em> Datumorphism</a><div class="navbar-burger burger" data-target=navMenu><span></span><span></span><span></span></div></div><div class=navbar-menu id=navMenu><div class=navbar-start><div class="navbar-item has-dropdown is-hoverable"><a href=/projects class=navbar-link>Notebooks</a><div class=navbar-dropdown><a href=/awesome/ class=navbar-item>Awesome</a>
<a href=/blog/ class=navbar-item>Blog</a>
<a href=/cards/ class=navbar-item>Cards</a>
<a href=/reading/ class=navbar-item>Reading Notes</a>
<a href=/til/ class=navbar-item>TIL</a>
<a href=/wiki/ class=navbar-item>Wiki</a></div></div></div><span class=navbar-burger><span></span><span></span><span></span></span><div class=navbar-end><div class=navbar-item><a class=navbar-item target=blank href=/blog/>Blog</a>
<a class=navbar-item target=blank href=/tags/>Tags</a>
<a class=navbar-item id=showModal><span class=icon><i class="fas fa-project-diagram"></i></span></a><a class=navbar-item target=blank href=https://github.com/datumorphism><span class=icon><i class="fab fa-github"></i></span></a></div></div></div></nav><script>document.addEventListener('DOMContentLoaded',()=>{const $navbarBurgers=Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'),0);if($navbarBurgers.length>0){$navbarBurgers.forEach(el=>{el.addEventListener('click',()=>{const target=el.dataset.target;const $target=document.getElementById(target);el.classList.toggle('is-active');$target.classList.toggle('is-active');});});}});</script></header><main><div class=container itemscope itemtype=http://schema.org/BlogPosting><meta itemprop=name content="Random Forest"><meta itemprop=description content="random forest in machine learning"><meta itemprop=datePublished content="2019-12-25T00:00:00+00:00"><meta itemprop=dateModified content="2019-12-25T00:00:00+00:00"><meta itemprop=wordCount content="809"><meta itemprop=keywords content="Decision Tree,Ensemble,Supervised Learning,Statistical Learning,Basics,"><section class=section><div class=container><article class=post><header class=post-header><nav class="breadcrumb has-succeeds-separator is-small" aria-label=breadcrumbs><ul><li><a href=/>Datumorphism</a></li><li><a href=/wiki/>Wiki</a></li><li><a href=/wiki/machine-learning/>Machine Learning</a></li><li><a href=/wiki/machine-learning/tree-based/>Tree-based Methods</a></li><li class=active><a href=/wiki/machine-learning/tree-based/random-forest/>Random Forest</a></li></ul></nav><h1 class="post-title has-text-centered is-size-1" itemprop="name headline">Random Forest</h1><h2 class="title is-6 has-text-centered"><i class="fas fa-tags" style=margin-right:.5em></i><a href=/tags/decision-tree><span class="tag is-warning is-small is-light">#Decision Tree</span></a>
<a href=/tags/ensemble><span class="tag is-warning is-small is-light">#Ensemble</span></a>
<a href=/tags/supervised-learning><span class="tag is-warning is-small is-light">#Supervised Learning</span></a>
<a href=/tags/statistical-learning><span class="tag is-warning is-small is-light">#Statistical Learning</span></a>
<a href=/tags/basics><span class="tag is-warning is-small is-light">#Basics</span></a></h2></header><div class=columns><div class="column is-8"><div class=is-divider data-content=ARTICLE></div><div class="content blog-post section" itemprop=articleBody><p>Random forest is an ensemble method based on decision trees. Instead of using one decision tree and model on all the features, the decision tree method can model on a random set of features (feature subspace) using many decision trees and make decisions by democratizing the trees.</p><p>Given a proper dataset $\mathscr D(\mathbf X, \mathbf y)$, the ensemble of trees is denoted as ${f_i(\mathbf X)}$, will predict an ensemble of results. There are several key ideas in random forests.</p><ol><li>Are the predicted results representative?</li><li>How to democratize the ensemble of results?</li><li>What determines the quality of the predictions?</li></ol><h2 id=margin-strength-and-correlations>Margin, Strength, and Correlations</h2><p>The margin of the model, the strength of the trees, and the correlation between the trees are crucial to answer the questions.</p><h3 id=margin>Margin</h3><p>The <strong>margin</strong> of the tree is defined as</p><p>$$
M(\mathbf X, \mathbf y) = P (f_i(\mathbf X)=\mathbf y ) - \operatorname{max}_{\mathbf j\neq \mathbf y} P ( f_i(\mathbf X) = \mathbf j ).
$$</p><p>The first term, $P (f_i(\mathbf X)=\mathbf y )$ is the probability of predicting the exact value in the dataset. It can be calculated using</p><p>$$
P (f_i(\mathbf X)=\mathbf y ) = \frac{sum_{i=1}^N I(f_i(\mathbf X) = \mathbf y)}{N},
$$</p><p>where $I$ is the indicator function that maps the correct predictions to 1 and the incorrect predictions to 0.</p><p>The term $P ( f_i(\mathbf X) = \mathbf j )$ is the probability of predicting other values $\mathbf j$. The second term $\operatorname{max}_{\mathbf j\neq \mathbf y} P ( f_i(\mathbf X) = \mathbf j )$ finds the maximum the the probabilities of predicting values $\mathbf j$ other than $\mathbf y$, i.e., the most probable predicted value other than the correct value.</p><p>Thus we expect that the ensemble predicts the correct result if $M(\mathbf X, \mathbf y)>0$.</p><p><strong>Notice that these probabilities are over the trees,</strong> i.e., the subscript $i$.</p><p>If all the predictions in all the trees are predicting the correct values $\mathbf y$, the margin will be 1. If all the predictions are not correct, the margin is -1. If we have two predicted values and probabilities of each of the predictions are equal, the margin is 0.</p><h3 id=strength>Strength</h3><p>The <strong>expectation values of the margin over the dataset is the strength</strong>, i.e.,</p><p>$$
s = E_{\mathscr D}[M(\mathbf X, \mathbf y)].
$$</p><h3 id=raw-margin>Raw Margin</h3><p>Instead of using the probability of the predictions in the margin, the indicator function itself is also a measure of how well the predictions are. The <strong>raw margin</strong> is then defined as</p><p>$$
M_{R,i}(\mathbf X, \mathbf y) = I (f_i(\mathbf X)=\mathbf y ) - \operatorname{max}_{\mathbf j\neq \mathbf y} I ( f_i(\mathbf X) = \mathbf j ).
$$</p><h3 id=correlation>Correlation</h3><p>The correlation between the trees is</p><p>$$
\rho_{ij} = \operatorname{corr}(M_{R,i}, M_{R,j}) = \frac{\operatorname{cov}(M_{R,i}, M_{R,j})}{\sigma_{M_{R,i}} \sigma_{M_{R,j}}} = \frac{E[(M_{R,i} - \bar M_{R,i})(M_{R,j} - \bar M_{R,j})]}{\sigma_{M_{R,i}} \sigma_{M_{R,j}}}.
$$</p><p>The correlation tells us how strong the two trees are correlated. If all trees are exactly the same, then the correlation is infinite, which means the ensemble is not doing the work.</p><p>To get a scalar value of the whole model, the average correlation $\bar \rho$ over all the possible pairs is calculated.</p><h2 id=predicting-power>Predicting Power</h2><p>The power of the ensemble can be measure by the generalization error,</p><p>$$
P_{err} = P_{\mathscr D}(M(\mathbf X, \mathbf y)&lt; 0),
$$</p><p>i.e., the probability of getting the correct answer over the whole dataset.</p><p>It has been proved that <strong>the ensemble will converge in the random forest as the number of trees gets large.</strong> And the generalization error is proven to be related to the strength and the mean correlation,</p><p>$$
P_{err} \leq \frac{\bar \rho (1-s^2) }{s^2}.
$$</p><p>We conclude that</p><ol><li><strong>The stronger the strength is, the lower the generalization error is.</strong></li><li><strong>The smaller the correlation is, the lower the generalization error is.</strong></li></ol><figure><img src=../assets/random-forest/rf_generalization_error.png alt="Upper Limit of generalization error as functions of $\bar \rho$ and $s$."><figcaption><p>Upper Limit of generalization error as functions of $\bar \rho$ and $s$.</p></figcaption></figure><h2 id=random-forest-regressor>Random Forest Regressor</h2><p>Similar to decision trees, a random forest can also be used as regressors. A similar conclusion about the regressors can be proved.</p><p>To see how the regressor works, we construct an artificial problem. The code can be accessed <a href=https://github.com/datumorphism/mini-code/blob/master/random_forest/random_forest_benchmark.ipynb>on GitHub</a>.</p><p>The data we will use is generated by sin function.</p><pre><code>X_sin = [[6*random()] for i in range(10000)]
y_sin = np.sin(X_sin)

X_sin_test = [[6*random()] for i in range(10000)]
y_sin_test = np.sin(X_sin_test)
</code></pre><p>A random forest model is constructed and a random search cross vaidation is applied</p><pre><code>model = RandomizedSearchCV(
    pipeline,
    cv=10,
    param_distributions = rf_random_grid,
    verbose=3,
    n_jobs=-1
)
</code></pre><figure><img src=../assets/random-forest/rf_on_sin_data.png alt="Random forest on a dataset generated by sin function. The rather dense dots are the predicted results. The black line is the ground truth."><figcaption><p>Random forest on a dataset generated by sin function. The rather dense dots are the predicted results. The black line is the ground truth.</p></figcaption></figure><p>The predictions at each data point is quite concentrated, as the convergence has been proved.</p><figure><img src=../assets/random-forest/boxplot_trees_rf_on_sin_data.png alt="Boxplot of the predicted results of the trees in the ensemble. The quantiles are small."><figcaption><p>Boxplot of the predicted results of the trees in the ensemble. The quantiles are small.</p></figcaption></figure><p>In fact, it has also been shown by G. Biau that as the number of estimators grows, the trees will be focusing more on the informative variables.</p></div><p><div class="has-text-right is-size-7"><span class=icon><i class="fas fa-pencil-alt"></i></span>Published: <time datetime=2019-12-25T00:00:00+00:00>2019-12-25</time>
by <span itemprop=author>Lei Ma</span>;</div></p><div class=is-divider></div><nav class="pagination is-centered" role=navigation aria-label=pagination><a href="/wiki/machine-learning/tree-based/decision-tree/?ref=footer" class=pagination-previous>« Decision Tree</a></nav></div><div class="column is-4"><style>#TableOfContents>ul{list-style-type:lower-greek;padding-left:0}#TableOfContents>ul>li ul{list-style-type:none;padding-left:1em}</style><div class=is-divider data-content=ToC></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><details><summary>Table of Contents</summary><div><div><nav id=TableOfContents><ul><li><a href=#margin-strength-and-correlations>Margin, Strength, and Correlations</a><ul><li><a href=#margin>Margin</a></li><li><a href=#strength>Strength</a></li><li><a href=#raw-margin>Raw Margin</a></li><li><a href=#correlation>Correlation</a></li></ul></li><li><a href=#predicting-power>Predicting Power</a></li><li><a href=#random-forest-regressor>Random Forest Regressor</a></li></ul></nav></div></div></details></div></div></article></div><script>const el=document.querySelector('details summary')
el.onclick=()=>{(function(l,o,a,d,e,r){e=o.createElement(a),r=o.getElementsByTagName(a)[0];e.async=1;e.src=d;r.parentNode.insertBefore(e,r)})(window,document,'script','/js/smoothscroll.js');el.onclick=null}
document.querySelectorAll('#TableOfContents a').forEach(link=>{link.addEventListener('click',()=>{document.querySelector(link.href.slice(link.href.indexOf('#'))).scrollIntoView({behavior:'smooth'})})})</script><div class=is-divider data-content=REFERENCES></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><p><strong>References:</strong><br><ol><li class=has-text-weight-bold><a href=https://doi.org/10.1023/A:101093340 style=text-decoration:none>Breiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.</a></li><li class=has-text-weight-bold><a href=https://doi.org/10.5555/2188385.2343682 style=text-decoration:none>Biau, G. (2012). Analysis of a Random Forests Model. J. Mach. Learn. Res., 13, 1063–1095.</a></li></ol></p></div></div></article></div><div class=is-divider data-content=SUPPLEMENTARY></div><div class="box is-size-7"><article class="media is-link"><div class=media-content><div class=content><p><strong>Supplementary:</strong><br><ol><li class=has-text-weight-bold><a href=https://github.com/datumorphism/mini-code/tree/master/random_forest style=text-decoration:none>Code used in this article</a></li></ol></p></div></div></article></div><div class=is-divider data-content=CONNECTUME></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><p><strong>Current Ref:</strong><br><ul><li style=list-style:none><span class="tag is-primary is-light has-text-weight-bold">wiki/machine-learning/tree-based/random-forest.md</span></li></ul></p></div></div></article></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><p><strong>Links to:</strong><ul><li class=has-text-weight-bold><a href=/cards/machine-learning/measurement/gini-impurity/>Gini Impurity</a></li><li class=has-text-weight-bold><a href=/cards/machine-learning/measurement/information-gain/>Information Gain</a></li><li class=has-text-weight-bold><a href=/wiki/machine-learning/tree-based/decision-tree/>Decision Tree</a></li></ul></p></div></div></article></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><p><strong>Links from:</strong><ul><li class=has-text-weight-bold><a href=/wiki/machine-learning/tree-based/decision-tree/>Decision Tree</a></li></ul></p></div></div></article></div><div id=comments class=is-divider data-content=COMMENTS></div><script src=https://utteranc.es/client.js repo=datumorphism/comments issue-term=pathname theme=github-light crossorigin=anonymous async></script></div></div></article></div></section></div><div class=navtools><a class="button is-primary is-light is-outlined" alt="Edit this page" href=https://github.com/datumorphism/datumorphism.github.io/edit/master/content/wiki/machine-learning/tree-based/random-forest.md target=blank style=position:fixed;bottom:20px;right:10px;border-radius:9999px;width:35px;height:35px><i class="fas fa-pencil-alt"></i></a><a class="button is-primary is-light is-outlined" href=#comments alt=Comments style=position:fixed;bottom:60px;right:10px;border-radius:9999px;width:35px;height:35px><i class="far fa-comments"></i></a><style>applause-button .count-container{top:-60%!important}</style><applause-button color=red multiclap=true style="width: 35px; height: 35px;position:fixed;bottom: 100px;right: 10px;"></div></main><footer><footer class=footer><div class=container><div class="content has-text-centered"><p>Created and maintained by <a href=/>Lei Ma</a>.
Acknowledgement: <a href=https://gohugo.io/>Hugo</a>,
<a href=https://themes.gohugo.io/bulma/>Bulma</a>, <a href=https://kausalflow.com>KausalFlow</a>.
<strong>love</strong>.<br><a class=tag href=/about>About</a>
<a class=tag href=/index.xml>Feed</a>
<a class=tag href=/data.json>JSON Data</a></p></div></div></footer><script src=https://unpkg.com/applause-button/dist/applause-button.js></script></footer><div class=modal><div class=modal-background></div><div class=modal-content><div id=network-graph style="margin-left:calc(50% - 50vw);width:100vw;height:100vh"></div></div><button class=modal-close style=color:#000>Close</button></div><script src=https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js></script><link href=/assets/network/netjsongraph.css rel=stylesheet><link href=/assets/network/netjsongraph-theme.css rel=stylesheet><script src=/assets/network/netjsongraph.js></script><script>d3.netJsonGraph("/network.json",{el:"#network-graph",metadata:true,linkDistance:100,linkStrength:1,charge:-1000,circleRadius:12,defaultStyle:false,linkClassProperty:"type",nodeClassProperty:"style",labelDy:"-1.8em"});</script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js></script><script>$("#showModal").click(function(){$(".modal").addClass("is-active");});$(".modal-close").click(function(){$(".modal").removeClass("is-active");});</script><script async type=text/javascript src=/js/bulma.js></script></body></html>