<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Spark on Datumorphism</title><link>https://datumorphism.leima.is/tags/spark/</link><description>Recent content in Spark on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Mon, 31 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://datumorphism.leima.is/tags/spark/index.xml" rel="self" type="application/rss+xml"/><item><title>Data Processing - (Py)Spark</title><link>https://datumorphism.leima.is/wiki/tools/data-processing-spark/</link><pubDate>Mon, 31 Jan 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/tools/data-processing-spark/</guid><description>Spark uses Resilient Distributed Dataset (RDD).
PySpark PySpark provides
SparkContext SparkSession A spark dataframe is immutable. This makes it tricky to update a dataframe.
Useful Commands Get Session In pyspark, we can also get or create the session using the following method.
pyspark.sql.SparkSession.builder.getOrCreate() List all Tables A pyspark.sql.SparkSession has property catalog and can be used to list the tables.
pyspark.sql.SparkSession.catalog.listTables() Run SQL Query Given a SQL query query, we can query the table using .sql() method of the session.
query = ... pyspark.sql.SparkSession.sql(query) Convert Dataframe to Pandas Dataframe .toPandas() Convert Pandas Dataframe to Spark Dataframe To create a spark dataframe from a pandas dataframe,</description></item></channel></rss>