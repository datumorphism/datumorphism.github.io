<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Perceptron on Datumorphism</title><link>https://datumorphism.leima.is/tags/perceptron/</link><description>Recent content in Perceptron on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Thu, 25 Feb 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://datumorphism.leima.is/tags/perceptron/index.xml" rel="self" type="application/rss+xml"/><item><title>Rosenblatt's Perceptron</title><link>https://datumorphism.leima.is/cards/machine-learning/neural-networks/rosenblatt-perceptron/</link><pubDate>Thu, 25 Feb 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/machine-learning/neural-networks/rosenblatt-perceptron/</guid><description>Rosenblatt&amp;rsquo;s perceptron connects McCulloch-Pitts neurons in levels.
Rosenblatt proposed that we fix all the weights and leave the weights of the last neuron free.
The first few layers but the last layer is used as a transformation of the input data ${x_1, \cdots, x_i, \cdots, x_N}$ into a new space ${z_1, \cdots, z_i, \cdots, z_{N&amp;rsquo;}}$. The classification is done on the ${z_1, \cdots, z_i, \cdots, z_{N&amp;rsquo;}}$ space by tuning the last neuron.</description></item></channel></rss>