<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>scipy on Datumorphism</title><link>https://datumorphism.leima.is/tags/scipy/</link><description>Recent content in scipy on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Sun, 07 Mar 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://datumorphism.leima.is/tags/scipy/index.xml" rel="self" type="application/rss+xml"/><item><title>Ordinary Differential Equations</title><link>https://datumorphism.leima.is/wiki/dynamical-system/ordinary-differential-method/</link><pubDate>Mon, 19 Nov 2018 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/dynamical-system/ordinary-differential-method/</guid><description>For a first order differentiation $\frac{\partial f}{\partial t}$, we might have many finite differencing methods.
Euler Method For linear first ODE,
$$ \frac{dy}{dx} = f(x, y), $$
we can discretize the equation using a step size $\delta x \cdot$ so that the differential equation becomes
$$ \frac{y_{n+1} - y_n }{ \delta x } = f(x_n, y_n), $$
which is also written as
$$ y_{n+1} = y_n + \delta x \cdot f(x_n, y_n). \label{euler-method-discretized-form-y-n-plus-1} $$
This is also called forward Euler differencing. It is first order accurate in $\Delta t$.
Generally speaking, a simple iteraction will do the work.
Adams' Method Taylor Expansion of Functions</description></item><item><title>Signal Processing: Audio Basics</title><link>https://datumorphism.leima.is/wiki/algorithms/signal-processing-audio/</link><pubDate>Thu, 29 Mar 2018 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/algorithms/signal-processing-audio/</guid><description>Keywords Harmonic structure of sound Parson code of music Linear time-invariant theory Autocorrelation Noise Chirps DCT compression Discrete Fourier transform filtering convolution Linear Time-Invariant System We describe the system with $Y(t) = f(X(t))$, where $X(t)$ is the input, and $Y(t)$ is the output.
Linear: $f(a X_1(t) + b X_2(t)) = a f(X_1(t)) + b f(X_2(t))$ Time-invariant: input $X(t+\Delta t)$ will produce the shifted signal $Y(t+\Delta t)$. LTI systems are memory systems, casual, real, and stable. Stable means the output won&amp;rsquo;t reach infinite if the input is finite. It&amp;rsquo;s bounded.
Impulse Response Suppose we have a impulse $X(t) = I(t)$, and output $h(t)$.</description></item><item><title>ANOVA</title><link>https://datumorphism.leima.is/wiki/statistics/anova/</link><pubDate>Sun, 07 Mar 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/statistics/anova/</guid><description>In many problems, we have to test if several distributions associated with several groups of experiments are the same. The null hypothesis to be used is
The distributions of several groups are the same.
ANOVA tests the null hypothesis by comparing the variability between groups and within groups. If the variability between groups are significantly larger than the variability within groups, we are more confident that the distributions of different groups are different.
We will use two-group experiments as an example. We use a fake dataset:
Group A $x^A_1$ $x^A_2$ &amp;hellip; $x^A_{N_A}$ Group B $x^B_1$ $x^B_2$ &amp;hellip; $x^B_{N_B}$ Within Group Variability The within group variability is proportional to</description></item></channel></rss>