<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Bayes on Datumorphism</title><link>https://datumorphism.leima.is/tags/bayes/</link><description>Recent content in Bayes on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Wed, 26 May 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://datumorphism.leima.is/tags/bayes/index.xml" rel="self" type="application/rss+xml"/><item><title>Likelihood</title><link>https://datumorphism.leima.is/cards/statistics/likelihood/</link><pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/statistics/likelihood/</guid><description>For some data points $\{x_i\}$ and a model $\theta$, the likelihood of our data point $x_i$ is $p(x_i\mid \theta)$. To be more specific, the likelihood of all data points is a function of the model $\theta$,
$$ L(\theta) = \Pi_i p(x_i\mid\theta). $$
It should be mentioned that this likelihood is not necessarily a pdf. As an example, we can calculate the likelihood of a Bernoulli distribution for a single event $x$,
$$ L(\theta) = \theta^x (1-\theta)^{(1-x)}. $$
If we are flipping coins, and the head $x=1$ probability is $\theta$, the likelihood for this single event $x=1$ is
$$ L(\theta)=\theta. $$</description></item></channel></rss>