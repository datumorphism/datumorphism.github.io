<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Information Bottleneck on Datumorphism</title><link>https://datumorphism.leima.is/tags/information-bottleneck/</link><description>Recent content in Information Bottleneck on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Sat, 30 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://datumorphism.leima.is/tags/information-bottleneck/index.xml" rel="self" type="application/rss+xml"/><item><title>Information Bottleneck</title><link>https://datumorphism.leima.is/wiki/learning-theory/information-bottleneck/</link><pubDate>Sat, 30 Apr 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/learning-theory/information-bottleneck/</guid><description>Information Bottleneck In a [[induction-deduction framework]] Induction, Deduction, and Transduction , for a given training dataset
$$ \{X, Y\}, $$
a prediction Markov chain1
$$ X \to \hat X \to Y, $$
where $\hat X$ is supposed to be the minimal sufficient statistics of $X$. $\hat X$ is the minimal data that can still represent the relation between $X$ and $Y$, i.e., $I(X;Y)$, the [[mutual information]] Mutual Information Mutual information is defined as $$ I(X;Y) = \mathbb E_{p_{XY}} \ln \frac{P_{XY}}{P_X P_Y}. $$ In the case that $X$ and $Y$ are independent variables, we have $P_{XY} = P_X P_Y$, thus $I(X;Y) = 0$.</description></item></channel></rss>