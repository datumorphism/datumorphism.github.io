<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Forecasting on Datumorphism</title><link>https://datumorphism.leima.is/tags/forecasting/</link><description>Recent content in Forecasting on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Mon, 28 Nov 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://datumorphism.leima.is/tags/forecasting/index.xml" rel="self" type="application/rss+xml"/><item><title>Prediction Space in Forecasting</title><link>https://datumorphism.leima.is/cards/forecasting/prediction-space/</link><pubDate>Fri, 08 Apr 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/forecasting/prediction-space/</guid><description>In a forecasting problem, we have
$\mathcal P$, the priors, e.g., price and demand is negatively correlated, $\mathcal D$, available dataset, $Y$, the observations, and $F$, the forecasts. Information Set $\mathcal A$
The priors $\mathcal D$ and the available data $\mathcal P$ can be summarized together as the information set $\mathcal A$. Under a probabilistic view, a forecaster will find out or approximate a CDF $\mathcal F$ such that1
$$ \mathcal F(Y\vert \mathcal D, \mathcal P) \to F. $$
Naively speaking, once the density $\rho(F, Y)$ is determined or estimated, a probabilistic forecaster can be formed.</description></item><item><title>Time Convolution</title><link>https://datumorphism.leima.is/cards/forecasting/time-convolution/</link><pubDate>Mon, 28 Nov 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/forecasting/time-convolution/</guid><description>The temporal convolution is responsible for capturing temporal patterns in a sequence.
Dilated Temporal Convolution Unit8 has a nice blog about temporal convolution and dilated temporal convolution1. In this
Convolutions Using Fourier Transform Convolution and Fourier transform Dilated Convolution For a convolution $$ f*h(x) = \sum_{s+t=x} f(s) h(t), $$ the dilated version of it is1 $$ f*_l h(x) = \sum_{s+t*l=x} f(s) h(t), $$ where $l$ is the dilation factor. Yu2015 Yu F, Koltun V. Multi-Scale Context Aggregation by Dilated Convolutions. arXiv [cs.CV]. 2015. Available: http://arxiv.org/abs/1511.07122 &amp;#160;&amp;#x21a9;&amp;#xfe0e; Inception A good convolutional network should capture both short-term and long-term patterns in the time series data.</description></item><item><title>Mix-hop Propagation in GNN</title><link>https://datumorphism.leima.is/cards/forecasting/gnn-mix-hop-propagation/</link><pubDate>Mon, 28 Nov 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/forecasting/gnn-mix-hop-propagation/</guid><description>The mix-hop propagation layer has two steps1:
information propagation step: $$ \mathbf H^{(k)} = \beta \mathbf H_{in} + (1-\beta)\mathbf L \mathbf H^{(k-1)}, $$
where $\mathbf L= (1+ \operatorname{A}) (\mathbf A + \mathbf I)$. This convolution step tries to disentangle the correlation between the nodes. information selection step: $$ \mathbf H_{out} = \sum_k \mathbf H^{(k)} \mathbf W^{(k)}. $$
See Fig 4 in the paper1.
Wu2020 Wu Z, Pan S, Long G, Jiang J, Chang X, Zhang C. Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2005.11650 &amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>Graph Structure Learning in GNN</title><link>https://datumorphism.leima.is/cards/forecasting/gnn-graph-structure-learning/</link><pubDate>Mon, 28 Nov 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/forecasting/gnn-graph-structure-learning/</guid><description>We extract the definitions in Wu et al., 20201. Given node embeddings $\mathbf E_i$1,
$$ \begin{align} \mathbf M_i &amp;= \tanh(\alpha \mathbf E_i \Theta_i) \\ \mathbf A &amp;= \operatorname{ReLU}(\tanh(\alpha (\mathbf M_1 \mathbf M_2^T - \mathbf M_2\mathbf M_1^T))), \end{align} $$
The author also proposed sparse requirement and only take the top-$k$ largest elements in $A$.
Wu2020 Wu Z, Pan S, Long G, Jiang J, Chang X, Zhang C. Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2005.11650 &amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>Forecasting</title><link>https://datumorphism.leima.is/wiki/forecasting/</link><pubDate>Sat, 12 Nov 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/forecasting/</guid><description/></item><item><title>MTGNN</title><link>https://datumorphism.leima.is/reading/mtgnn/</link><pubDate>Mon, 28 Nov 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/reading/mtgnn/</guid><description>Key Components Time Convolution (TC) Module Time Convolution The temporal convolution is responsible for capturing temporal patterns in a sequence. Graph Convolution Module Mix-hop Propagation in GNN Mix-hop is a strategy to avoid oversmoothing in GNN Graph Structure Learning Layer Graph Structure Learning in GNN We can learn a graph structure without prior knowledge Architecture Wu et al., 2020</description></item><item><title>Empirical Correlation Coefficient (CORR)</title><link>https://datumorphism.leima.is/cards/time-series/ts-corr/</link><pubDate>Sun, 21 Aug 2022 20:43:36 +0200</pubDate><guid>https://datumorphism.leima.is/cards/time-series/ts-corr/</guid><description>The Empirical Correlation Coefficient (CORR) is an evaluation metric in time series forecasting,1
$$ \mathrm{CORR} = \frac{1}{N} \sum_{i=1}^N \frac{ \sum_t (y^{(i)}_t - \bar y^{(i)} ) ( \hat y^{(i)}_t -\bar{ \hat y}^{(i)} ) }{ \sqrt{ \sum_t (y^{(i)}_t - \bar y^{(i)} )^2 ( \hat y^{(i)}_t -\bar{\hat y}^{(i)} )^2 } } $$
where $y^{(i)}$ is the $i$th time series, ${} _ t$ denotes the time step $t$, and $\bar y^{(i)}$ is the mean of the $i$th forecasted series, i.e., $\bar y^{(i)} = \operatorname{mean}( y^{(i)} _ { t \in \{T _ f, T _ {f+1}, \cdots T _ {f+H}\} } )$.
Lai2017 Lai G, Chang W-C, Yang Y, Liu H.</description></item><item><title>Root Relative Squared Error (RSE)</title><link>https://datumorphism.leima.is/cards/time-series/ts-rse/</link><pubDate>Sun, 21 Aug 2022 20:43:36 +0200</pubDate><guid>https://datumorphism.leima.is/cards/time-series/ts-rse/</guid><description>The Root Relative Squared Error (RSE) is an evaluation metric in time series forecasting,1
$$ \mathrm{RSE} = \frac{ \sqrt{ \sum_{i, t} ( y^{(i)}_t - \hat y^{(i)}_t )^2 } }{ \sqrt{ \sum_{i, t} ( y^{(i)}_t - \bar y )^2 } } $$
where $y^{(i)}$ is the $i$th time series, ${} _ t$ denotes the time step $t$, and $\bar y$ is the mean of the forecasted series, i.e., $\bar y = \operatorname{mean}(y^{(i\in\{0, 1, \cdots, N\})} _ { t\in \{T _ f, T _ {f+1}, \cdots T _ {f+H}\} })$.
Lai2017 Lai G, Chang W-C, Yang Y, Liu H.</description></item><item><title>Continuous Ranked Probability Score - CRPS</title><link>https://datumorphism.leima.is/cards/time-series/crps/</link><pubDate>Fri, 18 Mar 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/time-series/crps/</guid><description>The Continuous Ranked Probability Score, known as CRPS, is a score to measure how a proposed distribution approximates the data, without knowledge about the true distributions of the data.
Definition CRPS is defined as1
$$ CRPS(P, x_a) = \int_{-\infty}^\infty \lVert P(x) - H(x - x_a) \rVert_2 dx, $$
where
$x_a$ is the true value of $x$, P(x) is our proposed cumulative distribution for $x$, $H(x)$ is the Heaviside step function $$ H(x) = \begin{cases} 1, &amp;\qquad x=0\\ 0, &amp;\qquad x\leq 0\\ \end{cases} $$
$\lVert \cdot \rVert_2$ is the L2 norm. Explain it The formula looks abstract on first sight, but it becomes crystal clear once we understand it.</description></item><item><title>StemGNN</title><link>https://datumorphism.leima.is/reading/stemgnn/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/reading/stemgnn/</guid><description>What problem is StemGNN solving: intra-series temporal pattern: DFT Each series inter-series correlations At each step, the interactions between nodes reversible operator Example problem Covid cases: DE, AT, NL, &amp;hellip; Predicting each country without considering the interactions between them Or introduce the people flow between them GFT: Completes DFT as it takes care of the inter-series correlations one extra slide for this topic Convolutions on Graphs one extra slide for this topic Graph Basics How to build the graph &amp;ldquo;self-attention&amp;rdquo;: outer product of key, query, as the adjacency matrix key, query are of length # of ndoes Weights and Biases LC 1DConv GLU FC Experiments Traffic adjacency matrix neighbouring sensors have higher correlations Covid Neighbouring countries have higher correlation Spetral analysis: Some eigenvectors have clear meanings Week spots Paper and code are not consistent https://github.</description></item></channel></rss>