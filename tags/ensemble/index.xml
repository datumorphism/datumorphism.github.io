<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ensemble on Datumorphism</title><link>/tags/ensemble/</link><description>Recent content in Ensemble on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Wed, 25 Dec 2019 00:00:00 +0000</lastBuildDate><atom:link href="/tags/ensemble/index.xml" rel="self" type="application/rss+xml"/><item><title>Random Forest</title><link>/wiki/machine-learning/tree-based/random-forest/</link><pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate><guid>/wiki/machine-learning/tree-based/random-forest/</guid><description>Random forest is an ensemble method based on decision trees. Instead of using one decision tree and model on all the features, the decision tree method can model on a random set of features (feature subspace) using many decision trees and make decisions by democratizing the trees.
Given a proper dataset $\mathscr D(\mathbf X, \mathbf y)$, the ensemble of trees is denoted as ${f_i(\mathbf X)}$, will predict an ensemble of results.</description></item></channel></rss>