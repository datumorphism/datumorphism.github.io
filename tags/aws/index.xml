<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AWS on Datumorphism</title><link>https://datumorphism.leima.is/tags/aws/</link><description>Recent content in AWS on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Mon, 11 Mar 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://datumorphism.leima.is/tags/aws/index.xml" rel="self" type="application/rss+xml"/><item><title>Amazon CloudWatch Logs</title><link>https://datumorphism.leima.is/wiki/tools/awslogs/</link><pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/tools/awslogs/</guid><description>Why Suppose we have all kinds of pipelines written in different languages, using different tools, and located in different places. It would be frustrating to pull out the logs.
This is why we need a centralized log service, for example cloudwatch.
Sending logs to CloudWatch First of all, send your logs to awslogs. The easies way is to use boto.
Retrieving and Analyzing Logs First of all, we need this: awslogs. With the logs sent to cloudwatch, we then could read out the logs using the following command:
awslogs get etl-tools --start='1d ago' --timestamp --output text | grep error This will print out the logs 1 day ago.</description></item><item><title>Tools</title><link>https://datumorphism.leima.is/wiki/tools/</link><pubDate>Sat, 28 Aug 2021 00:03:10 +0200</pubDate><guid>https://datumorphism.leima.is/wiki/tools/</guid><description/></item></channel></rss>