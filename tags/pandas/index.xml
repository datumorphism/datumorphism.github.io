<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>pandas on Datumorphism</title><link>https://datumorphism.leima.is/tags/pandas/</link><description>Recent content in pandas on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Wed, 10 Mar 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://datumorphism.leima.is/tags/pandas/index.xml" rel="self" type="application/rss+xml"/><item><title>Binning Data Values using Pandas</title><link>https://datumorphism.leima.is/til/programming/pandas/pandas-binning-values/</link><pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/til/programming/pandas/pandas-binning-values/</guid><description>Use the pd.cut function. The bins argument is using (] are the segments. The official documentation comes with detailed examples.
If pandas is not an option, one could use numpy.digitize to find which bin the elements belong to.</description></item><item><title>Deal with Rare Categories Using Pandas</title><link>https://datumorphism.leima.is/til/data/deal-with-rare-categories-using-pandas/</link><pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/til/data/deal-with-rare-categories-using-pandas/</guid><description>We will illustrate how to deal with rare categories using pandas mask.
import pandas as pd ############# # Create fake names frequent_names = list(&amp;#39;ABC&amp;#39;) rare_names = list(&amp;#39;DEF&amp;#39;) dataset = sum( [[i]*10 for i in frequent_names] + [[i]*2 for i in rare_names], [] ) # Create a series based on the names series = pd.Series(dataset) print(series) # Find the counts of the names in the series series_counts = series.value_counts() print(series_counts) # Find names that has less than 10 counts # And create a mask mask = series.isin(series_counts.loc[series_counts&amp;lt;10].index) print(mask) # Set these rare names to X series[mask] = &amp;#39;X&amp;#39; # Check the new series print(series.</description></item><item><title>Pandas Groupby Does Not Guarantee Unique Content in Groupby Columns</title><link>https://datumorphism.leima.is/til/machine-learning/pandas-groupby-caveats/</link><pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/til/machine-learning/pandas-groupby-caveats/</guid><description>Pandas Groupby Does Not Guarantee Unique Content in Groupby Columns, it also considers the datatypes. Dealing with mixed types requires additional attention.</description></item><item><title>Pandas with MultiProcessing</title><link>https://datumorphism.leima.is/til/programming/pandas/pandas-parallel-multiprocessing/</link><pubDate>Sun, 09 Sep 2018 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/til/programming/pandas/pandas-parallel-multiprocessing/</guid><description>Define number of processes, prs; Split dataframe into prs dataframes; Process each dataframe with one process; Merge processed dataframes into one. A piece of demo code is shown below.
from multiprocessing.dummy import Pool as ThreadPool import pandas as pd # Create a dataframe to be processed df = pd.read_csv(&amp;#39;somedata.csv&amp;#39;).reset_index(drop=True) # Define a function to be applied to the dataframe def nice_func(name, age): return (name,age) # Apply to dataframe def apply_to_df(df_chunks): df_chunks[&amp;#39;tupled&amp;#39;] = df_chunks.apply( lambda x: nice_func( x[&amp;#39;host_name&amp;#39;], x[&amp;#39;host_country&amp;#39;]), axis=1 ) return df_chunks print(&amp;#39;finished chunk&amp;#39;) # Divide dataframe to chunks prs = 100 # define the number of processes chunk_size = int(df.</description></item><item><title>Calculated Columns in Pandas</title><link>https://datumorphism.leima.is/til/programming/pandas/pandas-new-column-from-other/</link><pubDate>Sun, 20 May 2018 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/til/programming/pandas/pandas-new-column-from-other/</guid><description>Create new columns in pandas</description></item></channel></rss>