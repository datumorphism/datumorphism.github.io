<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Generalizability on Datumorphism</title><link>https://datumorphism.leima.is/tags/generalizability/</link><description>Recent content in Generalizability on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Sun, 08 Nov 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://datumorphism.leima.is/tags/generalizability/index.xml" rel="self" type="application/rss+xml"/><item><title>Measures of Generalizability</title><link>https://datumorphism.leima.is/wiki/model-selection/measures-of-generalizability/</link><pubDate>Sun, 08 Nov 2020 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/model-selection/measures-of-generalizability/</guid><description>To measure the generalization, we define a generalization error,
$$ \begin{align} \mathcal G = \mathcal L_{P}(\hat f) - \mathcal L_E(\hat f), \end{align} $$
where $\mathcal L_{P}$ is the population loss, $\mathcal L_E$ is the empirical loss, and $\hat f$ is our model by minimizing the empirical loss.
However, we do not know the actual joint probability $p(x, y)$ of our dataset $\{x_i, y_i\}$. Thus the population loss is not known. In machine learning, we usually use [[cross validation]] Cross Validation Cross validation is a method to estimate the [[risk]] The Learning Problem The learning problem posed by Vapnik:1 Given a sample: $\{z_i\}$ in the probability space $Z$; Assuming a probability measure on the probability space $Z$; Assuming a set of functions $Q(z, \alpha)$ (e.</description></item></channel></rss>