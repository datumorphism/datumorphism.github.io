<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>numpy on Datumorphism</title><link>https://datumorphism.leima.is/tags/numpy/</link><description>Recent content in numpy on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Mon, 08 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://datumorphism.leima.is/tags/numpy/index.xml" rel="self" type="application/rss+xml"/><item><title>Centering Matrix</title><link>https://datumorphism.leima.is/cards/math/statistics-centering-matrix/</link><pubDate>Mon, 08 Nov 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/cards/math/statistics-centering-matrix/</guid><description>Given a vector $v$, with mean value of its elements $m$, we can center the vector by subtracting the mean $m$ from each element,
import numpy as np n = 10 v = np.random.randn(n) v_c = v - v.mean() This operation is easy and obvious. However, the formalism is not elegant. In some cases, we would like to formulate the process of centering the elements as operators,
$$ v_c = \operatorname{\hat H}v. $$
In this case, the operator $\operatorname{\hat H}$ is simply a matrix
$$ \operatorname{\hat H} \to I_n - \frac{1}{n} J_n, $$
where $n$ is the dimension of the vector $v$, $I_n$ is a identity matrix, $J_n$ is a matrix of all $1$s.</description></item><item><title>Binning Data Values using Pandas</title><link>https://datumorphism.leima.is/til/programming/pandas/pandas-binning-values/</link><pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/til/programming/pandas/pandas-binning-values/</guid><description>Use the pd.cut function. The bins argument is using (] are the segments. The official documentation comes with detailed examples.
If pandas is not an option, one could use numpy.digitize to find which bin the elements belong to.</description></item><item><title>ANOVA</title><link>https://datumorphism.leima.is/wiki/statistics/anova/</link><pubDate>Sun, 07 Mar 2021 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/wiki/statistics/anova/</guid><description>In many problems, we have to test if several distributions associated with several groups of experiments are the same. The null hypothesis to be used is
The distributions of several groups are the same.
ANOVA tests the null hypothesis by comparing the variability between groups and within groups. If the variability between groups are significantly larger than the variability within groups, we are more confident that the distributions of different groups are different.
We will use two-group experiments as an example. We use a fake dataset:
Group A $x^A_1$ $x^A_2$ &amp;hellip; $x^A_{N_A}$ Group B $x^B_1$ $x^B_2$ &amp;hellip; $x^B_{N_B}$ Within Group Variability The within group variability is proportional to</description></item><item><title>Python Stupid numpy.piecewise</title><link>https://datumorphism.leima.is/til/programming/python/python-stupid-numpy-piecewise/</link><pubDate>Fri, 04 Dec 2015 00:00:00 +0000</pubDate><guid>https://datumorphism.leima.is/til/programming/python/python-stupid-numpy-piecewise/</guid><description>Python Stupid numpy.piecewise</description></item></channel></rss>